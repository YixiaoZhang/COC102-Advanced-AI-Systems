{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18COC102 -  Advanced Artificial Intelligence Systems - Coursework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style='color:red'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Experiment B2</p>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n",
      "CPython 3.6.7\n",
      "IPython 7.2.0\n",
      "\n",
      "numpy 1.15.4\n",
      "torch 0.4.1\n",
      "torchvision 0.2.1\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%watermark -v -p numpy,torch,torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import os\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement the network by myself#\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1  = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2  = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.fc1   = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate=0.001\n",
    "batch_size=1000\n",
    "epoch=800\n",
    "workers=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set GPU \n",
    "device = torch.device(\"cuda:0\")\n",
    "# set Netwrok\n",
    "net = LeNet()\n",
    "net = net.to(device)\n",
    "# set optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "# set loss function\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# dataloader refer source [2]\n",
    "\n",
    "# load training dataset\n",
    "trainingset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, \n",
    "                                           transform=transforms.ToTensor())\n",
    "\n",
    "trainingloader = torch.utils.data.DataLoader(trainingset, batch_size=batch_size,shuffle=True, \n",
    "                                             num_workers=workers)\n",
    "# load testing dataset\n",
    "testingset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transforms.ToTensor())\n",
    "\n",
    "testingloader = torch.utils.data.DataLoader(testingset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=workers)\n",
    "\n",
    "#end of source [2]\n",
    "#source [2] https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0]  Loss: 0.2129  Accuracy: 19.902 %\n",
      "[epoch 1]  Loss: 0.1811  Accuracy: 33.670 %\n",
      "[epoch 2]  Loss: 0.1684  Accuracy: 37.948 %\n",
      "[epoch 3]  Loss: 0.1618  Accuracy: 40.678 %\n",
      "[epoch 4]  Loss: 0.1569  Accuracy: 42.542 %\n",
      "[epoch 5]  Loss: 0.1533  Accuracy: 44.206 %\n",
      "[epoch 6]  Loss: 0.1498  Accuracy: 45.696 %\n",
      "[epoch 7]  Loss: 0.1488  Accuracy: 45.986 %\n",
      "[epoch 8]  Loss: 0.1453  Accuracy: 47.342 %\n",
      "[epoch 9]  Loss: 0.1428  Accuracy: 48.398 %\n",
      "[epoch 10]  Loss: 0.1407  Accuracy: 49.268 %\n",
      "[epoch 11]  Loss: 0.1385  Accuracy: 50.156 %\n",
      "[epoch 12]  Loss: 0.1370  Accuracy: 50.760 %\n",
      "[epoch 13]  Loss: 0.1352  Accuracy: 51.480 %\n",
      "[epoch 14]  Loss: 0.1332  Accuracy: 52.256 %\n",
      "[epoch 15]  Loss: 0.1317  Accuracy: 52.908 %\n",
      "[epoch 16]  Loss: 0.1301  Accuracy: 53.574 %\n",
      "[epoch 17]  Loss: 0.1297  Accuracy: 53.624 %\n",
      "[epoch 18]  Loss: 0.1276  Accuracy: 54.600 %\n",
      "[epoch 19]  Loss: 0.1258  Accuracy: 55.284 %\n",
      "[epoch 20]  Loss: 0.1256  Accuracy: 55.204 %\n",
      "[epoch 21]  Loss: 0.1238  Accuracy: 56.094 %\n",
      "[epoch 22]  Loss: 0.1226  Accuracy: 56.516 %\n",
      "[epoch 23]  Loss: 0.1210  Accuracy: 57.146 %\n",
      "[epoch 24]  Loss: 0.1210  Accuracy: 57.116 %\n",
      "[epoch 25]  Loss: 0.1207  Accuracy: 57.264 %\n",
      "[epoch 26]  Loss: 0.1184  Accuracy: 58.140 %\n",
      "[epoch 27]  Loss: 0.1176  Accuracy: 58.418 %\n",
      "[epoch 28]  Loss: 0.1181  Accuracy: 58.246 %\n",
      "[epoch 29]  Loss: 0.1161  Accuracy: 59.002 %\n",
      "[epoch 30]  Loss: 0.1160  Accuracy: 58.854 %\n",
      "[epoch 31]  Loss: 0.1142  Accuracy: 59.674 %\n",
      "[epoch 32]  Loss: 0.1136  Accuracy: 59.878 %\n",
      "[epoch 33]  Loss: 0.1142  Accuracy: 59.602 %\n",
      "[epoch 34]  Loss: 0.1117  Accuracy: 60.602 %\n",
      "[epoch 35]  Loss: 0.1119  Accuracy: 60.464 %\n",
      "[epoch 36]  Loss: 0.1109  Accuracy: 60.722 %\n",
      "[epoch 37]  Loss: 0.1104  Accuracy: 61.080 %\n",
      "[epoch 38]  Loss: 0.1097  Accuracy: 61.232 %\n",
      "[epoch 39]  Loss: 0.1094  Accuracy: 61.506 %\n",
      "[epoch 40]  Loss: 0.1083  Accuracy: 61.796 %\n",
      "[epoch 41]  Loss: 0.1075  Accuracy: 62.190 %\n",
      "[epoch 42]  Loss: 0.1066  Accuracy: 62.228 %\n",
      "[epoch 43]  Loss: 0.1062  Accuracy: 62.544 %\n",
      "[epoch 44]  Loss: 0.1054  Accuracy: 62.958 %\n",
      "[epoch 45]  Loss: 0.1063  Accuracy: 62.364 %\n",
      "[epoch 46]  Loss: 0.1055  Accuracy: 62.964 %\n",
      "[epoch 47]  Loss: 0.1040  Accuracy: 63.378 %\n",
      "[epoch 48]  Loss: 0.1039  Accuracy: 63.402 %\n",
      "[epoch 49]  Loss: 0.1037  Accuracy: 63.316 %\n",
      "[epoch 50]  Loss: 0.1021  Accuracy: 64.016 %\n",
      "[epoch 51]  Loss: 0.1024  Accuracy: 64.032 %\n",
      "[epoch 52]  Loss: 0.1012  Accuracy: 64.518 %\n",
      "[epoch 53]  Loss: 0.1011  Accuracy: 64.224 %\n",
      "[epoch 54]  Loss: 0.1001  Accuracy: 64.674 %\n",
      "[epoch 55]  Loss: 0.0997  Accuracy: 64.922 %\n",
      "[epoch 56]  Loss: 0.0999  Accuracy: 64.834 %\n",
      "[epoch 57]  Loss: 0.0996  Accuracy: 64.804 %\n",
      "[epoch 58]  Loss: 0.0994  Accuracy: 65.110 %\n",
      "[epoch 59]  Loss: 0.0980  Accuracy: 65.468 %\n",
      "[epoch 60]  Loss: 0.0974  Accuracy: 65.666 %\n",
      "[epoch 61]  Loss: 0.0977  Accuracy: 65.512 %\n",
      "[epoch 62]  Loss: 0.0974  Accuracy: 65.562 %\n",
      "[epoch 63]  Loss: 0.0965  Accuracy: 66.098 %\n",
      "[epoch 64]  Loss: 0.0956  Accuracy: 66.240 %\n",
      "[epoch 65]  Loss: 0.0947  Accuracy: 66.726 %\n",
      "[epoch 66]  Loss: 0.0951  Accuracy: 66.458 %\n",
      "[epoch 67]  Loss: 0.0952  Accuracy: 66.438 %\n",
      "[epoch 68]  Loss: 0.0939  Accuracy: 67.006 %\n",
      "[epoch 69]  Loss: 0.0945  Accuracy: 66.708 %\n",
      "[epoch 70]  Loss: 0.0932  Accuracy: 67.182 %\n",
      "[epoch 71]  Loss: 0.0923  Accuracy: 67.474 %\n",
      "[epoch 72]  Loss: 0.0924  Accuracy: 67.570 %\n",
      "[epoch 73]  Loss: 0.0917  Accuracy: 67.686 %\n",
      "[epoch 74]  Loss: 0.0917  Accuracy: 67.714 %\n",
      "[epoch 75]  Loss: 0.0906  Accuracy: 68.178 %\n",
      "[epoch 76]  Loss: 0.0909  Accuracy: 68.018 %\n",
      "[epoch 77]  Loss: 0.0911  Accuracy: 67.994 %\n",
      "[epoch 78]  Loss: 0.0909  Accuracy: 68.058 %\n",
      "[epoch 79]  Loss: 0.0897  Accuracy: 68.364 %\n",
      "[epoch 80]  Loss: 0.0895  Accuracy: 68.834 %\n",
      "[epoch 81]  Loss: 0.0888  Accuracy: 68.874 %\n",
      "[epoch 82]  Loss: 0.0885  Accuracy: 68.866 %\n",
      "[epoch 83]  Loss: 0.0884  Accuracy: 68.846 %\n",
      "[epoch 84]  Loss: 0.0874  Accuracy: 69.360 %\n",
      "[epoch 85]  Loss: 0.0873  Accuracy: 69.332 %\n",
      "[epoch 86]  Loss: 0.0871  Accuracy: 69.454 %\n",
      "[epoch 87]  Loss: 0.0862  Accuracy: 69.872 %\n",
      "[epoch 88]  Loss: 0.0862  Accuracy: 69.672 %\n",
      "[epoch 89]  Loss: 0.0863  Accuracy: 69.672 %\n",
      "[epoch 90]  Loss: 0.0857  Accuracy: 69.862 %\n",
      "[epoch 91]  Loss: 0.0848  Accuracy: 70.188 %\n",
      "[epoch 92]  Loss: 0.0844  Accuracy: 70.190 %\n",
      "[epoch 93]  Loss: 0.0850  Accuracy: 70.188 %\n",
      "[epoch 94]  Loss: 0.0847  Accuracy: 70.236 %\n",
      "[epoch 95]  Loss: 0.0841  Accuracy: 70.442 %\n",
      "[epoch 96]  Loss: 0.0838  Accuracy: 70.514 %\n",
      "[epoch 97]  Loss: 0.0833  Accuracy: 70.684 %\n",
      "[epoch 98]  Loss: 0.0823  Accuracy: 71.134 %\n",
      "[epoch 99]  Loss: 0.0820  Accuracy: 71.270 %\n",
      "[epoch 100]  Loss: 0.0819  Accuracy: 71.244 %\n",
      "[epoch 101]  Loss: 0.0823  Accuracy: 70.976 %\n",
      "[epoch 102]  Loss: 0.0821  Accuracy: 70.944 %\n",
      "[epoch 103]  Loss: 0.0816  Accuracy: 71.324 %\n",
      "[epoch 104]  Loss: 0.0807  Accuracy: 71.700 %\n",
      "[epoch 105]  Loss: 0.0806  Accuracy: 71.646 %\n",
      "[epoch 106]  Loss: 0.0799  Accuracy: 71.932 %\n",
      "[epoch 107]  Loss: 0.0801  Accuracy: 71.976 %\n",
      "[epoch 108]  Loss: 0.0794  Accuracy: 72.260 %\n",
      "[epoch 109]  Loss: 0.0793  Accuracy: 72.240 %\n",
      "[epoch 110]  Loss: 0.0788  Accuracy: 72.330 %\n",
      "[epoch 111]  Loss: 0.0783  Accuracy: 72.440 %\n",
      "[epoch 112]  Loss: 0.0792  Accuracy: 72.194 %\n",
      "[epoch 113]  Loss: 0.0790  Accuracy: 72.170 %\n",
      "[epoch 114]  Loss: 0.0780  Accuracy: 72.786 %\n",
      "[epoch 115]  Loss: 0.0778  Accuracy: 72.760 %\n",
      "[epoch 116]  Loss: 0.0773  Accuracy: 72.664 %\n",
      "[epoch 117]  Loss: 0.0769  Accuracy: 73.050 %\n",
      "[epoch 118]  Loss: 0.0758  Accuracy: 73.316 %\n",
      "[epoch 119]  Loss: 0.0766  Accuracy: 72.996 %\n",
      "[epoch 120]  Loss: 0.0755  Accuracy: 73.510 %\n",
      "[epoch 121]  Loss: 0.0758  Accuracy: 73.478 %\n",
      "[epoch 122]  Loss: 0.0758  Accuracy: 73.384 %\n",
      "[epoch 123]  Loss: 0.0750  Accuracy: 73.690 %\n",
      "[epoch 124]  Loss: 0.0743  Accuracy: 74.134 %\n",
      "[epoch 125]  Loss: 0.0741  Accuracy: 73.962 %\n",
      "[epoch 126]  Loss: 0.0747  Accuracy: 73.880 %\n",
      "[epoch 127]  Loss: 0.0738  Accuracy: 74.090 %\n",
      "[epoch 128]  Loss: 0.0735  Accuracy: 74.354 %\n",
      "[epoch 129]  Loss: 0.0736  Accuracy: 74.346 %\n",
      "[epoch 130]  Loss: 0.0738  Accuracy: 74.058 %\n",
      "[epoch 131]  Loss: 0.0724  Accuracy: 74.622 %\n",
      "[epoch 132]  Loss: 0.0731  Accuracy: 74.260 %\n",
      "[epoch 133]  Loss: 0.0722  Accuracy: 74.556 %\n",
      "[epoch 134]  Loss: 0.0723  Accuracy: 74.604 %\n",
      "[epoch 135]  Loss: 0.0715  Accuracy: 74.802 %\n",
      "[epoch 136]  Loss: 0.0714  Accuracy: 74.882 %\n",
      "[epoch 137]  Loss: 0.0711  Accuracy: 75.112 %\n",
      "[epoch 138]  Loss: 0.0718  Accuracy: 74.804 %\n",
      "[epoch 139]  Loss: 0.0712  Accuracy: 74.952 %\n",
      "[epoch 140]  Loss: 0.0711  Accuracy: 75.130 %\n",
      "[epoch 141]  Loss: 0.0701  Accuracy: 75.530 %\n",
      "[epoch 142]  Loss: 0.0695  Accuracy: 75.636 %\n",
      "[epoch 143]  Loss: 0.0700  Accuracy: 75.464 %\n",
      "[epoch 144]  Loss: 0.0690  Accuracy: 75.914 %\n",
      "[epoch 145]  Loss: 0.0690  Accuracy: 75.660 %\n",
      "[epoch 146]  Loss: 0.0691  Accuracy: 75.718 %\n",
      "[epoch 147]  Loss: 0.0687  Accuracy: 75.820 %\n",
      "[epoch 148]  Loss: 0.0682  Accuracy: 76.110 %\n",
      "[epoch 149]  Loss: 0.0699  Accuracy: 75.378 %\n",
      "[epoch 150]  Loss: 0.0680  Accuracy: 76.258 %\n",
      "[epoch 151]  Loss: 0.0673  Accuracy: 76.360 %\n",
      "[epoch 152]  Loss: 0.0682  Accuracy: 75.950 %\n",
      "[epoch 153]  Loss: 0.0667  Accuracy: 76.602 %\n",
      "[epoch 154]  Loss: 0.0682  Accuracy: 75.916 %\n",
      "[epoch 155]  Loss: 0.0661  Accuracy: 76.852 %\n",
      "[epoch 156]  Loss: 0.0675  Accuracy: 76.218 %\n",
      "[epoch 157]  Loss: 0.0656  Accuracy: 76.928 %\n",
      "[epoch 158]  Loss: 0.0654  Accuracy: 77.104 %\n",
      "[epoch 159]  Loss: 0.0656  Accuracy: 76.950 %\n",
      "[epoch 160]  Loss: 0.0668  Accuracy: 76.474 %\n",
      "[epoch 161]  Loss: 0.0662  Accuracy: 76.610 %\n",
      "[epoch 162]  Loss: 0.0651  Accuracy: 77.184 %\n",
      "[epoch 163]  Loss: 0.0655  Accuracy: 76.876 %\n",
      "[epoch 164]  Loss: 0.0645  Accuracy: 77.388 %\n",
      "[epoch 165]  Loss: 0.0644  Accuracy: 77.466 %\n",
      "[epoch 166]  Loss: 0.0655  Accuracy: 76.928 %\n",
      "[epoch 167]  Loss: 0.0644  Accuracy: 77.396 %\n",
      "[epoch 168]  Loss: 0.0645  Accuracy: 77.232 %\n",
      "[epoch 169]  Loss: 0.0634  Accuracy: 77.828 %\n",
      "[epoch 170]  Loss: 0.0635  Accuracy: 77.786 %\n",
      "[epoch 171]  Loss: 0.0628  Accuracy: 77.812 %\n",
      "[epoch 172]  Loss: 0.0636  Accuracy: 77.588 %\n",
      "[epoch 173]  Loss: 0.0634  Accuracy: 77.572 %\n",
      "[epoch 174]  Loss: 0.0628  Accuracy: 77.922 %\n",
      "[epoch 175]  Loss: 0.0617  Accuracy: 78.344 %\n",
      "[epoch 176]  Loss: 0.0613  Accuracy: 78.588 %\n",
      "[epoch 177]  Loss: 0.0619  Accuracy: 78.256 %\n",
      "[epoch 178]  Loss: 0.0613  Accuracy: 78.556 %\n",
      "[epoch 179]  Loss: 0.0618  Accuracy: 78.458 %\n",
      "[epoch 180]  Loss: 0.0616  Accuracy: 78.380 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 181]  Loss: 0.0608  Accuracy: 78.768 %\n",
      "[epoch 182]  Loss: 0.0613  Accuracy: 78.584 %\n",
      "[epoch 183]  Loss: 0.0607  Accuracy: 78.698 %\n",
      "[epoch 184]  Loss: 0.0600  Accuracy: 78.934 %\n",
      "[epoch 185]  Loss: 0.0604  Accuracy: 78.798 %\n",
      "[epoch 186]  Loss: 0.0597  Accuracy: 79.172 %\n",
      "[epoch 187]  Loss: 0.0589  Accuracy: 79.516 %\n",
      "[epoch 188]  Loss: 0.0586  Accuracy: 79.614 %\n",
      "[epoch 189]  Loss: 0.0582  Accuracy: 79.704 %\n",
      "[epoch 190]  Loss: 0.0594  Accuracy: 79.042 %\n",
      "[epoch 191]  Loss: 0.0595  Accuracy: 79.106 %\n",
      "[epoch 192]  Loss: 0.0584  Accuracy: 79.816 %\n",
      "[epoch 193]  Loss: 0.0583  Accuracy: 79.546 %\n",
      "[epoch 194]  Loss: 0.0592  Accuracy: 79.088 %\n",
      "[epoch 195]  Loss: 0.0585  Accuracy: 79.606 %\n",
      "[epoch 196]  Loss: 0.0574  Accuracy: 79.920 %\n",
      "[epoch 197]  Loss: 0.0578  Accuracy: 79.792 %\n",
      "[epoch 198]  Loss: 0.0572  Accuracy: 79.892 %\n",
      "[epoch 199]  Loss: 0.0589  Accuracy: 79.316 %\n",
      "[epoch 200]  Loss: 0.0575  Accuracy: 79.942 %\n",
      "[epoch 201]  Loss: 0.0565  Accuracy: 80.348 %\n",
      "[epoch 202]  Loss: 0.0567  Accuracy: 80.172 %\n",
      "[epoch 203]  Loss: 0.0560  Accuracy: 80.492 %\n",
      "[epoch 204]  Loss: 0.0562  Accuracy: 80.268 %\n",
      "[epoch 205]  Loss: 0.0566  Accuracy: 80.124 %\n",
      "[epoch 206]  Loss: 0.0564  Accuracy: 80.348 %\n",
      "[epoch 207]  Loss: 0.0556  Accuracy: 80.582 %\n",
      "[epoch 208]  Loss: 0.0560  Accuracy: 80.416 %\n",
      "[epoch 209]  Loss: 0.0551  Accuracy: 80.722 %\n",
      "[epoch 210]  Loss: 0.0543  Accuracy: 81.128 %\n",
      "[epoch 211]  Loss: 0.0549  Accuracy: 80.834 %\n",
      "[epoch 212]  Loss: 0.0580  Accuracy: 79.330 %\n",
      "[epoch 213]  Loss: 0.0560  Accuracy: 80.322 %\n",
      "[epoch 214]  Loss: 0.0548  Accuracy: 80.952 %\n",
      "[epoch 215]  Loss: 0.0535  Accuracy: 81.468 %\n",
      "[epoch 216]  Loss: 0.0541  Accuracy: 81.066 %\n",
      "[epoch 217]  Loss: 0.0535  Accuracy: 81.386 %\n",
      "[epoch 218]  Loss: 0.0549  Accuracy: 80.658 %\n",
      "[epoch 219]  Loss: 0.0544  Accuracy: 81.086 %\n",
      "[epoch 220]  Loss: 0.0542  Accuracy: 81.050 %\n",
      "[epoch 221]  Loss: 0.0532  Accuracy: 81.514 %\n",
      "[epoch 222]  Loss: 0.0535  Accuracy: 81.162 %\n",
      "[epoch 223]  Loss: 0.0526  Accuracy: 81.648 %\n",
      "[epoch 224]  Loss: 0.0525  Accuracy: 81.700 %\n",
      "[epoch 225]  Loss: 0.0522  Accuracy: 81.974 %\n",
      "[epoch 226]  Loss: 0.0524  Accuracy: 81.842 %\n",
      "[epoch 227]  Loss: 0.0516  Accuracy: 82.206 %\n",
      "[epoch 228]  Loss: 0.0520  Accuracy: 81.774 %\n",
      "[epoch 229]  Loss: 0.0535  Accuracy: 81.098 %\n",
      "[epoch 230]  Loss: 0.0525  Accuracy: 81.436 %\n",
      "[epoch 231]  Loss: 0.0511  Accuracy: 82.294 %\n",
      "[epoch 232]  Loss: 0.0509  Accuracy: 82.210 %\n",
      "[epoch 233]  Loss: 0.0510  Accuracy: 82.228 %\n",
      "[epoch 234]  Loss: 0.0508  Accuracy: 82.268 %\n",
      "[epoch 235]  Loss: 0.0502  Accuracy: 82.742 %\n",
      "[epoch 236]  Loss: 0.0501  Accuracy: 82.500 %\n",
      "[epoch 237]  Loss: 0.0502  Accuracy: 82.590 %\n",
      "[epoch 238]  Loss: 0.0507  Accuracy: 82.236 %\n",
      "[epoch 239]  Loss: 0.0497  Accuracy: 82.776 %\n",
      "[epoch 240]  Loss: 0.0495  Accuracy: 82.870 %\n",
      "[epoch 241]  Loss: 0.0491  Accuracy: 82.974 %\n",
      "[epoch 242]  Loss: 0.0495  Accuracy: 82.802 %\n",
      "[epoch 243]  Loss: 0.0490  Accuracy: 83.026 %\n",
      "[epoch 244]  Loss: 0.0492  Accuracy: 82.942 %\n",
      "[epoch 245]  Loss: 0.0488  Accuracy: 83.042 %\n",
      "[epoch 246]  Loss: 0.0494  Accuracy: 82.704 %\n",
      "[epoch 247]  Loss: 0.0479  Accuracy: 83.440 %\n",
      "[epoch 248]  Loss: 0.0487  Accuracy: 83.002 %\n",
      "[epoch 249]  Loss: 0.0479  Accuracy: 83.410 %\n",
      "[epoch 250]  Loss: 0.0480  Accuracy: 83.164 %\n",
      "[epoch 251]  Loss: 0.0482  Accuracy: 83.304 %\n",
      "[epoch 252]  Loss: 0.0482  Accuracy: 83.254 %\n",
      "[epoch 253]  Loss: 0.0486  Accuracy: 82.934 %\n",
      "[epoch 254]  Loss: 0.0480  Accuracy: 83.256 %\n",
      "[epoch 255]  Loss: 0.0474  Accuracy: 83.394 %\n",
      "[epoch 256]  Loss: 0.0471  Accuracy: 83.762 %\n",
      "[epoch 257]  Loss: 0.0473  Accuracy: 83.414 %\n",
      "[epoch 258]  Loss: 0.0470  Accuracy: 83.550 %\n",
      "[epoch 259]  Loss: 0.0468  Accuracy: 83.690 %\n",
      "[epoch 260]  Loss: 0.0467  Accuracy: 83.696 %\n",
      "[epoch 261]  Loss: 0.0465  Accuracy: 83.794 %\n",
      "[epoch 262]  Loss: 0.0451  Accuracy: 84.304 %\n",
      "[epoch 263]  Loss: 0.0455  Accuracy: 84.244 %\n",
      "[epoch 264]  Loss: 0.0462  Accuracy: 84.030 %\n",
      "[epoch 265]  Loss: 0.0466  Accuracy: 83.578 %\n",
      "[epoch 266]  Loss: 0.0458  Accuracy: 84.198 %\n",
      "[epoch 267]  Loss: 0.0462  Accuracy: 83.740 %\n",
      "[epoch 268]  Loss: 0.0452  Accuracy: 84.148 %\n",
      "[epoch 269]  Loss: 0.0455  Accuracy: 84.026 %\n",
      "[epoch 270]  Loss: 0.0445  Accuracy: 84.446 %\n",
      "[epoch 271]  Loss: 0.0446  Accuracy: 84.498 %\n",
      "[epoch 272]  Loss: 0.0465  Accuracy: 83.616 %\n",
      "[epoch 273]  Loss: 0.0457  Accuracy: 83.952 %\n",
      "[epoch 274]  Loss: 0.0435  Accuracy: 84.966 %\n",
      "[epoch 275]  Loss: 0.0440  Accuracy: 84.662 %\n",
      "[epoch 276]  Loss: 0.0434  Accuracy: 85.028 %\n",
      "[epoch 277]  Loss: 0.0435  Accuracy: 85.014 %\n",
      "[epoch 278]  Loss: 0.0433  Accuracy: 84.996 %\n",
      "[epoch 279]  Loss: 0.0428  Accuracy: 85.146 %\n",
      "[epoch 280]  Loss: 0.0434  Accuracy: 84.882 %\n",
      "[epoch 281]  Loss: 0.0442  Accuracy: 84.558 %\n",
      "[epoch 282]  Loss: 0.0445  Accuracy: 84.260 %\n",
      "[epoch 283]  Loss: 0.0429  Accuracy: 85.008 %\n",
      "[epoch 284]  Loss: 0.0422  Accuracy: 85.522 %\n",
      "[epoch 285]  Loss: 0.0425  Accuracy: 85.294 %\n",
      "[epoch 286]  Loss: 0.0430  Accuracy: 84.928 %\n",
      "[epoch 287]  Loss: 0.0414  Accuracy: 85.914 %\n",
      "[epoch 288]  Loss: 0.0419  Accuracy: 85.558 %\n",
      "[epoch 289]  Loss: 0.0432  Accuracy: 84.818 %\n",
      "[epoch 290]  Loss: 0.0424  Accuracy: 85.318 %\n",
      "[epoch 291]  Loss: 0.0420  Accuracy: 85.244 %\n",
      "[epoch 292]  Loss: 0.0420  Accuracy: 85.436 %\n",
      "[epoch 293]  Loss: 0.0409  Accuracy: 85.968 %\n",
      "[epoch 294]  Loss: 0.0417  Accuracy: 85.514 %\n",
      "[epoch 295]  Loss: 0.0413  Accuracy: 85.684 %\n",
      "[epoch 296]  Loss: 0.0407  Accuracy: 85.928 %\n",
      "[epoch 297]  Loss: 0.0401  Accuracy: 86.232 %\n",
      "[epoch 298]  Loss: 0.0408  Accuracy: 85.816 %\n",
      "[epoch 299]  Loss: 0.0400  Accuracy: 86.248 %\n",
      "[epoch 300]  Loss: 0.0393  Accuracy: 86.498 %\n",
      "[epoch 301]  Loss: 0.0405  Accuracy: 86.088 %\n",
      "[epoch 302]  Loss: 0.0399  Accuracy: 86.176 %\n",
      "[epoch 303]  Loss: 0.0402  Accuracy: 86.000 %\n",
      "[epoch 304]  Loss: 0.0395  Accuracy: 86.384 %\n",
      "[epoch 305]  Loss: 0.0395  Accuracy: 86.350 %\n",
      "[epoch 306]  Loss: 0.0396  Accuracy: 86.114 %\n",
      "[epoch 307]  Loss: 0.0390  Accuracy: 86.588 %\n",
      "[epoch 308]  Loss: 0.0388  Accuracy: 86.580 %\n",
      "[epoch 309]  Loss: 0.0399  Accuracy: 85.842 %\n",
      "[epoch 310]  Loss: 0.0395  Accuracy: 86.170 %\n",
      "[epoch 311]  Loss: 0.0401  Accuracy: 86.072 %\n",
      "[epoch 312]  Loss: 0.0384  Accuracy: 86.656 %\n",
      "[epoch 313]  Loss: 0.0381  Accuracy: 86.894 %\n",
      "[epoch 314]  Loss: 0.0381  Accuracy: 86.880 %\n",
      "[epoch 315]  Loss: 0.0377  Accuracy: 86.946 %\n",
      "[epoch 316]  Loss: 0.0380  Accuracy: 86.662 %\n",
      "[epoch 317]  Loss: 0.0381  Accuracy: 86.796 %\n",
      "[epoch 318]  Loss: 0.0388  Accuracy: 86.342 %\n",
      "[epoch 319]  Loss: 0.0382  Accuracy: 86.676 %\n",
      "[epoch 320]  Loss: 0.0381  Accuracy: 86.744 %\n",
      "[epoch 321]  Loss: 0.0380  Accuracy: 86.644 %\n",
      "[epoch 322]  Loss: 0.0377  Accuracy: 86.874 %\n",
      "[epoch 323]  Loss: 0.0379  Accuracy: 86.680 %\n",
      "[epoch 324]  Loss: 0.0370  Accuracy: 87.268 %\n",
      "[epoch 325]  Loss: 0.0373  Accuracy: 87.070 %\n",
      "[epoch 326]  Loss: 0.0373  Accuracy: 87.100 %\n",
      "[epoch 327]  Loss: 0.0368  Accuracy: 87.176 %\n",
      "[epoch 328]  Loss: 0.0377  Accuracy: 86.842 %\n",
      "[epoch 329]  Loss: 0.0361  Accuracy: 87.512 %\n",
      "[epoch 330]  Loss: 0.0365  Accuracy: 87.334 %\n",
      "[epoch 331]  Loss: 0.0368  Accuracy: 87.206 %\n",
      "[epoch 332]  Loss: 0.0356  Accuracy: 87.808 %\n",
      "[epoch 333]  Loss: 0.0363  Accuracy: 87.432 %\n",
      "[epoch 334]  Loss: 0.0358  Accuracy: 87.638 %\n",
      "[epoch 335]  Loss: 0.0359  Accuracy: 87.518 %\n",
      "[epoch 336]  Loss: 0.0356  Accuracy: 87.790 %\n",
      "[epoch 337]  Loss: 0.0353  Accuracy: 87.838 %\n",
      "[epoch 338]  Loss: 0.0357  Accuracy: 87.650 %\n",
      "[epoch 339]  Loss: 0.0352  Accuracy: 87.836 %\n",
      "[epoch 340]  Loss: 0.0357  Accuracy: 87.492 %\n",
      "[epoch 341]  Loss: 0.0350  Accuracy: 87.872 %\n",
      "[epoch 342]  Loss: 0.0344  Accuracy: 88.260 %\n",
      "[epoch 343]  Loss: 0.0342  Accuracy: 88.294 %\n",
      "[epoch 344]  Loss: 0.0341  Accuracy: 88.282 %\n",
      "[epoch 345]  Loss: 0.0355  Accuracy: 87.642 %\n",
      "[epoch 346]  Loss: 0.0347  Accuracy: 87.928 %\n",
      "[epoch 347]  Loss: 0.0343  Accuracy: 88.048 %\n",
      "[epoch 348]  Loss: 0.0337  Accuracy: 88.304 %\n",
      "[epoch 349]  Loss: 0.0335  Accuracy: 88.524 %\n",
      "[epoch 350]  Loss: 0.0327  Accuracy: 89.000 %\n",
      "[epoch 351]  Loss: 0.0331  Accuracy: 88.736 %\n",
      "[epoch 352]  Loss: 0.0344  Accuracy: 87.876 %\n",
      "[epoch 353]  Loss: 0.0341  Accuracy: 88.238 %\n",
      "[epoch 354]  Loss: 0.0339  Accuracy: 88.118 %\n",
      "[epoch 355]  Loss: 0.0330  Accuracy: 88.658 %\n",
      "[epoch 356]  Loss: 0.0333  Accuracy: 88.438 %\n",
      "[epoch 357]  Loss: 0.0332  Accuracy: 88.458 %\n",
      "[epoch 358]  Loss: 0.0326  Accuracy: 88.784 %\n",
      "[epoch 359]  Loss: 0.0330  Accuracy: 88.586 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 360]  Loss: 0.0323  Accuracy: 88.890 %\n",
      "[epoch 361]  Loss: 0.0325  Accuracy: 88.776 %\n",
      "[epoch 362]  Loss: 0.0330  Accuracy: 88.420 %\n",
      "[epoch 363]  Loss: 0.0336  Accuracy: 88.212 %\n",
      "[epoch 364]  Loss: 0.0324  Accuracy: 88.910 %\n",
      "[epoch 365]  Loss: 0.0324  Accuracy: 88.860 %\n",
      "[epoch 366]  Loss: 0.0312  Accuracy: 89.420 %\n",
      "[epoch 367]  Loss: 0.0313  Accuracy: 89.348 %\n",
      "[epoch 368]  Loss: 0.0325  Accuracy: 88.476 %\n",
      "[epoch 369]  Loss: 0.0321  Accuracy: 88.920 %\n",
      "[epoch 370]  Loss: 0.0316  Accuracy: 89.036 %\n",
      "[epoch 371]  Loss: 0.0307  Accuracy: 89.414 %\n",
      "[epoch 372]  Loss: 0.0313  Accuracy: 89.132 %\n",
      "[epoch 373]  Loss: 0.0310  Accuracy: 89.316 %\n",
      "[epoch 374]  Loss: 0.0330  Accuracy: 88.372 %\n",
      "[epoch 375]  Loss: 0.0311  Accuracy: 89.254 %\n",
      "[epoch 376]  Loss: 0.0307  Accuracy: 89.416 %\n",
      "[epoch 377]  Loss: 0.0308  Accuracy: 89.280 %\n",
      "[epoch 378]  Loss: 0.0295  Accuracy: 90.034 %\n",
      "[epoch 379]  Loss: 0.0311  Accuracy: 89.124 %\n",
      "[epoch 380]  Loss: 0.0303  Accuracy: 89.638 %\n",
      "[epoch 381]  Loss: 0.0312  Accuracy: 89.120 %\n",
      "[epoch 382]  Loss: 0.0298  Accuracy: 89.780 %\n",
      "[epoch 383]  Loss: 0.0302  Accuracy: 89.538 %\n",
      "[epoch 384]  Loss: 0.0296  Accuracy: 89.852 %\n",
      "[epoch 385]  Loss: 0.0295  Accuracy: 89.992 %\n",
      "[epoch 386]  Loss: 0.0290  Accuracy: 90.192 %\n",
      "[epoch 387]  Loss: 0.0293  Accuracy: 89.848 %\n",
      "[epoch 388]  Loss: 0.0324  Accuracy: 88.420 %\n",
      "[epoch 389]  Loss: 0.0302  Accuracy: 89.530 %\n",
      "[epoch 390]  Loss: 0.0294  Accuracy: 89.988 %\n",
      "[epoch 391]  Loss: 0.0290  Accuracy: 90.044 %\n",
      "[epoch 392]  Loss: 0.0295  Accuracy: 89.716 %\n",
      "[epoch 393]  Loss: 0.0291  Accuracy: 90.104 %\n",
      "[epoch 394]  Loss: 0.0286  Accuracy: 90.152 %\n",
      "[epoch 395]  Loss: 0.0293  Accuracy: 89.880 %\n",
      "[epoch 396]  Loss: 0.0281  Accuracy: 90.264 %\n",
      "[epoch 397]  Loss: 0.0283  Accuracy: 90.300 %\n",
      "[epoch 398]  Loss: 0.0275  Accuracy: 90.758 %\n",
      "[epoch 399]  Loss: 0.0291  Accuracy: 89.838 %\n",
      "[epoch 400]  Loss: 0.0294  Accuracy: 89.754 %\n",
      "[epoch 401]  Loss: 0.0292  Accuracy: 89.642 %\n",
      "[epoch 402]  Loss: 0.0307  Accuracy: 89.054 %\n",
      "[epoch 403]  Loss: 0.0292  Accuracy: 89.794 %\n",
      "[epoch 404]  Loss: 0.0271  Accuracy: 90.760 %\n",
      "[epoch 405]  Loss: 0.0279  Accuracy: 90.280 %\n",
      "[epoch 406]  Loss: 0.0287  Accuracy: 89.962 %\n",
      "[epoch 407]  Loss: 0.0274  Accuracy: 90.606 %\n",
      "[epoch 408]  Loss: 0.0285  Accuracy: 89.988 %\n",
      "[epoch 409]  Loss: 0.0284  Accuracy: 90.016 %\n",
      "[epoch 410]  Loss: 0.0265  Accuracy: 91.014 %\n",
      "[epoch 411]  Loss: 0.0274  Accuracy: 90.542 %\n",
      "[epoch 412]  Loss: 0.0260  Accuracy: 91.262 %\n",
      "[epoch 413]  Loss: 0.0265  Accuracy: 90.970 %\n",
      "[epoch 414]  Loss: 0.0257  Accuracy: 91.466 %\n",
      "[epoch 415]  Loss: 0.0280  Accuracy: 90.240 %\n",
      "[epoch 416]  Loss: 0.0258  Accuracy: 91.272 %\n",
      "[epoch 417]  Loss: 0.0255  Accuracy: 91.496 %\n",
      "[epoch 418]  Loss: 0.0267  Accuracy: 90.800 %\n",
      "[epoch 419]  Loss: 0.0273  Accuracy: 90.536 %\n",
      "[epoch 420]  Loss: 0.0256  Accuracy: 91.330 %\n",
      "[epoch 421]  Loss: 0.0270  Accuracy: 90.554 %\n",
      "[epoch 422]  Loss: 0.0261  Accuracy: 91.096 %\n",
      "[epoch 423]  Loss: 0.0251  Accuracy: 91.714 %\n",
      "[epoch 424]  Loss: 0.0253  Accuracy: 91.376 %\n",
      "[epoch 425]  Loss: 0.0254  Accuracy: 91.446 %\n",
      "[epoch 426]  Loss: 0.0252  Accuracy: 91.478 %\n",
      "[epoch 427]  Loss: 0.0270  Accuracy: 90.488 %\n",
      "[epoch 428]  Loss: 0.0247  Accuracy: 91.796 %\n",
      "[epoch 429]  Loss: 0.0271  Accuracy: 90.350 %\n",
      "[epoch 430]  Loss: 0.0274  Accuracy: 90.424 %\n",
      "[epoch 431]  Loss: 0.0278  Accuracy: 90.206 %\n",
      "[epoch 432]  Loss: 0.0244  Accuracy: 91.788 %\n",
      "[epoch 433]  Loss: 0.0239  Accuracy: 92.118 %\n",
      "[epoch 434]  Loss: 0.0243  Accuracy: 91.792 %\n",
      "[epoch 435]  Loss: 0.0251  Accuracy: 91.294 %\n",
      "[epoch 436]  Loss: 0.0245  Accuracy: 91.756 %\n",
      "[epoch 437]  Loss: 0.0240  Accuracy: 91.964 %\n",
      "[epoch 438]  Loss: 0.0247  Accuracy: 91.588 %\n",
      "[epoch 439]  Loss: 0.0241  Accuracy: 91.802 %\n",
      "[epoch 440]  Loss: 0.0261  Accuracy: 90.806 %\n",
      "[epoch 441]  Loss: 0.0249  Accuracy: 91.410 %\n",
      "[epoch 442]  Loss: 0.0232  Accuracy: 92.316 %\n",
      "[epoch 443]  Loss: 0.0234  Accuracy: 92.102 %\n",
      "[epoch 444]  Loss: 0.0238  Accuracy: 91.894 %\n",
      "[epoch 445]  Loss: 0.0250  Accuracy: 91.374 %\n",
      "[epoch 446]  Loss: 0.0249  Accuracy: 91.348 %\n",
      "[epoch 447]  Loss: 0.0256  Accuracy: 90.978 %\n",
      "[epoch 448]  Loss: 0.0228  Accuracy: 92.428 %\n",
      "[epoch 449]  Loss: 0.0235  Accuracy: 91.982 %\n",
      "[epoch 450]  Loss: 0.0230  Accuracy: 92.346 %\n",
      "[epoch 451]  Loss: 0.0236  Accuracy: 91.886 %\n",
      "[epoch 452]  Loss: 0.0240  Accuracy: 91.748 %\n",
      "[epoch 453]  Loss: 0.0242  Accuracy: 91.620 %\n",
      "[epoch 454]  Loss: 0.0232  Accuracy: 92.242 %\n",
      "[epoch 455]  Loss: 0.0231  Accuracy: 92.184 %\n",
      "[epoch 456]  Loss: 0.0239  Accuracy: 91.788 %\n",
      "[epoch 457]  Loss: 0.0233  Accuracy: 92.156 %\n",
      "[epoch 458]  Loss: 0.0261  Accuracy: 90.632 %\n",
      "[epoch 459]  Loss: 0.0233  Accuracy: 91.880 %\n",
      "[epoch 460]  Loss: 0.0217  Accuracy: 92.852 %\n",
      "[epoch 461]  Loss: 0.0226  Accuracy: 92.380 %\n",
      "[epoch 462]  Loss: 0.0218  Accuracy: 92.798 %\n",
      "[epoch 463]  Loss: 0.0228  Accuracy: 92.148 %\n",
      "[epoch 464]  Loss: 0.0217  Accuracy: 92.802 %\n",
      "[epoch 465]  Loss: 0.0213  Accuracy: 92.924 %\n",
      "[epoch 466]  Loss: 0.0219  Accuracy: 92.678 %\n",
      "[epoch 467]  Loss: 0.0216  Accuracy: 92.694 %\n",
      "[epoch 468]  Loss: 0.0218  Accuracy: 92.618 %\n",
      "[epoch 469]  Loss: 0.0209  Accuracy: 93.192 %\n",
      "[epoch 470]  Loss: 0.0220  Accuracy: 92.412 %\n",
      "[epoch 471]  Loss: 0.0229  Accuracy: 92.060 %\n",
      "[epoch 472]  Loss: 0.0226  Accuracy: 92.168 %\n",
      "[epoch 473]  Loss: 0.0212  Accuracy: 92.870 %\n",
      "[epoch 474]  Loss: 0.0240  Accuracy: 91.430 %\n",
      "[epoch 475]  Loss: 0.0247  Accuracy: 91.110 %\n",
      "[epoch 476]  Loss: 0.0224  Accuracy: 92.196 %\n",
      "[epoch 477]  Loss: 0.0216  Accuracy: 92.630 %\n",
      "[epoch 478]  Loss: 0.0199  Accuracy: 93.524 %\n",
      "[epoch 479]  Loss: 0.0201  Accuracy: 93.474 %\n",
      "[epoch 480]  Loss: 0.0206  Accuracy: 93.080 %\n",
      "[epoch 481]  Loss: 0.0198  Accuracy: 93.478 %\n",
      "[epoch 482]  Loss: 0.0204  Accuracy: 93.180 %\n",
      "[epoch 483]  Loss: 0.0209  Accuracy: 92.916 %\n",
      "[epoch 484]  Loss: 0.0216  Accuracy: 92.492 %\n",
      "[epoch 485]  Loss: 0.0211  Accuracy: 92.838 %\n",
      "[epoch 486]  Loss: 0.0212  Accuracy: 92.810 %\n",
      "[epoch 487]  Loss: 0.0197  Accuracy: 93.312 %\n",
      "[epoch 488]  Loss: 0.0193  Accuracy: 93.712 %\n",
      "[epoch 489]  Loss: 0.0197  Accuracy: 93.594 %\n",
      "[epoch 490]  Loss: 0.0207  Accuracy: 92.928 %\n",
      "[epoch 491]  Loss: 0.0207  Accuracy: 92.862 %\n",
      "[epoch 492]  Loss: 0.0202  Accuracy: 93.070 %\n",
      "[epoch 493]  Loss: 0.0204  Accuracy: 92.990 %\n",
      "[epoch 494]  Loss: 0.0217  Accuracy: 92.170 %\n",
      "[epoch 495]  Loss: 0.0211  Accuracy: 92.664 %\n",
      "[epoch 496]  Loss: 0.0212  Accuracy: 92.564 %\n",
      "[epoch 497]  Loss: 0.0213  Accuracy: 92.528 %\n",
      "[epoch 498]  Loss: 0.0195  Accuracy: 93.480 %\n",
      "[epoch 499]  Loss: 0.0187  Accuracy: 93.806 %\n",
      "[epoch 500]  Loss: 0.0207  Accuracy: 92.742 %\n",
      "[epoch 501]  Loss: 0.0181  Accuracy: 94.204 %\n",
      "[epoch 502]  Loss: 0.0218  Accuracy: 92.188 %\n",
      "[epoch 503]  Loss: 0.0189  Accuracy: 93.654 %\n",
      "[epoch 504]  Loss: 0.0198  Accuracy: 93.306 %\n",
      "[epoch 505]  Loss: 0.0188  Accuracy: 93.656 %\n",
      "[epoch 506]  Loss: 0.0182  Accuracy: 94.062 %\n",
      "[epoch 507]  Loss: 0.0180  Accuracy: 94.092 %\n",
      "[epoch 508]  Loss: 0.0179  Accuracy: 94.150 %\n",
      "[epoch 509]  Loss: 0.0212  Accuracy: 92.544 %\n",
      "[epoch 510]  Loss: 0.0224  Accuracy: 91.858 %\n",
      "[epoch 511]  Loss: 0.0194  Accuracy: 93.376 %\n",
      "[epoch 512]  Loss: 0.0179  Accuracy: 94.010 %\n",
      "[epoch 513]  Loss: 0.0172  Accuracy: 94.590 %\n",
      "[epoch 514]  Loss: 0.0173  Accuracy: 94.528 %\n",
      "[epoch 515]  Loss: 0.0186  Accuracy: 93.760 %\n",
      "[epoch 516]  Loss: 0.0174  Accuracy: 94.436 %\n",
      "[epoch 517]  Loss: 0.0198  Accuracy: 93.122 %\n",
      "[epoch 518]  Loss: 0.0188  Accuracy: 93.600 %\n",
      "[epoch 519]  Loss: 0.0191  Accuracy: 93.446 %\n",
      "[epoch 520]  Loss: 0.0198  Accuracy: 93.122 %\n",
      "[epoch 521]  Loss: 0.0182  Accuracy: 93.800 %\n",
      "[epoch 522]  Loss: 0.0174  Accuracy: 94.194 %\n",
      "[epoch 523]  Loss: 0.0176  Accuracy: 94.224 %\n",
      "[epoch 524]  Loss: 0.0178  Accuracy: 94.074 %\n",
      "[epoch 525]  Loss: 0.0169  Accuracy: 94.540 %\n",
      "[epoch 526]  Loss: 0.0172  Accuracy: 94.336 %\n",
      "[epoch 527]  Loss: 0.0168  Accuracy: 94.552 %\n",
      "[epoch 528]  Loss: 0.0166  Accuracy: 94.698 %\n",
      "[epoch 529]  Loss: 0.0178  Accuracy: 93.944 %\n",
      "[epoch 530]  Loss: 0.0169  Accuracy: 94.468 %\n",
      "[epoch 531]  Loss: 0.0207  Accuracy: 92.640 %\n",
      "[epoch 532]  Loss: 0.0169  Accuracy: 94.318 %\n",
      "[epoch 533]  Loss: 0.0174  Accuracy: 94.040 %\n",
      "[epoch 534]  Loss: 0.0169  Accuracy: 94.432 %\n",
      "[epoch 535]  Loss: 0.0173  Accuracy: 94.124 %\n",
      "[epoch 536]  Loss: 0.0167  Accuracy: 94.490 %\n",
      "[epoch 537]  Loss: 0.0172  Accuracy: 94.168 %\n",
      "[epoch 538]  Loss: 0.0165  Accuracy: 94.476 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 539]  Loss: 0.0173  Accuracy: 94.062 %\n",
      "[epoch 540]  Loss: 0.0182  Accuracy: 93.756 %\n",
      "[epoch 541]  Loss: 0.0161  Accuracy: 94.720 %\n",
      "[epoch 542]  Loss: 0.0159  Accuracy: 94.884 %\n",
      "[epoch 543]  Loss: 0.0154  Accuracy: 95.064 %\n",
      "[epoch 544]  Loss: 0.0172  Accuracy: 94.038 %\n",
      "[epoch 545]  Loss: 0.0165  Accuracy: 94.406 %\n",
      "[epoch 546]  Loss: 0.0185  Accuracy: 93.358 %\n",
      "[epoch 547]  Loss: 0.0182  Accuracy: 93.482 %\n",
      "[epoch 548]  Loss: 0.0160  Accuracy: 94.812 %\n",
      "[epoch 549]  Loss: 0.0149  Accuracy: 95.322 %\n",
      "[epoch 550]  Loss: 0.0152  Accuracy: 95.192 %\n",
      "[epoch 551]  Loss: 0.0164  Accuracy: 94.522 %\n",
      "[epoch 552]  Loss: 0.0165  Accuracy: 94.354 %\n",
      "[epoch 553]  Loss: 0.0158  Accuracy: 94.784 %\n",
      "[epoch 554]  Loss: 0.0169  Accuracy: 94.144 %\n",
      "[epoch 555]  Loss: 0.0183  Accuracy: 93.468 %\n",
      "[epoch 556]  Loss: 0.0185  Accuracy: 93.224 %\n",
      "[epoch 557]  Loss: 0.0191  Accuracy: 93.048 %\n",
      "[epoch 558]  Loss: 0.0156  Accuracy: 94.804 %\n",
      "[epoch 559]  Loss: 0.0140  Accuracy: 95.602 %\n",
      "[epoch 560]  Loss: 0.0139  Accuracy: 95.708 %\n",
      "[epoch 561]  Loss: 0.0136  Accuracy: 95.890 %\n",
      "[epoch 562]  Loss: 0.0129  Accuracy: 96.258 %\n",
      "[epoch 563]  Loss: 0.0137  Accuracy: 95.796 %\n",
      "[epoch 564]  Loss: 0.0143  Accuracy: 95.452 %\n",
      "[epoch 565]  Loss: 0.0189  Accuracy: 93.332 %\n",
      "[epoch 566]  Loss: 0.0225  Accuracy: 91.778 %\n",
      "[epoch 567]  Loss: 0.0168  Accuracy: 94.160 %\n",
      "[epoch 568]  Loss: 0.0147  Accuracy: 95.130 %\n",
      "[epoch 569]  Loss: 0.0141  Accuracy: 95.394 %\n",
      "[epoch 570]  Loss: 0.0143  Accuracy: 95.470 %\n",
      "[epoch 571]  Loss: 0.0137  Accuracy: 95.680 %\n",
      "[epoch 572]  Loss: 0.0158  Accuracy: 94.492 %\n",
      "[epoch 573]  Loss: 0.0158  Accuracy: 94.556 %\n",
      "[epoch 574]  Loss: 0.0140  Accuracy: 95.534 %\n",
      "[epoch 575]  Loss: 0.0142  Accuracy: 95.394 %\n",
      "[epoch 576]  Loss: 0.0150  Accuracy: 94.942 %\n",
      "[epoch 577]  Loss: 0.0140  Accuracy: 95.452 %\n",
      "[epoch 578]  Loss: 0.0127  Accuracy: 96.178 %\n",
      "[epoch 579]  Loss: 0.0134  Accuracy: 95.784 %\n",
      "[epoch 580]  Loss: 0.0129  Accuracy: 96.050 %\n",
      "[epoch 581]  Loss: 0.0147  Accuracy: 95.076 %\n",
      "[epoch 582]  Loss: 0.0166  Accuracy: 94.146 %\n",
      "[epoch 583]  Loss: 0.0140  Accuracy: 95.386 %\n",
      "[epoch 584]  Loss: 0.0139  Accuracy: 95.422 %\n",
      "[epoch 585]  Loss: 0.0144  Accuracy: 95.202 %\n",
      "[epoch 586]  Loss: 0.0127  Accuracy: 96.038 %\n",
      "[epoch 587]  Loss: 0.0135  Accuracy: 95.648 %\n",
      "[epoch 588]  Loss: 0.0133  Accuracy: 95.670 %\n",
      "[epoch 589]  Loss: 0.0123  Accuracy: 96.268 %\n",
      "[epoch 590]  Loss: 0.0158  Accuracy: 94.472 %\n",
      "[epoch 591]  Loss: 0.0187  Accuracy: 92.956 %\n",
      "[epoch 592]  Loss: 0.0144  Accuracy: 95.116 %\n",
      "[epoch 593]  Loss: 0.0133  Accuracy: 95.722 %\n",
      "[epoch 594]  Loss: 0.0219  Accuracy: 92.056 %\n",
      "[epoch 595]  Loss: 0.0190  Accuracy: 92.942 %\n",
      "[epoch 596]  Loss: 0.0141  Accuracy: 95.208 %\n",
      "[epoch 597]  Loss: 0.0126  Accuracy: 96.094 %\n",
      "[epoch 598]  Loss: 0.0117  Accuracy: 96.478 %\n",
      "[epoch 599]  Loss: 0.0120  Accuracy: 96.258 %\n",
      "[epoch 600]  Loss: 0.0120  Accuracy: 96.394 %\n",
      "[epoch 601]  Loss: 0.0126  Accuracy: 95.974 %\n",
      "[epoch 602]  Loss: 0.0114  Accuracy: 96.552 %\n",
      "[epoch 603]  Loss: 0.0120  Accuracy: 96.276 %\n",
      "[epoch 604]  Loss: 0.0125  Accuracy: 96.000 %\n",
      "[epoch 605]  Loss: 0.0122  Accuracy: 96.182 %\n",
      "[epoch 606]  Loss: 0.0126  Accuracy: 95.958 %\n",
      "[epoch 607]  Loss: 0.0133  Accuracy: 95.524 %\n",
      "[epoch 608]  Loss: 0.0118  Accuracy: 96.306 %\n",
      "[epoch 609]  Loss: 0.0143  Accuracy: 94.980 %\n",
      "[epoch 610]  Loss: 0.0156  Accuracy: 94.352 %\n",
      "[epoch 611]  Loss: 0.0146  Accuracy: 94.862 %\n",
      "[epoch 612]  Loss: 0.0176  Accuracy: 93.560 %\n",
      "[epoch 613]  Loss: 0.0140  Accuracy: 95.112 %\n",
      "[epoch 614]  Loss: 0.0110  Accuracy: 96.684 %\n",
      "[epoch 615]  Loss: 0.0106  Accuracy: 96.884 %\n",
      "[epoch 616]  Loss: 0.0104  Accuracy: 96.994 %\n",
      "[epoch 617]  Loss: 0.0099  Accuracy: 97.354 %\n",
      "[epoch 618]  Loss: 0.0112  Accuracy: 96.580 %\n",
      "[epoch 619]  Loss: 0.0118  Accuracy: 96.312 %\n",
      "[epoch 620]  Loss: 0.0153  Accuracy: 94.496 %\n",
      "[epoch 621]  Loss: 0.0177  Accuracy: 93.460 %\n",
      "[epoch 622]  Loss: 0.0120  Accuracy: 96.106 %\n",
      "[epoch 623]  Loss: 0.0113  Accuracy: 96.352 %\n",
      "[epoch 624]  Loss: 0.0101  Accuracy: 97.082 %\n",
      "[epoch 625]  Loss: 0.0102  Accuracy: 97.092 %\n",
      "[epoch 626]  Loss: 0.0117  Accuracy: 96.266 %\n",
      "[epoch 627]  Loss: 0.0115  Accuracy: 96.354 %\n",
      "[epoch 628]  Loss: 0.0116  Accuracy: 96.266 %\n",
      "[epoch 629]  Loss: 0.0111  Accuracy: 96.498 %\n",
      "[epoch 630]  Loss: 0.0130  Accuracy: 95.508 %\n",
      "[epoch 631]  Loss: 0.0125  Accuracy: 95.836 %\n",
      "[epoch 632]  Loss: 0.0128  Accuracy: 95.622 %\n",
      "[epoch 633]  Loss: 0.0109  Accuracy: 96.612 %\n",
      "[epoch 634]  Loss: 0.0121  Accuracy: 95.990 %\n",
      "[epoch 635]  Loss: 0.0146  Accuracy: 94.720 %\n",
      "[epoch 636]  Loss: 0.0148  Accuracy: 94.684 %\n",
      "[epoch 637]  Loss: 0.0122  Accuracy: 95.956 %\n",
      "[epoch 638]  Loss: 0.0094  Accuracy: 97.394 %\n",
      "[epoch 639]  Loss: 0.0105  Accuracy: 96.758 %\n",
      "[epoch 640]  Loss: 0.0217  Accuracy: 92.152 %\n",
      "[epoch 641]  Loss: 0.0150  Accuracy: 94.492 %\n",
      "[epoch 642]  Loss: 0.0105  Accuracy: 96.740 %\n",
      "[epoch 643]  Loss: 0.0088  Accuracy: 97.642 %\n",
      "[epoch 644]  Loss: 0.0090  Accuracy: 97.494 %\n",
      "[epoch 645]  Loss: 0.0104  Accuracy: 96.698 %\n",
      "[epoch 646]  Loss: 0.0105  Accuracy: 96.616 %\n",
      "[epoch 647]  Loss: 0.0099  Accuracy: 96.946 %\n",
      "[epoch 648]  Loss: 0.0100  Accuracy: 96.902 %\n",
      "[epoch 649]  Loss: 0.0110  Accuracy: 96.388 %\n",
      "[epoch 650]  Loss: 0.0100  Accuracy: 96.918 %\n",
      "[epoch 651]  Loss: 0.0091  Accuracy: 97.332 %\n",
      "[epoch 652]  Loss: 0.0091  Accuracy: 97.448 %\n",
      "[epoch 653]  Loss: 0.0091  Accuracy: 97.296 %\n",
      "[epoch 654]  Loss: 0.0095  Accuracy: 97.036 %\n",
      "[epoch 655]  Loss: 0.0120  Accuracy: 95.992 %\n",
      "[epoch 656]  Loss: 0.0137  Accuracy: 94.968 %\n",
      "[epoch 657]  Loss: 0.0143  Accuracy: 94.860 %\n",
      "[epoch 658]  Loss: 0.0105  Accuracy: 96.592 %\n",
      "[epoch 659]  Loss: 0.0091  Accuracy: 97.406 %\n",
      "[epoch 660]  Loss: 0.0115  Accuracy: 96.170 %\n",
      "[epoch 661]  Loss: 0.0104  Accuracy: 96.586 %\n",
      "[epoch 662]  Loss: 0.0137  Accuracy: 94.992 %\n",
      "[epoch 663]  Loss: 0.0114  Accuracy: 96.044 %\n",
      "[epoch 664]  Loss: 0.0078  Accuracy: 97.958 %\n",
      "[epoch 665]  Loss: 0.0081  Accuracy: 97.858 %\n",
      "[epoch 666]  Loss: 0.0096  Accuracy: 97.036 %\n",
      "[epoch 667]  Loss: 0.0106  Accuracy: 96.386 %\n",
      "[epoch 668]  Loss: 0.0087  Accuracy: 97.416 %\n",
      "[epoch 669]  Loss: 0.0107  Accuracy: 96.400 %\n",
      "[epoch 670]  Loss: 0.0110  Accuracy: 96.318 %\n",
      "[epoch 671]  Loss: 0.0105  Accuracy: 96.518 %\n",
      "[epoch 672]  Loss: 0.0103  Accuracy: 96.596 %\n",
      "[epoch 673]  Loss: 0.0093  Accuracy: 97.046 %\n",
      "[epoch 674]  Loss: 0.0145  Accuracy: 94.530 %\n",
      "[epoch 675]  Loss: 0.0148  Accuracy: 94.584 %\n",
      "[epoch 676]  Loss: 0.0114  Accuracy: 96.048 %\n",
      "[epoch 677]  Loss: 0.0091  Accuracy: 97.120 %\n",
      "[epoch 678]  Loss: 0.0092  Accuracy: 97.110 %\n",
      "[epoch 679]  Loss: 0.0081  Accuracy: 97.714 %\n",
      "[epoch 680]  Loss: 0.0073  Accuracy: 98.170 %\n",
      "[epoch 681]  Loss: 0.0070  Accuracy: 98.308 %\n",
      "[epoch 682]  Loss: 0.0067  Accuracy: 98.444 %\n",
      "[epoch 683]  Loss: 0.0070  Accuracy: 98.288 %\n",
      "[epoch 684]  Loss: 0.0088  Accuracy: 97.280 %\n",
      "[epoch 685]  Loss: 0.0113  Accuracy: 96.042 %\n",
      "[epoch 686]  Loss: 0.0122  Accuracy: 95.614 %\n",
      "[epoch 687]  Loss: 0.0128  Accuracy: 95.264 %\n",
      "[epoch 688]  Loss: 0.0093  Accuracy: 96.972 %\n",
      "[epoch 689]  Loss: 0.0116  Accuracy: 96.044 %\n",
      "[epoch 690]  Loss: 0.0150  Accuracy: 94.406 %\n",
      "[epoch 691]  Loss: 0.0103  Accuracy: 96.472 %\n",
      "[epoch 692]  Loss: 0.0092  Accuracy: 97.014 %\n",
      "[epoch 693]  Loss: 0.0087  Accuracy: 97.280 %\n",
      "[epoch 694]  Loss: 0.0078  Accuracy: 97.776 %\n",
      "[epoch 695]  Loss: 0.0123  Accuracy: 95.608 %\n",
      "[epoch 696]  Loss: 0.0116  Accuracy: 95.856 %\n",
      "[epoch 697]  Loss: 0.0075  Accuracy: 97.870 %\n",
      "[epoch 698]  Loss: 0.0063  Accuracy: 98.574 %\n",
      "[epoch 699]  Loss: 0.0064  Accuracy: 98.466 %\n",
      "[epoch 700]  Loss: 0.0066  Accuracy: 98.442 %\n",
      "[epoch 701]  Loss: 0.0097  Accuracy: 96.852 %\n",
      "[epoch 702]  Loss: 0.0151  Accuracy: 94.392 %\n",
      "[epoch 703]  Loss: 0.0091  Accuracy: 96.908 %\n",
      "[epoch 704]  Loss: 0.0130  Accuracy: 95.214 %\n",
      "[epoch 705]  Loss: 0.0096  Accuracy: 96.778 %\n",
      "[epoch 706]  Loss: 0.0070  Accuracy: 98.046 %\n",
      "[epoch 707]  Loss: 0.0079  Accuracy: 97.614 %\n",
      "[epoch 708]  Loss: 0.0078  Accuracy: 97.750 %\n",
      "[epoch 709]  Loss: 0.0065  Accuracy: 98.324 %\n",
      "[epoch 710]  Loss: 0.0063  Accuracy: 98.420 %\n",
      "[epoch 711]  Loss: 0.0066  Accuracy: 98.300 %\n",
      "[epoch 712]  Loss: 0.0068  Accuracy: 98.158 %\n",
      "[epoch 713]  Loss: 0.0059  Accuracy: 98.656 %\n",
      "[epoch 714]  Loss: 0.0091  Accuracy: 97.024 %\n",
      "[epoch 715]  Loss: 0.0150  Accuracy: 94.492 %\n",
      "[epoch 716]  Loss: 0.0196  Accuracy: 92.868 %\n",
      "[epoch 717]  Loss: 0.0107  Accuracy: 96.192 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 718]  Loss: 0.0096  Accuracy: 96.780 %\n",
      "[epoch 719]  Loss: 0.0097  Accuracy: 96.696 %\n",
      "[epoch 720]  Loss: 0.0071  Accuracy: 98.000 %\n",
      "[epoch 721]  Loss: 0.0053  Accuracy: 98.878 %\n",
      "[epoch 722]  Loss: 0.0055  Accuracy: 98.810 %\n",
      "[epoch 723]  Loss: 0.0051  Accuracy: 98.998 %\n",
      "[epoch 724]  Loss: 0.0047  Accuracy: 99.186 %\n",
      "[epoch 725]  Loss: 0.0052  Accuracy: 98.956 %\n",
      "[epoch 726]  Loss: 0.0085  Accuracy: 97.256 %\n",
      "[epoch 727]  Loss: 0.0116  Accuracy: 95.900 %\n",
      "[epoch 728]  Loss: 0.0150  Accuracy: 94.564 %\n",
      "[epoch 729]  Loss: 0.0077  Accuracy: 97.662 %\n",
      "[epoch 730]  Loss: 0.0069  Accuracy: 97.998 %\n",
      "[epoch 731]  Loss: 0.0071  Accuracy: 97.930 %\n",
      "[epoch 732]  Loss: 0.0114  Accuracy: 95.852 %\n",
      "[epoch 733]  Loss: 0.0069  Accuracy: 97.944 %\n",
      "[epoch 734]  Loss: 0.0069  Accuracy: 97.948 %\n",
      "[epoch 735]  Loss: 0.0062  Accuracy: 98.400 %\n",
      "[epoch 736]  Loss: 0.0070  Accuracy: 97.960 %\n",
      "[epoch 737]  Loss: 0.0058  Accuracy: 98.554 %\n",
      "[epoch 738]  Loss: 0.0054  Accuracy: 98.816 %\n",
      "[epoch 739]  Loss: 0.0054  Accuracy: 98.708 %\n",
      "[epoch 740]  Loss: 0.0055  Accuracy: 98.674 %\n",
      "[epoch 741]  Loss: 0.0067  Accuracy: 98.116 %\n",
      "[epoch 742]  Loss: 0.0200  Accuracy: 92.764 %\n",
      "[epoch 743]  Loss: 0.0157  Accuracy: 94.418 %\n",
      "[epoch 744]  Loss: 0.0202  Accuracy: 92.516 %\n",
      "[epoch 745]  Loss: 0.0132  Accuracy: 95.194 %\n",
      "[epoch 746]  Loss: 0.0091  Accuracy: 96.834 %\n",
      "[epoch 747]  Loss: 0.0059  Accuracy: 98.416 %\n",
      "[epoch 748]  Loss: 0.0048  Accuracy: 98.950 %\n",
      "[epoch 749]  Loss: 0.0049  Accuracy: 98.928 %\n",
      "[epoch 750]  Loss: 0.0042  Accuracy: 99.270 %\n",
      "[epoch 751]  Loss: 0.0043  Accuracy: 99.296 %\n",
      "[epoch 752]  Loss: 0.0041  Accuracy: 99.358 %\n",
      "[epoch 753]  Loss: 0.0040  Accuracy: 99.390 %\n",
      "[epoch 754]  Loss: 0.0036  Accuracy: 99.582 %\n",
      "[epoch 755]  Loss: 0.0036  Accuracy: 99.560 %\n",
      "[epoch 756]  Loss: 0.0046  Accuracy: 99.070 %\n",
      "[epoch 757]  Loss: 0.0057  Accuracy: 98.522 %\n",
      "[epoch 758]  Loss: 0.0181  Accuracy: 93.574 %\n",
      "[epoch 759]  Loss: 0.0121  Accuracy: 95.550 %\n",
      "[epoch 760]  Loss: 0.0093  Accuracy: 96.706 %\n",
      "[epoch 761]  Loss: 0.0084  Accuracy: 97.130 %\n",
      "[epoch 762]  Loss: 0.0134  Accuracy: 94.952 %\n",
      "[epoch 763]  Loss: 0.0099  Accuracy: 96.560 %\n",
      "[epoch 764]  Loss: 0.0081  Accuracy: 97.226 %\n",
      "[epoch 765]  Loss: 0.0061  Accuracy: 98.226 %\n",
      "[epoch 766]  Loss: 0.0051  Accuracy: 98.778 %\n",
      "[epoch 767]  Loss: 0.0043  Accuracy: 99.172 %\n",
      "[epoch 768]  Loss: 0.0037  Accuracy: 99.448 %\n",
      "[epoch 769]  Loss: 0.0038  Accuracy: 99.420 %\n",
      "[epoch 770]  Loss: 0.0037  Accuracy: 99.410 %\n",
      "[epoch 771]  Loss: 0.0036  Accuracy: 99.514 %\n",
      "[epoch 772]  Loss: 0.0039  Accuracy: 99.382 %\n",
      "[epoch 773]  Loss: 0.0077  Accuracy: 97.532 %\n",
      "[epoch 774]  Loss: 0.0158  Accuracy: 94.272 %\n",
      "[epoch 775]  Loss: 0.0236  Accuracy: 92.032 %\n",
      "[epoch 776]  Loss: 0.0123  Accuracy: 95.352 %\n",
      "[epoch 777]  Loss: 0.0090  Accuracy: 96.718 %\n",
      "[epoch 778]  Loss: 0.0087  Accuracy: 97.046 %\n",
      "[epoch 779]  Loss: 0.0048  Accuracy: 98.938 %\n",
      "[epoch 780]  Loss: 0.0043  Accuracy: 99.102 %\n",
      "[epoch 781]  Loss: 0.0038  Accuracy: 99.390 %\n",
      "[epoch 782]  Loss: 0.0035  Accuracy: 99.502 %\n",
      "[epoch 783]  Loss: 0.0030  Accuracy: 99.706 %\n",
      "[epoch 784]  Loss: 0.0030  Accuracy: 99.690 %\n",
      "[epoch 785]  Loss: 0.0031  Accuracy: 99.666 %\n",
      "[epoch 786]  Loss: 0.0029  Accuracy: 99.742 %\n",
      "[epoch 787]  Loss: 0.0028  Accuracy: 99.728 %\n",
      "[epoch 788]  Loss: 0.0032  Accuracy: 99.586 %\n",
      "[epoch 789]  Loss: 0.0036  Accuracy: 99.414 %\n",
      "[epoch 790]  Loss: 0.0041  Accuracy: 99.162 %\n",
      "[epoch 791]  Loss: 0.0055  Accuracy: 98.448 %\n",
      "[epoch 792]  Loss: 0.0316  Accuracy: 90.512 %\n",
      "[epoch 793]  Loss: 0.0320  Accuracy: 89.868 %\n",
      "[epoch 794]  Loss: 0.0135  Accuracy: 94.980 %\n",
      "[epoch 795]  Loss: 0.0090  Accuracy: 96.836 %\n",
      "[epoch 796]  Loss: 0.0085  Accuracy: 97.018 %\n",
      "[epoch 797]  Loss: 0.0074  Accuracy: 97.578 %\n",
      "[epoch 798]  Loss: 0.0045  Accuracy: 98.948 %\n",
      "[epoch 799]  Loss: 0.0034  Accuracy: 99.532 %\n",
      "Finished Training! Training process cost 4412.920259 sec\n"
     ]
    }
   ],
   "source": [
    "#ALL THE CODE IN THIS CELL ARE WRITE BY MY SELF#\n",
    "# Start training : set net to train model\n",
    "net.train()\n",
    "\n",
    "# make two arrays for saving matplotlib data\n",
    "train_loss = []\n",
    "train_accu = []\n",
    "accuracy = 0\n",
    "\n",
    "# get TersorBoard writer object\n",
    "writer = SummaryWriter(log_dir='Training')\n",
    "\n",
    "# Training process\n",
    "timestart = time.time()\n",
    "for epoch in range(0,epoch):\n",
    "    \n",
    "    # initialize loss,total,correct\n",
    "    loss_value = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    # do iteration (total number of training images / batch size) times\n",
    "    for i, (inputs, labels) in enumerate(trainingloader, 0):\n",
    "        \n",
    "        # get the input and its label\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # make gradients to 0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward step\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        # compute the loss\n",
    "        l = loss(outputs, labels)\n",
    "        \n",
    "        # backward step\n",
    "        l.backward()\n",
    "        \n",
    "        # optimize step\n",
    "        optimizer.step()\n",
    "\n",
    "        # compute loss\n",
    "        loss_value += l.item()\n",
    "        \n",
    "        # save to array in oder to output loss image at the end\n",
    "        train_loss.append(l.item())\n",
    "        \n",
    "        # write to tensorboard file\n",
    "        writer.add_scalars('/GroupB/Loss', {'B2': l.item()}, epoch)\n",
    "\n",
    "        \n",
    "        # compute accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total = total + labels.size(0)\n",
    "        correct = correct + (predicted == labels).sum().item()\n",
    "        accuracy = correct / total * 100.0\n",
    "        \n",
    "        # save to array in oder to output accuracy image at the end\n",
    "        train_accu.append(accuracy)\n",
    "        \n",
    "        # write to tensorboard file\n",
    "        writer.add_scalars('/GroupB/Accuracy', {'B2': accuracy}, epoch)\n",
    "        \n",
    "\n",
    "    loss_epoch = loss_value / (500000/batch_size)\n",
    "    # output the result of this epoch \n",
    "    print('[epoch %d]  Loss: %.4f  Accuracy: %.3f %%' %(epoch, loss_epoch , accuracy))\n",
    "\n",
    "    \n",
    "# Finish Training\n",
    "result_training_accuracy = accuracy\n",
    "result_training_time = (time.time()-timestart)\n",
    "print('Finished Training! Training process cost %3f sec' %result_training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8fc7d4e710>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the loss\n",
    "plt.plot(np.arange(len(train_loss)), train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8fc7e96780>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the accuracy\n",
    "plt.plot(np.arange(len(train_accu)), train_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the TensorBoard output stream\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the network is 99.658 %\n"
     ]
    }
   ],
   "source": [
    "#ALL THE CODE IN THIS CELL ARE WRITE BY MY SELF#\n",
    "# Start testing : set net to train model\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# deactivate the autograd engine\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # do testing iteration\n",
    "    #for data in testingloader:\n",
    "        \n",
    "        # get the input and its label\n",
    "        #images, labels = data\n",
    "        #images, labels = images.to(device), labels.to(device)\n",
    "    for i, (inputs, labels) in enumerate(trainingloader, 0):\n",
    "        \n",
    "        # get the input and its label\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward step\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        # compute accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total = total + labels.size(0)\n",
    "        correct = correct + (predicted == labels).sum().item()\n",
    "\n",
    "# Finish Testing\n",
    "result_testing_accuracy = correct / total * 100.0\n",
    "print('The accuracy of the network is %.3f %%' % result_testing_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Configuration]\n",
      "learning rate = 0.001000\n",
      "batch size = 1000\n",
      "epoch = 799\n",
      "\n",
      "[Expirement Result]\n",
      "training time = 4412.920259 sec\n",
      "training accuracy = 99.532 %\n",
      "testing accuracy =  99.658 %\n"
     ]
    }
   ],
   "source": [
    "print('[Configuration]')\n",
    "print('learning rate = %3f' % learning_rate )\n",
    "print('batch size = %d' % batch_size )\n",
    "print('epoch = %d' % epoch )\n",
    "print('')\n",
    "print('[Expirement Result]')\n",
    "print('training time = %3f sec' % result_training_time )\n",
    "print('training accuracy = %.3f %%' %result_training_accuracy )\n",
    "print('testing accuracy =  %.3f %%' % (100.0 * correct / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>click <a href='../Main.ipynb'>here</a> to return to Main.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
