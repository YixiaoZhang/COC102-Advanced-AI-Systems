{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18COC102 -  Advanced Artificial Intelligence Systems - Coursework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style='color:red'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Experiment B1</p>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n",
      "CPython 3.6.7\n",
      "IPython 7.2.0\n",
      "\n",
      "numpy 1.15.4\n",
      "torch 0.4.1\n",
      "torchvision 0.2.1\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%watermark -v -p numpy,torch,torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import os\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement the network by myself#\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1  = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2  = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.fc1   = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate=0.001\n",
    "batch_size=100\n",
    "epoch=800\n",
    "workers=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set GPU \n",
    "device = torch.device(\"cuda:0\")\n",
    "# set Netwrok\n",
    "net = LeNet()\n",
    "net = net.to(device)\n",
    "# set optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "# set loss function\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# dataloader refer source [2]\n",
    "\n",
    "# load training dataset\n",
    "trainingset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, \n",
    "                                           transform=transforms.ToTensor())\n",
    "\n",
    "trainingloader = torch.utils.data.DataLoader(trainingset, batch_size=batch_size,shuffle=True, \n",
    "                                             num_workers=workers)\n",
    "# load testing dataset\n",
    "testingset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transforms.ToTensor())\n",
    "\n",
    "testingloader = torch.utils.data.DataLoader(testingset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=workers)\n",
    "\n",
    "#end of source [2]\n",
    "#source [2] https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0]  Loss: 0.1766  Accuracy: 34.024 %\n",
      "[epoch 1]  Loss: 0.1489  Accuracy: 45.422 %\n",
      "[epoch 2]  Loss: 0.1388  Accuracy: 49.516 %\n",
      "[epoch 3]  Loss: 0.1308  Accuracy: 52.826 %\n",
      "[epoch 4]  Loss: 0.1253  Accuracy: 54.788 %\n",
      "[epoch 5]  Loss: 0.1203  Accuracy: 56.904 %\n",
      "[epoch 6]  Loss: 0.1164  Accuracy: 58.220 %\n",
      "[epoch 7]  Loss: 0.1133  Accuracy: 59.576 %\n",
      "[epoch 8]  Loss: 0.1097  Accuracy: 60.782 %\n",
      "[epoch 9]  Loss: 0.1064  Accuracy: 62.024 %\n",
      "[epoch 10]  Loss: 0.1041  Accuracy: 63.164 %\n",
      "[epoch 11]  Loss: 0.1014  Accuracy: 64.118 %\n",
      "[epoch 12]  Loss: 0.0985  Accuracy: 65.096 %\n",
      "[epoch 13]  Loss: 0.0965  Accuracy: 65.838 %\n",
      "[epoch 14]  Loss: 0.0942  Accuracy: 66.602 %\n",
      "[epoch 15]  Loss: 0.0925  Accuracy: 67.384 %\n",
      "[epoch 16]  Loss: 0.0902  Accuracy: 68.220 %\n",
      "[epoch 17]  Loss: 0.0882  Accuracy: 69.098 %\n",
      "[epoch 18]  Loss: 0.0862  Accuracy: 69.602 %\n",
      "[epoch 19]  Loss: 0.0850  Accuracy: 70.080 %\n",
      "[epoch 20]  Loss: 0.0834  Accuracy: 70.386 %\n",
      "[epoch 21]  Loss: 0.0816  Accuracy: 71.332 %\n",
      "[epoch 22]  Loss: 0.0802  Accuracy: 71.622 %\n",
      "[epoch 23]  Loss: 0.0784  Accuracy: 72.478 %\n",
      "[epoch 24]  Loss: 0.0783  Accuracy: 72.462 %\n",
      "[epoch 25]  Loss: 0.0767  Accuracy: 72.834 %\n",
      "[epoch 26]  Loss: 0.0749  Accuracy: 73.526 %\n",
      "[epoch 27]  Loss: 0.0735  Accuracy: 74.234 %\n",
      "[epoch 28]  Loss: 0.0730  Accuracy: 74.174 %\n",
      "[epoch 29]  Loss: 0.0714  Accuracy: 74.956 %\n",
      "[epoch 30]  Loss: 0.0703  Accuracy: 75.290 %\n",
      "[epoch 31]  Loss: 0.0695  Accuracy: 75.504 %\n",
      "[epoch 32]  Loss: 0.0682  Accuracy: 76.006 %\n",
      "[epoch 33]  Loss: 0.0675  Accuracy: 76.168 %\n",
      "[epoch 34]  Loss: 0.0666  Accuracy: 76.452 %\n",
      "[epoch 35]  Loss: 0.0655  Accuracy: 76.810 %\n",
      "[epoch 36]  Loss: 0.0644  Accuracy: 77.242 %\n",
      "[epoch 37]  Loss: 0.0638  Accuracy: 77.428 %\n",
      "[epoch 38]  Loss: 0.0636  Accuracy: 77.502 %\n",
      "[epoch 39]  Loss: 0.0620  Accuracy: 78.132 %\n",
      "[epoch 40]  Loss: 0.0615  Accuracy: 78.318 %\n",
      "[epoch 41]  Loss: 0.0601  Accuracy: 78.886 %\n",
      "[epoch 42]  Loss: 0.0598  Accuracy: 78.882 %\n",
      "[epoch 43]  Loss: 0.0585  Accuracy: 79.430 %\n",
      "[epoch 44]  Loss: 0.0580  Accuracy: 79.476 %\n",
      "[epoch 45]  Loss: 0.0575  Accuracy: 79.686 %\n",
      "[epoch 46]  Loss: 0.0566  Accuracy: 79.990 %\n",
      "[epoch 47]  Loss: 0.0559  Accuracy: 80.178 %\n",
      "[epoch 48]  Loss: 0.0552  Accuracy: 80.584 %\n",
      "[epoch 49]  Loss: 0.0547  Accuracy: 80.742 %\n",
      "[epoch 50]  Loss: 0.0539  Accuracy: 81.040 %\n",
      "[epoch 51]  Loss: 0.0528  Accuracy: 81.460 %\n",
      "[epoch 52]  Loss: 0.0529  Accuracy: 81.232 %\n",
      "[epoch 53]  Loss: 0.0518  Accuracy: 81.444 %\n",
      "[epoch 54]  Loss: 0.0516  Accuracy: 81.730 %\n",
      "[epoch 55]  Loss: 0.0514  Accuracy: 81.862 %\n",
      "[epoch 56]  Loss: 0.0499  Accuracy: 82.352 %\n",
      "[epoch 57]  Loss: 0.0494  Accuracy: 82.498 %\n",
      "[epoch 58]  Loss: 0.0488  Accuracy: 82.608 %\n",
      "[epoch 59]  Loss: 0.0488  Accuracy: 82.686 %\n",
      "[epoch 60]  Loss: 0.0478  Accuracy: 82.978 %\n",
      "[epoch 61]  Loss: 0.0473  Accuracy: 83.278 %\n",
      "[epoch 62]  Loss: 0.0473  Accuracy: 83.248 %\n",
      "[epoch 63]  Loss: 0.0458  Accuracy: 83.832 %\n",
      "[epoch 64]  Loss: 0.0463  Accuracy: 83.502 %\n",
      "[epoch 65]  Loss: 0.0446  Accuracy: 84.098 %\n",
      "[epoch 66]  Loss: 0.0450  Accuracy: 83.860 %\n",
      "[epoch 67]  Loss: 0.0441  Accuracy: 84.074 %\n",
      "[epoch 68]  Loss: 0.0436  Accuracy: 84.274 %\n",
      "[epoch 69]  Loss: 0.0441  Accuracy: 84.158 %\n",
      "[epoch 70]  Loss: 0.0428  Accuracy: 84.670 %\n",
      "[epoch 71]  Loss: 0.0428  Accuracy: 84.612 %\n",
      "[epoch 72]  Loss: 0.0415  Accuracy: 85.054 %\n",
      "[epoch 73]  Loss: 0.0412  Accuracy: 85.188 %\n",
      "[epoch 74]  Loss: 0.0412  Accuracy: 85.190 %\n",
      "[epoch 75]  Loss: 0.0406  Accuracy: 85.394 %\n",
      "[epoch 76]  Loss: 0.0400  Accuracy: 85.648 %\n",
      "[epoch 77]  Loss: 0.0399  Accuracy: 85.622 %\n",
      "[epoch 78]  Loss: 0.0387  Accuracy: 86.178 %\n",
      "[epoch 79]  Loss: 0.0388  Accuracy: 86.028 %\n",
      "[epoch 80]  Loss: 0.0385  Accuracy: 86.100 %\n",
      "[epoch 81]  Loss: 0.0380  Accuracy: 86.348 %\n",
      "[epoch 82]  Loss: 0.0376  Accuracy: 86.498 %\n",
      "[epoch 83]  Loss: 0.0370  Accuracy: 86.724 %\n",
      "[epoch 84]  Loss: 0.0369  Accuracy: 86.632 %\n",
      "[epoch 85]  Loss: 0.0366  Accuracy: 86.734 %\n",
      "[epoch 86]  Loss: 0.0371  Accuracy: 86.588 %\n",
      "[epoch 87]  Loss: 0.0355  Accuracy: 87.280 %\n",
      "[epoch 88]  Loss: 0.0347  Accuracy: 87.486 %\n",
      "[epoch 89]  Loss: 0.0360  Accuracy: 87.046 %\n",
      "[epoch 90]  Loss: 0.0350  Accuracy: 87.264 %\n",
      "[epoch 91]  Loss: 0.0347  Accuracy: 87.546 %\n",
      "[epoch 92]  Loss: 0.0340  Accuracy: 87.758 %\n",
      "[epoch 93]  Loss: 0.0346  Accuracy: 87.342 %\n",
      "[epoch 94]  Loss: 0.0336  Accuracy: 87.780 %\n",
      "[epoch 95]  Loss: 0.0326  Accuracy: 88.254 %\n",
      "[epoch 96]  Loss: 0.0329  Accuracy: 88.054 %\n",
      "[epoch 97]  Loss: 0.0326  Accuracy: 88.118 %\n",
      "[epoch 98]  Loss: 0.0326  Accuracy: 88.170 %\n",
      "[epoch 99]  Loss: 0.0319  Accuracy: 88.368 %\n",
      "[epoch 100]  Loss: 0.0326  Accuracy: 88.170 %\n",
      "[epoch 101]  Loss: 0.0313  Accuracy: 88.612 %\n",
      "[epoch 102]  Loss: 0.0311  Accuracy: 88.606 %\n",
      "[epoch 103]  Loss: 0.0305  Accuracy: 89.118 %\n",
      "[epoch 104]  Loss: 0.0314  Accuracy: 88.572 %\n",
      "[epoch 105]  Loss: 0.0318  Accuracy: 88.478 %\n",
      "[epoch 106]  Loss: 0.0309  Accuracy: 88.770 %\n",
      "[epoch 107]  Loss: 0.0296  Accuracy: 89.184 %\n",
      "[epoch 108]  Loss: 0.0299  Accuracy: 89.042 %\n",
      "[epoch 109]  Loss: 0.0300  Accuracy: 88.920 %\n",
      "[epoch 110]  Loss: 0.0287  Accuracy: 89.640 %\n",
      "[epoch 111]  Loss: 0.0296  Accuracy: 89.186 %\n",
      "[epoch 112]  Loss: 0.0291  Accuracy: 89.484 %\n",
      "[epoch 113]  Loss: 0.0296  Accuracy: 89.228 %\n",
      "[epoch 114]  Loss: 0.0285  Accuracy: 89.552 %\n",
      "[epoch 115]  Loss: 0.0284  Accuracy: 89.694 %\n",
      "[epoch 116]  Loss: 0.0282  Accuracy: 89.826 %\n",
      "[epoch 117]  Loss: 0.0276  Accuracy: 89.898 %\n",
      "[epoch 118]  Loss: 0.0271  Accuracy: 90.098 %\n",
      "[epoch 119]  Loss: 0.0277  Accuracy: 89.960 %\n",
      "[epoch 120]  Loss: 0.0264  Accuracy: 90.506 %\n",
      "[epoch 121]  Loss: 0.0286  Accuracy: 89.490 %\n",
      "[epoch 122]  Loss: 0.0266  Accuracy: 90.252 %\n",
      "[epoch 123]  Loss: 0.0266  Accuracy: 90.288 %\n",
      "[epoch 124]  Loss: 0.0261  Accuracy: 90.454 %\n",
      "[epoch 125]  Loss: 0.0272  Accuracy: 90.054 %\n",
      "[epoch 126]  Loss: 0.0257  Accuracy: 90.656 %\n",
      "[epoch 127]  Loss: 0.0260  Accuracy: 90.516 %\n",
      "[epoch 128]  Loss: 0.0258  Accuracy: 90.492 %\n",
      "[epoch 129]  Loss: 0.0259  Accuracy: 90.512 %\n",
      "[epoch 130]  Loss: 0.0253  Accuracy: 90.704 %\n",
      "[epoch 131]  Loss: 0.0247  Accuracy: 91.072 %\n",
      "[epoch 132]  Loss: 0.0244  Accuracy: 91.200 %\n",
      "[epoch 133]  Loss: 0.0260  Accuracy: 90.522 %\n",
      "[epoch 134]  Loss: 0.0259  Accuracy: 90.468 %\n",
      "[epoch 135]  Loss: 0.0240  Accuracy: 91.398 %\n",
      "[epoch 136]  Loss: 0.0247  Accuracy: 90.938 %\n",
      "[epoch 137]  Loss: 0.0242  Accuracy: 91.102 %\n",
      "[epoch 138]  Loss: 0.0238  Accuracy: 91.322 %\n",
      "[epoch 139]  Loss: 0.0237  Accuracy: 91.336 %\n",
      "[epoch 140]  Loss: 0.0249  Accuracy: 90.844 %\n",
      "[epoch 141]  Loss: 0.0228  Accuracy: 91.674 %\n",
      "[epoch 142]  Loss: 0.0227  Accuracy: 91.698 %\n",
      "[epoch 143]  Loss: 0.0247  Accuracy: 90.822 %\n",
      "[epoch 144]  Loss: 0.0234  Accuracy: 91.396 %\n",
      "[epoch 145]  Loss: 0.0217  Accuracy: 92.082 %\n",
      "[epoch 146]  Loss: 0.0230  Accuracy: 91.442 %\n",
      "[epoch 147]  Loss: 0.0222  Accuracy: 91.818 %\n",
      "[epoch 148]  Loss: 0.0235  Accuracy: 91.292 %\n",
      "[epoch 149]  Loss: 0.0212  Accuracy: 92.286 %\n",
      "[epoch 150]  Loss: 0.0230  Accuracy: 91.678 %\n",
      "[epoch 151]  Loss: 0.0226  Accuracy: 91.658 %\n",
      "[epoch 152]  Loss: 0.0221  Accuracy: 91.966 %\n",
      "[epoch 153]  Loss: 0.0200  Accuracy: 92.658 %\n",
      "[epoch 154]  Loss: 0.0226  Accuracy: 91.730 %\n",
      "[epoch 155]  Loss: 0.0225  Accuracy: 91.616 %\n",
      "[epoch 156]  Loss: 0.0213  Accuracy: 92.182 %\n",
      "[epoch 157]  Loss: 0.0224  Accuracy: 91.882 %\n",
      "[epoch 158]  Loss: 0.0205  Accuracy: 92.464 %\n",
      "[epoch 159]  Loss: 0.0222  Accuracy: 91.874 %\n",
      "[epoch 160]  Loss: 0.0203  Accuracy: 92.548 %\n",
      "[epoch 161]  Loss: 0.0210  Accuracy: 92.512 %\n",
      "[epoch 162]  Loss: 0.0201  Accuracy: 92.584 %\n",
      "[epoch 163]  Loss: 0.0228  Accuracy: 91.586 %\n",
      "[epoch 164]  Loss: 0.0209  Accuracy: 92.294 %\n",
      "[epoch 165]  Loss: 0.0195  Accuracy: 92.846 %\n",
      "[epoch 166]  Loss: 0.0199  Accuracy: 92.786 %\n",
      "[epoch 167]  Loss: 0.0212  Accuracy: 92.226 %\n",
      "[epoch 168]  Loss: 0.0195  Accuracy: 92.854 %\n",
      "[epoch 169]  Loss: 0.0195  Accuracy: 92.760 %\n",
      "[epoch 170]  Loss: 0.0216  Accuracy: 92.032 %\n",
      "[epoch 171]  Loss: 0.0207  Accuracy: 92.558 %\n",
      "[epoch 172]  Loss: 0.0189  Accuracy: 92.980 %\n",
      "[epoch 173]  Loss: 0.0202  Accuracy: 92.536 %\n",
      "[epoch 174]  Loss: 0.0184  Accuracy: 93.226 %\n",
      "[epoch 175]  Loss: 0.0201  Accuracy: 92.576 %\n",
      "[epoch 176]  Loss: 0.0216  Accuracy: 92.108 %\n",
      "[epoch 177]  Loss: 0.0188  Accuracy: 93.030 %\n",
      "[epoch 178]  Loss: 0.0193  Accuracy: 92.928 %\n",
      "[epoch 179]  Loss: 0.0203  Accuracy: 92.646 %\n",
      "[epoch 180]  Loss: 0.0198  Accuracy: 92.656 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 181]  Loss: 0.0178  Accuracy: 93.448 %\n",
      "[epoch 182]  Loss: 0.0196  Accuracy: 92.888 %\n",
      "[epoch 183]  Loss: 0.0186  Accuracy: 93.120 %\n",
      "[epoch 184]  Loss: 0.0176  Accuracy: 93.610 %\n",
      "[epoch 185]  Loss: 0.0184  Accuracy: 93.240 %\n",
      "[epoch 186]  Loss: 0.0187  Accuracy: 93.218 %\n",
      "[epoch 187]  Loss: 0.0183  Accuracy: 93.176 %\n",
      "[epoch 188]  Loss: 0.0196  Accuracy: 92.694 %\n",
      "[epoch 189]  Loss: 0.0182  Accuracy: 93.298 %\n",
      "[epoch 190]  Loss: 0.0185  Accuracy: 93.278 %\n",
      "[epoch 191]  Loss: 0.0168  Accuracy: 93.750 %\n",
      "[epoch 192]  Loss: 0.0181  Accuracy: 93.396 %\n",
      "[epoch 193]  Loss: 0.0182  Accuracy: 93.236 %\n",
      "[epoch 194]  Loss: 0.0173  Accuracy: 93.612 %\n",
      "[epoch 195]  Loss: 0.0185  Accuracy: 93.178 %\n",
      "[epoch 196]  Loss: 0.0172  Accuracy: 93.788 %\n",
      "[epoch 197]  Loss: 0.0171  Accuracy: 93.924 %\n",
      "[epoch 198]  Loss: 0.0178  Accuracy: 93.510 %\n",
      "[epoch 199]  Loss: 0.0180  Accuracy: 93.420 %\n",
      "[epoch 200]  Loss: 0.0170  Accuracy: 93.786 %\n",
      "[epoch 201]  Loss: 0.0178  Accuracy: 93.560 %\n",
      "[epoch 202]  Loss: 0.0177  Accuracy: 93.446 %\n",
      "[epoch 203]  Loss: 0.0177  Accuracy: 93.690 %\n",
      "[epoch 204]  Loss: 0.0174  Accuracy: 93.542 %\n",
      "[epoch 205]  Loss: 0.0175  Accuracy: 93.680 %\n",
      "[epoch 206]  Loss: 0.0169  Accuracy: 93.940 %\n",
      "[epoch 207]  Loss: 0.0161  Accuracy: 93.978 %\n",
      "[epoch 208]  Loss: 0.0165  Accuracy: 94.004 %\n",
      "[epoch 209]  Loss: 0.0170  Accuracy: 93.770 %\n",
      "[epoch 210]  Loss: 0.0163  Accuracy: 94.030 %\n",
      "[epoch 211]  Loss: 0.0177  Accuracy: 93.652 %\n",
      "[epoch 212]  Loss: 0.0179  Accuracy: 93.418 %\n",
      "[epoch 213]  Loss: 0.0141  Accuracy: 94.732 %\n",
      "[epoch 214]  Loss: 0.0172  Accuracy: 93.770 %\n",
      "[epoch 215]  Loss: 0.0174  Accuracy: 93.666 %\n",
      "[epoch 216]  Loss: 0.0159  Accuracy: 94.154 %\n",
      "[epoch 217]  Loss: 0.0174  Accuracy: 93.700 %\n",
      "[epoch 218]  Loss: 0.0169  Accuracy: 93.768 %\n",
      "[epoch 219]  Loss: 0.0164  Accuracy: 93.970 %\n",
      "[epoch 220]  Loss: 0.0138  Accuracy: 94.930 %\n",
      "[epoch 221]  Loss: 0.0161  Accuracy: 93.986 %\n",
      "[epoch 222]  Loss: 0.0173  Accuracy: 93.630 %\n",
      "[epoch 223]  Loss: 0.0151  Accuracy: 94.440 %\n",
      "[epoch 224]  Loss: 0.0178  Accuracy: 93.562 %\n",
      "[epoch 225]  Loss: 0.0157  Accuracy: 94.268 %\n",
      "[epoch 226]  Loss: 0.0151  Accuracy: 94.396 %\n",
      "[epoch 227]  Loss: 0.0171  Accuracy: 93.884 %\n",
      "[epoch 228]  Loss: 0.0168  Accuracy: 93.820 %\n",
      "[epoch 229]  Loss: 0.0137  Accuracy: 94.976 %\n",
      "[epoch 230]  Loss: 0.0157  Accuracy: 94.286 %\n",
      "[epoch 231]  Loss: 0.0188  Accuracy: 93.210 %\n",
      "[epoch 232]  Loss: 0.0142  Accuracy: 94.824 %\n",
      "[epoch 233]  Loss: 0.0157  Accuracy: 94.226 %\n",
      "[epoch 234]  Loss: 0.0152  Accuracy: 94.422 %\n",
      "[epoch 235]  Loss: 0.0175  Accuracy: 93.676 %\n",
      "[epoch 236]  Loss: 0.0150  Accuracy: 94.548 %\n",
      "[epoch 237]  Loss: 0.0160  Accuracy: 94.088 %\n",
      "[epoch 238]  Loss: 0.0157  Accuracy: 94.172 %\n",
      "[epoch 239]  Loss: 0.0147  Accuracy: 94.534 %\n",
      "[epoch 240]  Loss: 0.0157  Accuracy: 94.194 %\n",
      "[epoch 241]  Loss: 0.0136  Accuracy: 95.040 %\n",
      "[epoch 242]  Loss: 0.0155  Accuracy: 94.490 %\n",
      "[epoch 243]  Loss: 0.0164  Accuracy: 94.094 %\n",
      "[epoch 244]  Loss: 0.0140  Accuracy: 94.836 %\n",
      "[epoch 245]  Loss: 0.0163  Accuracy: 94.136 %\n",
      "[epoch 246]  Loss: 0.0142  Accuracy: 94.728 %\n",
      "[epoch 247]  Loss: 0.0153  Accuracy: 94.534 %\n",
      "[epoch 248]  Loss: 0.0157  Accuracy: 94.326 %\n",
      "[epoch 249]  Loss: 0.0166  Accuracy: 94.042 %\n",
      "[epoch 250]  Loss: 0.0150  Accuracy: 94.580 %\n",
      "[epoch 251]  Loss: 0.0150  Accuracy: 94.592 %\n",
      "[epoch 252]  Loss: 0.0143  Accuracy: 94.798 %\n",
      "[epoch 253]  Loss: 0.0138  Accuracy: 95.000 %\n",
      "[epoch 254]  Loss: 0.0145  Accuracy: 94.684 %\n",
      "[epoch 255]  Loss: 0.0144  Accuracy: 94.754 %\n",
      "[epoch 256]  Loss: 0.0163  Accuracy: 94.128 %\n",
      "[epoch 257]  Loss: 0.0144  Accuracy: 94.818 %\n",
      "[epoch 258]  Loss: 0.0128  Accuracy: 95.390 %\n",
      "[epoch 259]  Loss: 0.0152  Accuracy: 94.580 %\n",
      "[epoch 260]  Loss: 0.0159  Accuracy: 94.254 %\n",
      "[epoch 261]  Loss: 0.0142  Accuracy: 94.946 %\n",
      "[epoch 262]  Loss: 0.0141  Accuracy: 94.974 %\n",
      "[epoch 263]  Loss: 0.0144  Accuracy: 94.798 %\n",
      "[epoch 264]  Loss: 0.0136  Accuracy: 95.026 %\n",
      "[epoch 265]  Loss: 0.0132  Accuracy: 95.216 %\n",
      "[epoch 266]  Loss: 0.0153  Accuracy: 94.440 %\n",
      "[epoch 267]  Loss: 0.0149  Accuracy: 94.650 %\n",
      "[epoch 268]  Loss: 0.0132  Accuracy: 95.240 %\n",
      "[epoch 269]  Loss: 0.0142  Accuracy: 94.910 %\n",
      "[epoch 270]  Loss: 0.0151  Accuracy: 94.524 %\n",
      "[epoch 271]  Loss: 0.0140  Accuracy: 94.916 %\n",
      "[epoch 272]  Loss: 0.0112  Accuracy: 95.942 %\n",
      "[epoch 273]  Loss: 0.0157  Accuracy: 94.394 %\n",
      "[epoch 274]  Loss: 0.0152  Accuracy: 94.662 %\n",
      "[epoch 275]  Loss: 0.0158  Accuracy: 94.404 %\n",
      "[epoch 276]  Loss: 0.0117  Accuracy: 95.816 %\n",
      "[epoch 277]  Loss: 0.0115  Accuracy: 95.790 %\n",
      "[epoch 278]  Loss: 0.0179  Accuracy: 93.702 %\n",
      "[epoch 279]  Loss: 0.0135  Accuracy: 95.094 %\n",
      "[epoch 280]  Loss: 0.0139  Accuracy: 94.888 %\n",
      "[epoch 281]  Loss: 0.0124  Accuracy: 95.570 %\n",
      "[epoch 282]  Loss: 0.0144  Accuracy: 94.758 %\n",
      "[epoch 283]  Loss: 0.0143  Accuracy: 95.048 %\n",
      "[epoch 284]  Loss: 0.0115  Accuracy: 95.858 %\n",
      "[epoch 285]  Loss: 0.0147  Accuracy: 94.766 %\n",
      "[epoch 286]  Loss: 0.0140  Accuracy: 94.986 %\n",
      "[epoch 287]  Loss: 0.0148  Accuracy: 94.774 %\n",
      "[epoch 288]  Loss: 0.0109  Accuracy: 96.068 %\n",
      "[epoch 289]  Loss: 0.0147  Accuracy: 94.820 %\n",
      "[epoch 290]  Loss: 0.0163  Accuracy: 94.288 %\n",
      "[epoch 291]  Loss: 0.0127  Accuracy: 95.368 %\n",
      "[epoch 292]  Loss: 0.0124  Accuracy: 95.620 %\n",
      "[epoch 293]  Loss: 0.0137  Accuracy: 94.996 %\n",
      "[epoch 294]  Loss: 0.0124  Accuracy: 95.652 %\n",
      "[epoch 295]  Loss: 0.0139  Accuracy: 94.832 %\n",
      "[epoch 296]  Loss: 0.0140  Accuracy: 95.002 %\n",
      "[epoch 297]  Loss: 0.0121  Accuracy: 95.596 %\n",
      "[epoch 298]  Loss: 0.0124  Accuracy: 95.536 %\n",
      "[epoch 299]  Loss: 0.0153  Accuracy: 94.510 %\n",
      "[epoch 300]  Loss: 0.0124  Accuracy: 95.460 %\n",
      "[epoch 301]  Loss: 0.0122  Accuracy: 95.596 %\n",
      "[epoch 302]  Loss: 0.0136  Accuracy: 95.142 %\n",
      "[epoch 303]  Loss: 0.0147  Accuracy: 94.682 %\n",
      "[epoch 304]  Loss: 0.0129  Accuracy: 95.374 %\n",
      "[epoch 305]  Loss: 0.0121  Accuracy: 95.648 %\n",
      "[epoch 306]  Loss: 0.0148  Accuracy: 94.816 %\n",
      "[epoch 307]  Loss: 0.0110  Accuracy: 96.054 %\n",
      "[epoch 308]  Loss: 0.0129  Accuracy: 95.384 %\n",
      "[epoch 309]  Loss: 0.0131  Accuracy: 95.364 %\n",
      "[epoch 310]  Loss: 0.0136  Accuracy: 95.072 %\n",
      "[epoch 311]  Loss: 0.0145  Accuracy: 94.864 %\n",
      "[epoch 312]  Loss: 0.0102  Accuracy: 96.340 %\n",
      "[epoch 313]  Loss: 0.0149  Accuracy: 94.742 %\n",
      "[epoch 314]  Loss: 0.0145  Accuracy: 94.916 %\n",
      "[epoch 315]  Loss: 0.0091  Accuracy: 96.724 %\n",
      "[epoch 316]  Loss: 0.0139  Accuracy: 95.222 %\n",
      "[epoch 317]  Loss: 0.0152  Accuracy: 94.682 %\n",
      "[epoch 318]  Loss: 0.0107  Accuracy: 96.112 %\n",
      "[epoch 319]  Loss: 0.0128  Accuracy: 95.382 %\n",
      "[epoch 320]  Loss: 0.0145  Accuracy: 94.906 %\n",
      "[epoch 321]  Loss: 0.0124  Accuracy: 95.612 %\n",
      "[epoch 322]  Loss: 0.0127  Accuracy: 95.508 %\n",
      "[epoch 323]  Loss: 0.0115  Accuracy: 95.912 %\n",
      "[epoch 324]  Loss: 0.0133  Accuracy: 95.364 %\n",
      "[epoch 325]  Loss: 0.0145  Accuracy: 94.964 %\n",
      "[epoch 326]  Loss: 0.0104  Accuracy: 96.334 %\n",
      "[epoch 327]  Loss: 0.0149  Accuracy: 94.844 %\n",
      "[epoch 328]  Loss: 0.0113  Accuracy: 95.914 %\n",
      "[epoch 329]  Loss: 0.0133  Accuracy: 95.304 %\n",
      "[epoch 330]  Loss: 0.0106  Accuracy: 96.198 %\n",
      "[epoch 331]  Loss: 0.0135  Accuracy: 95.258 %\n",
      "[epoch 332]  Loss: 0.0133  Accuracy: 95.316 %\n",
      "[epoch 333]  Loss: 0.0117  Accuracy: 95.870 %\n",
      "[epoch 334]  Loss: 0.0139  Accuracy: 95.130 %\n",
      "[epoch 335]  Loss: 0.0122  Accuracy: 95.664 %\n",
      "[epoch 336]  Loss: 0.0090  Accuracy: 96.728 %\n",
      "[epoch 337]  Loss: 0.0138  Accuracy: 95.226 %\n",
      "[epoch 338]  Loss: 0.0159  Accuracy: 94.564 %\n",
      "[epoch 339]  Loss: 0.0107  Accuracy: 96.134 %\n",
      "[epoch 340]  Loss: 0.0094  Accuracy: 96.598 %\n",
      "[epoch 341]  Loss: 0.0133  Accuracy: 95.406 %\n",
      "[epoch 342]  Loss: 0.0136  Accuracy: 95.188 %\n",
      "[epoch 343]  Loss: 0.0145  Accuracy: 94.978 %\n",
      "[epoch 344]  Loss: 0.0109  Accuracy: 96.060 %\n",
      "[epoch 345]  Loss: 0.0105  Accuracy: 96.164 %\n",
      "[epoch 346]  Loss: 0.0130  Accuracy: 95.388 %\n",
      "[epoch 347]  Loss: 0.0140  Accuracy: 95.042 %\n",
      "[epoch 348]  Loss: 0.0097  Accuracy: 96.530 %\n",
      "[epoch 349]  Loss: 0.0104  Accuracy: 96.312 %\n",
      "[epoch 350]  Loss: 0.0124  Accuracy: 95.608 %\n",
      "[epoch 351]  Loss: 0.0141  Accuracy: 95.102 %\n",
      "[epoch 352]  Loss: 0.0119  Accuracy: 95.736 %\n",
      "[epoch 353]  Loss: 0.0107  Accuracy: 96.174 %\n",
      "[epoch 354]  Loss: 0.0107  Accuracy: 96.178 %\n",
      "[epoch 355]  Loss: 0.0145  Accuracy: 95.202 %\n",
      "[epoch 356]  Loss: 0.0154  Accuracy: 94.782 %\n",
      "[epoch 357]  Loss: 0.0111  Accuracy: 96.028 %\n",
      "[epoch 358]  Loss: 0.0082  Accuracy: 97.082 %\n",
      "[epoch 359]  Loss: 0.0128  Accuracy: 95.508 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 360]  Loss: 0.0137  Accuracy: 95.266 %\n",
      "[epoch 361]  Loss: 0.0110  Accuracy: 96.208 %\n",
      "[epoch 362]  Loss: 0.0110  Accuracy: 96.150 %\n",
      "[epoch 363]  Loss: 0.0117  Accuracy: 96.010 %\n",
      "[epoch 364]  Loss: 0.0114  Accuracy: 95.944 %\n",
      "[epoch 365]  Loss: 0.0094  Accuracy: 96.642 %\n",
      "[epoch 366]  Loss: 0.0131  Accuracy: 95.496 %\n",
      "[epoch 367]  Loss: 0.0133  Accuracy: 95.366 %\n",
      "[epoch 368]  Loss: 0.0116  Accuracy: 95.930 %\n",
      "[epoch 369]  Loss: 0.0117  Accuracy: 95.856 %\n",
      "[epoch 370]  Loss: 0.0126  Accuracy: 95.624 %\n",
      "[epoch 371]  Loss: 0.0104  Accuracy: 96.348 %\n",
      "[epoch 372]  Loss: 0.0101  Accuracy: 96.496 %\n",
      "[epoch 373]  Loss: 0.0127  Accuracy: 95.592 %\n",
      "[epoch 374]  Loss: 0.0118  Accuracy: 95.882 %\n",
      "[epoch 375]  Loss: 0.0144  Accuracy: 95.046 %\n",
      "[epoch 376]  Loss: 0.0119  Accuracy: 95.832 %\n",
      "[epoch 377]  Loss: 0.0098  Accuracy: 96.542 %\n",
      "[epoch 378]  Loss: 0.0108  Accuracy: 96.094 %\n",
      "[epoch 379]  Loss: 0.0127  Accuracy: 95.534 %\n",
      "[epoch 380]  Loss: 0.0095  Accuracy: 96.614 %\n",
      "[epoch 381]  Loss: 0.0110  Accuracy: 96.074 %\n",
      "[epoch 382]  Loss: 0.0115  Accuracy: 96.142 %\n",
      "[epoch 383]  Loss: 0.0129  Accuracy: 95.564 %\n",
      "[epoch 384]  Loss: 0.0103  Accuracy: 96.358 %\n",
      "[epoch 385]  Loss: 0.0104  Accuracy: 96.356 %\n",
      "[epoch 386]  Loss: 0.0132  Accuracy: 95.372 %\n",
      "[epoch 387]  Loss: 0.0128  Accuracy: 95.706 %\n",
      "[epoch 388]  Loss: 0.0095  Accuracy: 96.624 %\n",
      "[epoch 389]  Loss: 0.0114  Accuracy: 95.980 %\n",
      "[epoch 390]  Loss: 0.0127  Accuracy: 95.608 %\n",
      "[epoch 391]  Loss: 0.0120  Accuracy: 95.928 %\n",
      "[epoch 392]  Loss: 0.0091  Accuracy: 96.694 %\n",
      "[epoch 393]  Loss: 0.0138  Accuracy: 95.408 %\n",
      "[epoch 394]  Loss: 0.0113  Accuracy: 96.090 %\n",
      "[epoch 395]  Loss: 0.0099  Accuracy: 96.448 %\n",
      "[epoch 396]  Loss: 0.0103  Accuracy: 96.412 %\n",
      "[epoch 397]  Loss: 0.0144  Accuracy: 95.046 %\n",
      "[epoch 398]  Loss: 0.0100  Accuracy: 96.536 %\n",
      "[epoch 399]  Loss: 0.0116  Accuracy: 95.982 %\n",
      "[epoch 400]  Loss: 0.0116  Accuracy: 95.980 %\n",
      "[epoch 401]  Loss: 0.0103  Accuracy: 96.500 %\n",
      "[epoch 402]  Loss: 0.0118  Accuracy: 95.986 %\n",
      "[epoch 403]  Loss: 0.0098  Accuracy: 96.528 %\n",
      "[epoch 404]  Loss: 0.0093  Accuracy: 96.692 %\n",
      "[epoch 405]  Loss: 0.0127  Accuracy: 95.622 %\n",
      "[epoch 406]  Loss: 0.0100  Accuracy: 96.400 %\n",
      "[epoch 407]  Loss: 0.0119  Accuracy: 96.006 %\n",
      "[epoch 408]  Loss: 0.0113  Accuracy: 96.068 %\n",
      "[epoch 409]  Loss: 0.0145  Accuracy: 95.144 %\n",
      "[epoch 410]  Loss: 0.0087  Accuracy: 96.960 %\n",
      "[epoch 411]  Loss: 0.0083  Accuracy: 97.102 %\n",
      "[epoch 412]  Loss: 0.0119  Accuracy: 95.952 %\n",
      "[epoch 413]  Loss: 0.0115  Accuracy: 96.010 %\n",
      "[epoch 414]  Loss: 0.0128  Accuracy: 95.644 %\n",
      "[epoch 415]  Loss: 0.0114  Accuracy: 96.138 %\n",
      "[epoch 416]  Loss: 0.0102  Accuracy: 96.464 %\n",
      "[epoch 417]  Loss: 0.0125  Accuracy: 95.758 %\n",
      "[epoch 418]  Loss: 0.0087  Accuracy: 96.924 %\n",
      "[epoch 419]  Loss: 0.0139  Accuracy: 95.290 %\n",
      "[epoch 420]  Loss: 0.0111  Accuracy: 96.126 %\n",
      "[epoch 421]  Loss: 0.0109  Accuracy: 96.278 %\n",
      "[epoch 422]  Loss: 0.0113  Accuracy: 96.158 %\n",
      "[epoch 423]  Loss: 0.0091  Accuracy: 96.684 %\n",
      "[epoch 424]  Loss: 0.0107  Accuracy: 96.354 %\n",
      "[epoch 425]  Loss: 0.0112  Accuracy: 96.146 %\n",
      "[epoch 426]  Loss: 0.0100  Accuracy: 96.414 %\n",
      "[epoch 427]  Loss: 0.0126  Accuracy: 95.768 %\n",
      "[epoch 428]  Loss: 0.0124  Accuracy: 95.802 %\n",
      "[epoch 429]  Loss: 0.0087  Accuracy: 96.894 %\n",
      "[epoch 430]  Loss: 0.0105  Accuracy: 96.458 %\n",
      "[epoch 431]  Loss: 0.0116  Accuracy: 95.934 %\n",
      "[epoch 432]  Loss: 0.0088  Accuracy: 96.836 %\n",
      "[epoch 433]  Loss: 0.0157  Accuracy: 94.940 %\n",
      "[epoch 434]  Loss: 0.0092  Accuracy: 96.714 %\n",
      "[epoch 435]  Loss: 0.0116  Accuracy: 95.950 %\n",
      "[epoch 436]  Loss: 0.0089  Accuracy: 96.848 %\n",
      "[epoch 437]  Loss: 0.0091  Accuracy: 96.832 %\n",
      "[epoch 438]  Loss: 0.0144  Accuracy: 95.254 %\n",
      "[epoch 439]  Loss: 0.0110  Accuracy: 96.180 %\n",
      "[epoch 440]  Loss: 0.0099  Accuracy: 96.598 %\n",
      "[epoch 441]  Loss: 0.0122  Accuracy: 95.926 %\n",
      "[epoch 442]  Loss: 0.0072  Accuracy: 97.486 %\n",
      "[epoch 443]  Loss: 0.0103  Accuracy: 96.470 %\n",
      "[epoch 444]  Loss: 0.0132  Accuracy: 95.566 %\n",
      "[epoch 445]  Loss: 0.0096  Accuracy: 96.636 %\n",
      "[epoch 446]  Loss: 0.0082  Accuracy: 97.078 %\n",
      "[epoch 447]  Loss: 0.0122  Accuracy: 95.896 %\n",
      "[epoch 448]  Loss: 0.0111  Accuracy: 96.146 %\n",
      "[epoch 449]  Loss: 0.0110  Accuracy: 96.216 %\n",
      "[epoch 450]  Loss: 0.0105  Accuracy: 96.454 %\n",
      "[epoch 451]  Loss: 0.0101  Accuracy: 96.586 %\n",
      "[epoch 452]  Loss: 0.0122  Accuracy: 95.902 %\n",
      "[epoch 453]  Loss: 0.0120  Accuracy: 96.024 %\n",
      "[epoch 454]  Loss: 0.0083  Accuracy: 97.086 %\n",
      "[epoch 455]  Loss: 0.0120  Accuracy: 95.882 %\n",
      "[epoch 456]  Loss: 0.0107  Accuracy: 96.412 %\n",
      "[epoch 457]  Loss: 0.0088  Accuracy: 96.926 %\n",
      "[epoch 458]  Loss: 0.0101  Accuracy: 96.392 %\n",
      "[epoch 459]  Loss: 0.0105  Accuracy: 96.320 %\n",
      "[epoch 460]  Loss: 0.0121  Accuracy: 95.962 %\n",
      "[epoch 461]  Loss: 0.0105  Accuracy: 96.480 %\n",
      "[epoch 462]  Loss: 0.0099  Accuracy: 96.602 %\n",
      "[epoch 463]  Loss: 0.0126  Accuracy: 95.832 %\n",
      "[epoch 464]  Loss: 0.0088  Accuracy: 96.910 %\n",
      "[epoch 465]  Loss: 0.0088  Accuracy: 96.932 %\n",
      "[epoch 466]  Loss: 0.0084  Accuracy: 97.010 %\n",
      "[epoch 467]  Loss: 0.0132  Accuracy: 95.646 %\n",
      "[epoch 468]  Loss: 0.0122  Accuracy: 95.780 %\n",
      "[epoch 469]  Loss: 0.0088  Accuracy: 96.908 %\n",
      "[epoch 470]  Loss: 0.0103  Accuracy: 96.446 %\n",
      "[epoch 471]  Loss: 0.0121  Accuracy: 95.940 %\n",
      "[epoch 472]  Loss: 0.0099  Accuracy: 96.668 %\n",
      "[epoch 473]  Loss: 0.0115  Accuracy: 96.120 %\n",
      "[epoch 474]  Loss: 0.0095  Accuracy: 96.680 %\n",
      "[epoch 475]  Loss: 0.0109  Accuracy: 96.280 %\n",
      "[epoch 476]  Loss: 0.0074  Accuracy: 97.344 %\n",
      "[epoch 477]  Loss: 0.0092  Accuracy: 96.830 %\n",
      "[epoch 478]  Loss: 0.0136  Accuracy: 95.458 %\n",
      "[epoch 479]  Loss: 0.0133  Accuracy: 95.586 %\n",
      "[epoch 480]  Loss: 0.0087  Accuracy: 97.006 %\n",
      "[epoch 481]  Loss: 0.0095  Accuracy: 96.736 %\n",
      "[epoch 482]  Loss: 0.0099  Accuracy: 96.586 %\n",
      "[epoch 483]  Loss: 0.0100  Accuracy: 96.580 %\n",
      "[epoch 484]  Loss: 0.0101  Accuracy: 96.454 %\n",
      "[epoch 485]  Loss: 0.0120  Accuracy: 96.020 %\n",
      "[epoch 486]  Loss: 0.0120  Accuracy: 96.040 %\n",
      "[epoch 487]  Loss: 0.0088  Accuracy: 96.952 %\n",
      "[epoch 488]  Loss: 0.0097  Accuracy: 96.718 %\n",
      "[epoch 489]  Loss: 0.0096  Accuracy: 96.720 %\n",
      "[epoch 490]  Loss: 0.0095  Accuracy: 96.706 %\n",
      "[epoch 491]  Loss: 0.0130  Accuracy: 95.730 %\n",
      "[epoch 492]  Loss: 0.0094  Accuracy: 96.712 %\n",
      "[epoch 493]  Loss: 0.0081  Accuracy: 97.228 %\n",
      "[epoch 494]  Loss: 0.0079  Accuracy: 97.164 %\n",
      "[epoch 495]  Loss: 0.0110  Accuracy: 96.244 %\n",
      "[epoch 496]  Loss: 0.0125  Accuracy: 95.888 %\n",
      "[epoch 497]  Loss: 0.0096  Accuracy: 96.834 %\n",
      "[epoch 498]  Loss: 0.0116  Accuracy: 96.160 %\n",
      "[epoch 499]  Loss: 0.0086  Accuracy: 97.076 %\n",
      "[epoch 500]  Loss: 0.0097  Accuracy: 96.700 %\n",
      "[epoch 501]  Loss: 0.0093  Accuracy: 96.814 %\n",
      "[epoch 502]  Loss: 0.0119  Accuracy: 96.074 %\n",
      "[epoch 503]  Loss: 0.0102  Accuracy: 96.488 %\n",
      "[epoch 504]  Loss: 0.0107  Accuracy: 96.402 %\n",
      "[epoch 505]  Loss: 0.0102  Accuracy: 96.490 %\n",
      "[epoch 506]  Loss: 0.0078  Accuracy: 97.214 %\n",
      "[epoch 507]  Loss: 0.0119  Accuracy: 96.148 %\n",
      "[epoch 508]  Loss: 0.0106  Accuracy: 96.380 %\n",
      "[epoch 509]  Loss: 0.0101  Accuracy: 96.642 %\n",
      "[epoch 510]  Loss: 0.0099  Accuracy: 96.522 %\n",
      "[epoch 511]  Loss: 0.0116  Accuracy: 96.252 %\n",
      "[epoch 512]  Loss: 0.0106  Accuracy: 96.380 %\n",
      "[epoch 513]  Loss: 0.0082  Accuracy: 97.166 %\n",
      "[epoch 514]  Loss: 0.0105  Accuracy: 96.502 %\n",
      "[epoch 515]  Loss: 0.0107  Accuracy: 96.410 %\n",
      "[epoch 516]  Loss: 0.0073  Accuracy: 97.558 %\n",
      "[epoch 517]  Loss: 0.0125  Accuracy: 95.976 %\n",
      "[epoch 518]  Loss: 0.0100  Accuracy: 96.566 %\n",
      "[epoch 519]  Loss: 0.0080  Accuracy: 97.220 %\n",
      "[epoch 520]  Loss: 0.0126  Accuracy: 95.962 %\n",
      "[epoch 521]  Loss: 0.0116  Accuracy: 96.072 %\n",
      "[epoch 522]  Loss: 0.0103  Accuracy: 96.602 %\n",
      "[epoch 523]  Loss: 0.0098  Accuracy: 96.760 %\n",
      "[epoch 524]  Loss: 0.0087  Accuracy: 97.094 %\n",
      "[epoch 525]  Loss: 0.0088  Accuracy: 97.088 %\n",
      "[epoch 526]  Loss: 0.0128  Accuracy: 95.824 %\n",
      "[epoch 527]  Loss: 0.0107  Accuracy: 96.350 %\n",
      "[epoch 528]  Loss: 0.0081  Accuracy: 97.220 %\n",
      "[epoch 529]  Loss: 0.0096  Accuracy: 96.814 %\n",
      "[epoch 530]  Loss: 0.0159  Accuracy: 94.990 %\n",
      "[epoch 531]  Loss: 0.0066  Accuracy: 97.744 %\n",
      "[epoch 532]  Loss: 0.0088  Accuracy: 97.082 %\n",
      "[epoch 533]  Loss: 0.0095  Accuracy: 96.812 %\n",
      "[epoch 534]  Loss: 0.0089  Accuracy: 96.924 %\n",
      "[epoch 535]  Loss: 0.0127  Accuracy: 95.802 %\n",
      "[epoch 536]  Loss: 0.0065  Accuracy: 97.708 %\n",
      "[epoch 537]  Loss: 0.0082  Accuracy: 97.134 %\n",
      "[epoch 538]  Loss: 0.0095  Accuracy: 96.812 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 539]  Loss: 0.0109  Accuracy: 96.322 %\n",
      "[epoch 540]  Loss: 0.0115  Accuracy: 96.250 %\n",
      "[epoch 541]  Loss: 0.0091  Accuracy: 96.920 %\n",
      "[epoch 542]  Loss: 0.0081  Accuracy: 97.156 %\n",
      "[epoch 543]  Loss: 0.0091  Accuracy: 96.808 %\n",
      "[epoch 544]  Loss: 0.0137  Accuracy: 95.546 %\n",
      "[epoch 545]  Loss: 0.0112  Accuracy: 96.282 %\n",
      "[epoch 546]  Loss: 0.0075  Accuracy: 97.436 %\n",
      "[epoch 547]  Loss: 0.0095  Accuracy: 96.804 %\n",
      "[epoch 548]  Loss: 0.0103  Accuracy: 96.510 %\n",
      "[epoch 549]  Loss: 0.0142  Accuracy: 95.614 %\n",
      "[epoch 550]  Loss: 0.0074  Accuracy: 97.402 %\n",
      "[epoch 551]  Loss: 0.0069  Accuracy: 97.798 %\n",
      "[epoch 552]  Loss: 0.0119  Accuracy: 96.126 %\n",
      "[epoch 553]  Loss: 0.0094  Accuracy: 96.776 %\n",
      "[epoch 554]  Loss: 0.0114  Accuracy: 96.352 %\n",
      "[epoch 555]  Loss: 0.0100  Accuracy: 96.578 %\n",
      "[epoch 556]  Loss: 0.0087  Accuracy: 97.198 %\n",
      "[epoch 557]  Loss: 0.0101  Accuracy: 96.582 %\n",
      "[epoch 558]  Loss: 0.0085  Accuracy: 97.144 %\n",
      "[epoch 559]  Loss: 0.0114  Accuracy: 96.298 %\n",
      "[epoch 560]  Loss: 0.0091  Accuracy: 96.832 %\n",
      "[epoch 561]  Loss: 0.0115  Accuracy: 96.250 %\n",
      "[epoch 562]  Loss: 0.0084  Accuracy: 97.192 %\n",
      "[epoch 563]  Loss: 0.0076  Accuracy: 97.400 %\n",
      "[epoch 564]  Loss: 0.0104  Accuracy: 96.492 %\n",
      "[epoch 565]  Loss: 0.0067  Accuracy: 97.694 %\n",
      "[epoch 566]  Loss: 0.0097  Accuracy: 96.814 %\n",
      "[epoch 567]  Loss: 0.0134  Accuracy: 95.742 %\n",
      "[epoch 568]  Loss: 0.0098  Accuracy: 96.676 %\n",
      "[epoch 569]  Loss: 0.0087  Accuracy: 97.114 %\n",
      "[epoch 570]  Loss: 0.0101  Accuracy: 96.682 %\n",
      "[epoch 571]  Loss: 0.0097  Accuracy: 96.734 %\n",
      "[epoch 572]  Loss: 0.0129  Accuracy: 95.966 %\n",
      "[epoch 573]  Loss: 0.0072  Accuracy: 97.526 %\n",
      "[epoch 574]  Loss: 0.0093  Accuracy: 96.916 %\n",
      "[epoch 575]  Loss: 0.0106  Accuracy: 96.464 %\n",
      "[epoch 576]  Loss: 0.0074  Accuracy: 97.412 %\n",
      "[epoch 577]  Loss: 0.0114  Accuracy: 96.342 %\n",
      "[epoch 578]  Loss: 0.0081  Accuracy: 97.270 %\n",
      "[epoch 579]  Loss: 0.0123  Accuracy: 95.978 %\n",
      "[epoch 580]  Loss: 0.0095  Accuracy: 96.696 %\n",
      "[epoch 581]  Loss: 0.0058  Accuracy: 97.932 %\n",
      "[epoch 582]  Loss: 0.0094  Accuracy: 96.850 %\n",
      "[epoch 583]  Loss: 0.0103  Accuracy: 96.644 %\n",
      "[epoch 584]  Loss: 0.0102  Accuracy: 96.668 %\n",
      "[epoch 585]  Loss: 0.0093  Accuracy: 96.902 %\n",
      "[epoch 586]  Loss: 0.0094  Accuracy: 96.874 %\n",
      "[epoch 587]  Loss: 0.0101  Accuracy: 96.696 %\n",
      "[epoch 588]  Loss: 0.0100  Accuracy: 96.662 %\n",
      "[epoch 589]  Loss: 0.0083  Accuracy: 97.238 %\n",
      "[epoch 590]  Loss: 0.0083  Accuracy: 97.106 %\n",
      "[epoch 591]  Loss: 0.0076  Accuracy: 97.410 %\n",
      "[epoch 592]  Loss: 0.0131  Accuracy: 95.846 %\n",
      "[epoch 593]  Loss: 0.0090  Accuracy: 96.942 %\n",
      "[epoch 594]  Loss: 0.0082  Accuracy: 97.274 %\n",
      "[epoch 595]  Loss: 0.0119  Accuracy: 96.098 %\n",
      "[epoch 596]  Loss: 0.0101  Accuracy: 96.712 %\n",
      "[epoch 597]  Loss: 0.0074  Accuracy: 97.466 %\n",
      "[epoch 598]  Loss: 0.0090  Accuracy: 97.100 %\n",
      "[epoch 599]  Loss: 0.0100  Accuracy: 96.668 %\n",
      "[epoch 600]  Loss: 0.0102  Accuracy: 96.736 %\n",
      "[epoch 601]  Loss: 0.0088  Accuracy: 96.960 %\n",
      "[epoch 602]  Loss: 0.0096  Accuracy: 96.884 %\n",
      "[epoch 603]  Loss: 0.0089  Accuracy: 97.064 %\n",
      "[epoch 604]  Loss: 0.0095  Accuracy: 96.926 %\n",
      "[epoch 605]  Loss: 0.0116  Accuracy: 96.274 %\n",
      "[epoch 606]  Loss: 0.0076  Accuracy: 97.444 %\n",
      "[epoch 607]  Loss: 0.0080  Accuracy: 97.252 %\n",
      "[epoch 608]  Loss: 0.0106  Accuracy: 96.540 %\n",
      "[epoch 609]  Loss: 0.0105  Accuracy: 96.492 %\n",
      "[epoch 610]  Loss: 0.0114  Accuracy: 96.318 %\n",
      "[epoch 611]  Loss: 0.0070  Accuracy: 97.530 %\n",
      "[epoch 612]  Loss: 0.0106  Accuracy: 96.476 %\n",
      "[epoch 613]  Loss: 0.0082  Accuracy: 97.280 %\n",
      "[epoch 614]  Loss: 0.0078  Accuracy: 97.256 %\n",
      "[epoch 615]  Loss: 0.0121  Accuracy: 96.302 %\n",
      "[epoch 616]  Loss: 0.0094  Accuracy: 96.888 %\n",
      "[epoch 617]  Loss: 0.0086  Accuracy: 97.060 %\n",
      "[epoch 618]  Loss: 0.0096  Accuracy: 96.852 %\n",
      "[epoch 619]  Loss: 0.0112  Accuracy: 96.406 %\n",
      "[epoch 620]  Loss: 0.0092  Accuracy: 96.990 %\n",
      "[epoch 621]  Loss: 0.0087  Accuracy: 97.102 %\n",
      "[epoch 622]  Loss: 0.0117  Accuracy: 96.404 %\n",
      "[epoch 623]  Loss: 0.0068  Accuracy: 97.624 %\n",
      "[epoch 624]  Loss: 0.0100  Accuracy: 96.800 %\n",
      "[epoch 625]  Loss: 0.0086  Accuracy: 97.118 %\n",
      "[epoch 626]  Loss: 0.0087  Accuracy: 97.092 %\n",
      "[epoch 627]  Loss: 0.0103  Accuracy: 96.738 %\n",
      "[epoch 628]  Loss: 0.0094  Accuracy: 96.874 %\n",
      "[epoch 629]  Loss: 0.0095  Accuracy: 96.824 %\n",
      "[epoch 630]  Loss: 0.0103  Accuracy: 96.628 %\n",
      "[epoch 631]  Loss: 0.0077  Accuracy: 97.470 %\n",
      "[epoch 632]  Loss: 0.0092  Accuracy: 96.914 %\n",
      "[epoch 633]  Loss: 0.0105  Accuracy: 96.616 %\n",
      "[epoch 634]  Loss: 0.0090  Accuracy: 97.036 %\n",
      "[epoch 635]  Loss: 0.0088  Accuracy: 97.056 %\n",
      "[epoch 636]  Loss: 0.0078  Accuracy: 97.364 %\n",
      "[epoch 637]  Loss: 0.0090  Accuracy: 96.986 %\n",
      "[epoch 638]  Loss: 0.0103  Accuracy: 96.652 %\n",
      "[epoch 639]  Loss: 0.0102  Accuracy: 96.646 %\n",
      "[epoch 640]  Loss: 0.0109  Accuracy: 96.566 %\n",
      "[epoch 641]  Loss: 0.0092  Accuracy: 96.954 %\n",
      "[epoch 642]  Loss: 0.0082  Accuracy: 97.382 %\n",
      "[epoch 643]  Loss: 0.0109  Accuracy: 96.548 %\n",
      "[epoch 644]  Loss: 0.0078  Accuracy: 97.432 %\n",
      "[epoch 645]  Loss: 0.0080  Accuracy: 97.306 %\n",
      "[epoch 646]  Loss: 0.0113  Accuracy: 96.386 %\n",
      "[epoch 647]  Loss: 0.0076  Accuracy: 97.466 %\n",
      "[epoch 648]  Loss: 0.0081  Accuracy: 97.348 %\n",
      "[epoch 649]  Loss: 0.0128  Accuracy: 96.006 %\n",
      "[epoch 650]  Loss: 0.0090  Accuracy: 97.008 %\n",
      "[epoch 651]  Loss: 0.0069  Accuracy: 97.568 %\n",
      "[epoch 652]  Loss: 0.0084  Accuracy: 97.328 %\n",
      "[epoch 653]  Loss: 0.0109  Accuracy: 96.644 %\n",
      "[epoch 654]  Loss: 0.0104  Accuracy: 96.560 %\n",
      "[epoch 655]  Loss: 0.0110  Accuracy: 96.562 %\n",
      "[epoch 656]  Loss: 0.0061  Accuracy: 97.890 %\n",
      "[epoch 657]  Loss: 0.0071  Accuracy: 97.586 %\n",
      "[epoch 658]  Loss: 0.0130  Accuracy: 95.952 %\n",
      "[epoch 659]  Loss: 0.0107  Accuracy: 96.546 %\n",
      "[epoch 660]  Loss: 0.0070  Accuracy: 97.618 %\n",
      "[epoch 661]  Loss: 0.0085  Accuracy: 97.146 %\n",
      "[epoch 662]  Loss: 0.0083  Accuracy: 97.270 %\n",
      "[epoch 663]  Loss: 0.0136  Accuracy: 95.866 %\n",
      "[epoch 664]  Loss: 0.0067  Accuracy: 97.748 %\n",
      "[epoch 665]  Loss: 0.0109  Accuracy: 96.510 %\n",
      "[epoch 666]  Loss: 0.0116  Accuracy: 96.296 %\n",
      "[epoch 667]  Loss: 0.0053  Accuracy: 98.184 %\n",
      "[epoch 668]  Loss: 0.0083  Accuracy: 97.216 %\n",
      "[epoch 669]  Loss: 0.0125  Accuracy: 96.194 %\n",
      "[epoch 670]  Loss: 0.0081  Accuracy: 97.310 %\n",
      "[epoch 671]  Loss: 0.0084  Accuracy: 97.180 %\n",
      "[epoch 672]  Loss: 0.0099  Accuracy: 96.740 %\n",
      "[epoch 673]  Loss: 0.0073  Accuracy: 97.476 %\n",
      "[epoch 674]  Loss: 0.0103  Accuracy: 96.816 %\n",
      "[epoch 675]  Loss: 0.0095  Accuracy: 96.878 %\n",
      "[epoch 676]  Loss: 0.0082  Accuracy: 97.338 %\n",
      "[epoch 677]  Loss: 0.0098  Accuracy: 96.814 %\n",
      "[epoch 678]  Loss: 0.0094  Accuracy: 96.962 %\n",
      "[epoch 679]  Loss: 0.0089  Accuracy: 97.050 %\n",
      "[epoch 680]  Loss: 0.0084  Accuracy: 97.176 %\n",
      "[epoch 681]  Loss: 0.0120  Accuracy: 96.324 %\n",
      "[epoch 682]  Loss: 0.0074  Accuracy: 97.494 %\n",
      "[epoch 683]  Loss: 0.0067  Accuracy: 97.682 %\n",
      "[epoch 684]  Loss: 0.0107  Accuracy: 96.560 %\n",
      "[epoch 685]  Loss: 0.0075  Accuracy: 97.526 %\n",
      "[epoch 686]  Loss: 0.0074  Accuracy: 97.494 %\n",
      "[epoch 687]  Loss: 0.0131  Accuracy: 96.110 %\n",
      "[epoch 688]  Loss: 0.0092  Accuracy: 96.964 %\n",
      "[epoch 689]  Loss: 0.0094  Accuracy: 97.014 %\n",
      "[epoch 690]  Loss: 0.0092  Accuracy: 97.172 %\n",
      "[epoch 691]  Loss: 0.0116  Accuracy: 96.398 %\n",
      "[epoch 692]  Loss: 0.0067  Accuracy: 97.718 %\n",
      "[epoch 693]  Loss: 0.0079  Accuracy: 97.384 %\n",
      "[epoch 694]  Loss: 0.0098  Accuracy: 96.822 %\n",
      "[epoch 695]  Loss: 0.0085  Accuracy: 97.130 %\n",
      "[epoch 696]  Loss: 0.0090  Accuracy: 97.084 %\n",
      "[epoch 697]  Loss: 0.0066  Accuracy: 97.842 %\n",
      "[epoch 698]  Loss: 0.0143  Accuracy: 95.784 %\n",
      "[epoch 699]  Loss: 0.0070  Accuracy: 97.700 %\n",
      "[epoch 700]  Loss: 0.0113  Accuracy: 96.516 %\n",
      "[epoch 701]  Loss: 0.0083  Accuracy: 97.208 %\n",
      "[epoch 702]  Loss: 0.0091  Accuracy: 97.032 %\n",
      "[epoch 703]  Loss: 0.0082  Accuracy: 97.318 %\n",
      "[epoch 704]  Loss: 0.0134  Accuracy: 96.022 %\n",
      "[epoch 705]  Loss: 0.0083  Accuracy: 97.284 %\n",
      "[epoch 706]  Loss: 0.0067  Accuracy: 97.720 %\n",
      "[epoch 707]  Loss: 0.0077  Accuracy: 97.428 %\n",
      "[epoch 708]  Loss: 0.0091  Accuracy: 96.970 %\n",
      "[epoch 709]  Loss: 0.0089  Accuracy: 97.150 %\n",
      "[epoch 710]  Loss: 0.0115  Accuracy: 96.330 %\n",
      "[epoch 711]  Loss: 0.0079  Accuracy: 97.354 %\n",
      "[epoch 712]  Loss: 0.0070  Accuracy: 97.620 %\n",
      "[epoch 713]  Loss: 0.0098  Accuracy: 96.940 %\n",
      "[epoch 714]  Loss: 0.0100  Accuracy: 96.678 %\n",
      "[epoch 715]  Loss: 0.0098  Accuracy: 96.924 %\n",
      "[epoch 716]  Loss: 0.0087  Accuracy: 97.166 %\n",
      "[epoch 717]  Loss: 0.0103  Accuracy: 96.764 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 718]  Loss: 0.0115  Accuracy: 96.498 %\n",
      "[epoch 719]  Loss: 0.0067  Accuracy: 97.720 %\n",
      "[epoch 720]  Loss: 0.0081  Accuracy: 97.402 %\n",
      "[epoch 721]  Loss: 0.0084  Accuracy: 97.280 %\n",
      "[epoch 722]  Loss: 0.0100  Accuracy: 96.912 %\n",
      "[epoch 723]  Loss: 0.0115  Accuracy: 96.478 %\n",
      "[epoch 724]  Loss: 0.0093  Accuracy: 97.028 %\n",
      "[epoch 725]  Loss: 0.0081  Accuracy: 97.278 %\n",
      "[epoch 726]  Loss: 0.0059  Accuracy: 97.976 %\n",
      "[epoch 727]  Loss: 0.0129  Accuracy: 96.226 %\n",
      "[epoch 728]  Loss: 0.0088  Accuracy: 97.116 %\n",
      "[epoch 729]  Loss: 0.0088  Accuracy: 97.254 %\n",
      "[epoch 730]  Loss: 0.0099  Accuracy: 96.838 %\n",
      "[epoch 731]  Loss: 0.0086  Accuracy: 97.228 %\n",
      "[epoch 732]  Loss: 0.0081  Accuracy: 97.350 %\n",
      "[epoch 733]  Loss: 0.0075  Accuracy: 97.596 %\n",
      "[epoch 734]  Loss: 0.0090  Accuracy: 97.086 %\n",
      "[epoch 735]  Loss: 0.0091  Accuracy: 96.986 %\n",
      "[epoch 736]  Loss: 0.0103  Accuracy: 96.712 %\n",
      "[epoch 737]  Loss: 0.0068  Accuracy: 97.724 %\n",
      "[epoch 738]  Loss: 0.0085  Accuracy: 97.320 %\n",
      "[epoch 739]  Loss: 0.0104  Accuracy: 96.684 %\n",
      "[epoch 740]  Loss: 0.0089  Accuracy: 97.172 %\n",
      "[epoch 741]  Loss: 0.0094  Accuracy: 97.014 %\n",
      "[epoch 742]  Loss: 0.0075  Accuracy: 97.570 %\n",
      "[epoch 743]  Loss: 0.0091  Accuracy: 97.176 %\n",
      "[epoch 744]  Loss: 0.0107  Accuracy: 96.702 %\n",
      "[epoch 745]  Loss: 0.0091  Accuracy: 97.154 %\n",
      "[epoch 746]  Loss: 0.0073  Accuracy: 97.620 %\n",
      "[epoch 747]  Loss: 0.0107  Accuracy: 96.692 %\n",
      "[epoch 748]  Loss: 0.0089  Accuracy: 97.148 %\n",
      "[epoch 749]  Loss: 0.0080  Accuracy: 97.380 %\n",
      "[epoch 750]  Loss: 0.0086  Accuracy: 97.152 %\n",
      "[epoch 751]  Loss: 0.0072  Accuracy: 97.624 %\n",
      "[epoch 752]  Loss: 0.0115  Accuracy: 96.470 %\n",
      "[epoch 753]  Loss: 0.0079  Accuracy: 97.470 %\n",
      "[epoch 754]  Loss: 0.0141  Accuracy: 96.036 %\n",
      "[epoch 755]  Loss: 0.0060  Accuracy: 97.952 %\n",
      "[epoch 756]  Loss: 0.0110  Accuracy: 96.592 %\n",
      "[epoch 757]  Loss: 0.0083  Accuracy: 97.352 %\n",
      "[epoch 758]  Loss: 0.0069  Accuracy: 97.716 %\n",
      "[epoch 759]  Loss: 0.0101  Accuracy: 96.852 %\n",
      "[epoch 760]  Loss: 0.0099  Accuracy: 96.898 %\n",
      "[epoch 761]  Loss: 0.0114  Accuracy: 96.656 %\n",
      "[epoch 762]  Loss: 0.0117  Accuracy: 96.434 %\n",
      "[epoch 763]  Loss: 0.0063  Accuracy: 97.910 %\n",
      "[epoch 764]  Loss: 0.0064  Accuracy: 97.942 %\n",
      "[epoch 765]  Loss: 0.0110  Accuracy: 96.606 %\n",
      "[epoch 766]  Loss: 0.0073  Accuracy: 97.478 %\n",
      "[epoch 767]  Loss: 0.0092  Accuracy: 97.004 %\n",
      "[epoch 768]  Loss: 0.0076  Accuracy: 97.518 %\n",
      "[epoch 769]  Loss: 0.0082  Accuracy: 97.316 %\n",
      "[epoch 770]  Loss: 0.0117  Accuracy: 96.478 %\n",
      "[epoch 771]  Loss: 0.0093  Accuracy: 97.078 %\n",
      "[epoch 772]  Loss: 0.0068  Accuracy: 97.682 %\n",
      "[epoch 773]  Loss: 0.0078  Accuracy: 97.454 %\n",
      "[epoch 774]  Loss: 0.0124  Accuracy: 96.316 %\n",
      "[epoch 775]  Loss: 0.0097  Accuracy: 96.954 %\n",
      "[epoch 776]  Loss: 0.0069  Accuracy: 97.784 %\n",
      "[epoch 777]  Loss: 0.0085  Accuracy: 97.270 %\n",
      "[epoch 778]  Loss: 0.0081  Accuracy: 97.352 %\n",
      "[epoch 779]  Loss: 0.0108  Accuracy: 96.710 %\n",
      "[epoch 780]  Loss: 0.0067  Accuracy: 97.870 %\n",
      "[epoch 781]  Loss: 0.0062  Accuracy: 97.906 %\n",
      "[epoch 782]  Loss: 0.0125  Accuracy: 96.220 %\n",
      "[epoch 783]  Loss: 0.0079  Accuracy: 97.470 %\n",
      "[epoch 784]  Loss: 0.0090  Accuracy: 97.234 %\n",
      "[epoch 785]  Loss: 0.0088  Accuracy: 97.226 %\n",
      "[epoch 786]  Loss: 0.0101  Accuracy: 96.924 %\n",
      "[epoch 787]  Loss: 0.0069  Accuracy: 97.776 %\n",
      "[epoch 788]  Loss: 0.0082  Accuracy: 97.290 %\n",
      "[epoch 789]  Loss: 0.0117  Accuracy: 96.438 %\n",
      "[epoch 790]  Loss: 0.0097  Accuracy: 96.980 %\n",
      "[epoch 791]  Loss: 0.0072  Accuracy: 97.630 %\n",
      "[epoch 792]  Loss: 0.0064  Accuracy: 97.850 %\n",
      "[epoch 793]  Loss: 0.0094  Accuracy: 97.116 %\n",
      "[epoch 794]  Loss: 0.0100  Accuracy: 96.974 %\n",
      "[epoch 795]  Loss: 0.0095  Accuracy: 97.016 %\n",
      "[epoch 796]  Loss: 0.0088  Accuracy: 97.122 %\n",
      "[epoch 797]  Loss: 0.0087  Accuracy: 97.390 %\n",
      "[epoch 798]  Loss: 0.0087  Accuracy: 97.152 %\n",
      "[epoch 799]  Loss: 0.0091  Accuracy: 97.112 %\n",
      "Finished Training! Training process cost 8768.758210 sec\n"
     ]
    }
   ],
   "source": [
    "#ALL THE CODE IN THIS CELL ARE WRITE BY MY SELF#\n",
    "# Start training : set net to train model\n",
    "net.train()\n",
    "\n",
    "# make two arrays for saving matplotlib data\n",
    "train_loss = []\n",
    "train_accu = []\n",
    "accuracy = 0\n",
    "\n",
    "# get TersorBoard writer object\n",
    "writer = SummaryWriter(log_dir='Training')\n",
    "\n",
    "# Training process\n",
    "timestart = time.time()\n",
    "for epoch in range(0,epoch):\n",
    "    \n",
    "    # initialize loss,total,correct\n",
    "    loss_value = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    # do iteration (total number of training images / batch size) times\n",
    "    for i, (inputs, labels) in enumerate(trainingloader, 0):\n",
    "        \n",
    "        # get the input and its label\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # make gradients to 0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward step\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        # compute the loss\n",
    "        l = loss(outputs, labels)\n",
    "        \n",
    "        # backward step\n",
    "        l.backward()\n",
    "        \n",
    "        # optimize step\n",
    "        optimizer.step()\n",
    "\n",
    "        # compute loss\n",
    "        loss_value += l.item()\n",
    "        \n",
    "        # save to array in oder to output loss image at the end\n",
    "        train_loss.append(l.item())\n",
    "        \n",
    "        # write to tensorboard file\n",
    "        writer.add_scalars('/GroupB/Loss', {'B1': l.item()}, epoch)\n",
    "\n",
    "        \n",
    "        # compute accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total = total + labels.size(0)\n",
    "        correct = correct + (predicted == labels).sum().item()\n",
    "        accuracy = correct / total * 100.0\n",
    "        \n",
    "        # save to array in oder to output accuracy image at the end\n",
    "        train_accu.append(accuracy)\n",
    "        \n",
    "        # write to tensorboard file\n",
    "        writer.add_scalars('/GroupB/Accuracy', {'B1': accuracy}, epoch)\n",
    "        \n",
    "\n",
    "    loss_epoch = loss_value / (500000/batch_size)\n",
    "    # output the result of this epoch \n",
    "    print('[epoch %d]  Loss: %.4f  Accuracy: %.3f %%' %(epoch, loss_epoch , accuracy))\n",
    "\n",
    "    \n",
    "# Finish Training\n",
    "result_training_accuracy = accuracy\n",
    "result_training_time = (time.time()-timestart)\n",
    "print('Finished Training! Training process cost %3f sec' %result_training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efb2b47b630>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the loss\n",
    "plt.plot(np.arange(len(train_loss)), train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efb2b33c860>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the accuracy\n",
    "plt.plot(np.arange(len(train_accu)), train_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the TensorBoard output stream\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the network is 98.428 %\n"
     ]
    }
   ],
   "source": [
    "#ALL THE CODE IN THIS CELL ARE WRITE BY MY SELF#\n",
    "# Start testing : set net to train model\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# deactivate the autograd engine\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # do testing iteration\n",
    "    #for data in testingloader:\n",
    "        \n",
    "        # get the input and its label\n",
    "        #images, labels = data\n",
    "        #images, labels = images.to(device), labels.to(device)\n",
    "    for i, (inputs, labels) in enumerate(trainingloader, 0):\n",
    "        \n",
    "        # get the input and its label\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward step\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        # compute accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total = total + labels.size(0)\n",
    "        correct = correct + (predicted == labels).sum().item()\n",
    "\n",
    "# Finish Testing\n",
    "result_testing_accuracy = correct / total * 100.0\n",
    "print('The accuracy of the network is %.3f %%' % result_testing_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Configuration]\n",
      "learning rate = 0.001000\n",
      "batch size = 100\n",
      "epoch = 799\n",
      "\n",
      "[Expirement Result]\n",
      "training time = 8768.758210 sec\n",
      "training accuracy = 97.112 %\n",
      "testing accuracy =  98.428 %\n"
     ]
    }
   ],
   "source": [
    "print('[Configuration]')\n",
    "print('learning rate = %3f' % learning_rate )\n",
    "print('batch size = %d' % batch_size )\n",
    "print('epoch = %d' % epoch )\n",
    "print('')\n",
    "print('[Expirement Result]')\n",
    "print('training time = %3f sec' % result_training_time )\n",
    "print('training accuracy = %.3f %%' %result_training_accuracy )\n",
    "print('testing accuracy =  %.3f %%' % (100.0 * correct / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>click <a href='../Main.ipynb'>here</a> to return to Main.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
