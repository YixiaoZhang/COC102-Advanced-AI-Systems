{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18COC102 -  Advanced Artificial Intelligence Systems - Coursework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style='color:red'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Experiment B3</p>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n",
      "CPython 3.6.7\n",
      "IPython 7.2.0\n",
      "\n",
      "numpy 1.15.4\n",
      "torch 0.4.1\n",
      "torchvision 0.2.1\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%watermark -v -p numpy,torch,torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import os\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement the network by myself#\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1  = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2  = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.fc1   = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate=0.001\n",
    "batch_size=10000\n",
    "epoch=800\n",
    "workers=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set GPU \n",
    "device = torch.device(\"cuda:0\")\n",
    "# set Netwrok\n",
    "net = LeNet()\n",
    "net = net.to(device)\n",
    "# set optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "# set loss function\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# dataloader refer source [2]\n",
    "\n",
    "# load training dataset\n",
    "trainingset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, \n",
    "                                           transform=transforms.ToTensor())\n",
    "\n",
    "trainingloader = torch.utils.data.DataLoader(trainingset, batch_size=batch_size,shuffle=True, \n",
    "                                             num_workers=workers)\n",
    "# load testing dataset\n",
    "testingset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transforms.ToTensor())\n",
    "\n",
    "testingloader = torch.utils.data.DataLoader(testingset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=workers)\n",
    "\n",
    "#end of source [2]\n",
    "#source [2] https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0]  Loss: 0.2303  Accuracy: 10.000 %\n",
      "[epoch 1]  Loss: 0.2292  Accuracy: 15.544 %\n",
      "[epoch 2]  Loss: 0.2258  Accuracy: 19.222 %\n",
      "[epoch 3]  Loss: 0.2175  Accuracy: 21.506 %\n",
      "[epoch 4]  Loss: 0.2071  Accuracy: 24.416 %\n",
      "[epoch 5]  Loss: 0.2030  Accuracy: 25.824 %\n",
      "[epoch 6]  Loss: 0.1995  Accuracy: 26.906 %\n",
      "[epoch 7]  Loss: 0.1967  Accuracy: 28.052 %\n",
      "[epoch 8]  Loss: 0.1944  Accuracy: 28.958 %\n",
      "[epoch 9]  Loss: 0.1924  Accuracy: 30.148 %\n",
      "[epoch 10]  Loss: 0.1903  Accuracy: 30.890 %\n",
      "[epoch 11]  Loss: 0.1881  Accuracy: 31.762 %\n",
      "[epoch 12]  Loss: 0.1860  Accuracy: 32.638 %\n",
      "[epoch 13]  Loss: 0.1836  Accuracy: 33.588 %\n",
      "[epoch 14]  Loss: 0.1816  Accuracy: 34.114 %\n",
      "[epoch 15]  Loss: 0.1789  Accuracy: 35.322 %\n",
      "[epoch 16]  Loss: 0.1765  Accuracy: 36.092 %\n",
      "[epoch 17]  Loss: 0.1744  Accuracy: 36.700 %\n",
      "[epoch 18]  Loss: 0.1722  Accuracy: 37.614 %\n",
      "[epoch 19]  Loss: 0.1697  Accuracy: 38.426 %\n",
      "[epoch 20]  Loss: 0.1686  Accuracy: 39.062 %\n",
      "[epoch 21]  Loss: 0.1666  Accuracy: 39.800 %\n",
      "[epoch 22]  Loss: 0.1658  Accuracy: 39.700 %\n",
      "[epoch 23]  Loss: 0.1640  Accuracy: 40.576 %\n",
      "[epoch 24]  Loss: 0.1623  Accuracy: 40.988 %\n",
      "[epoch 25]  Loss: 0.1611  Accuracy: 41.220 %\n",
      "[epoch 26]  Loss: 0.1604  Accuracy: 41.588 %\n",
      "[epoch 27]  Loss: 0.1596  Accuracy: 41.808 %\n",
      "[epoch 28]  Loss: 0.1591  Accuracy: 41.916 %\n",
      "[epoch 29]  Loss: 0.1598  Accuracy: 41.692 %\n",
      "[epoch 30]  Loss: 0.1579  Accuracy: 42.308 %\n",
      "[epoch 31]  Loss: 0.1569  Accuracy: 42.698 %\n",
      "[epoch 32]  Loss: 0.1562  Accuracy: 43.102 %\n",
      "[epoch 33]  Loss: 0.1554  Accuracy: 43.188 %\n",
      "[epoch 34]  Loss: 0.1551  Accuracy: 43.358 %\n",
      "[epoch 35]  Loss: 0.1550  Accuracy: 43.378 %\n",
      "[epoch 36]  Loss: 0.1544  Accuracy: 43.618 %\n",
      "[epoch 37]  Loss: 0.1538  Accuracy: 43.718 %\n",
      "[epoch 38]  Loss: 0.1551  Accuracy: 43.574 %\n",
      "[epoch 39]  Loss: 0.1543  Accuracy: 43.650 %\n",
      "[epoch 40]  Loss: 0.1530  Accuracy: 44.242 %\n",
      "[epoch 41]  Loss: 0.1520  Accuracy: 44.602 %\n",
      "[epoch 42]  Loss: 0.1513  Accuracy: 44.774 %\n",
      "[epoch 43]  Loss: 0.1508  Accuracy: 44.936 %\n",
      "[epoch 44]  Loss: 0.1505  Accuracy: 45.070 %\n",
      "[epoch 45]  Loss: 0.1501  Accuracy: 45.432 %\n",
      "[epoch 46]  Loss: 0.1498  Accuracy: 45.420 %\n",
      "[epoch 47]  Loss: 0.1496  Accuracy: 45.476 %\n",
      "[epoch 48]  Loss: 0.1489  Accuracy: 45.832 %\n",
      "[epoch 49]  Loss: 0.1490  Accuracy: 45.794 %\n",
      "[epoch 50]  Loss: 0.1484  Accuracy: 46.106 %\n",
      "[epoch 51]  Loss: 0.1492  Accuracy: 45.818 %\n",
      "[epoch 52]  Loss: 0.1484  Accuracy: 46.322 %\n",
      "[epoch 53]  Loss: 0.1482  Accuracy: 46.242 %\n",
      "[epoch 54]  Loss: 0.1468  Accuracy: 46.810 %\n",
      "[epoch 55]  Loss: 0.1464  Accuracy: 46.924 %\n",
      "[epoch 56]  Loss: 0.1457  Accuracy: 47.088 %\n",
      "[epoch 57]  Loss: 0.1453  Accuracy: 47.448 %\n",
      "[epoch 58]  Loss: 0.1451  Accuracy: 47.380 %\n",
      "[epoch 59]  Loss: 0.1449  Accuracy: 47.596 %\n",
      "[epoch 60]  Loss: 0.1444  Accuracy: 47.720 %\n",
      "[epoch 61]  Loss: 0.1444  Accuracy: 47.770 %\n",
      "[epoch 62]  Loss: 0.1445  Accuracy: 47.946 %\n",
      "[epoch 63]  Loss: 0.1434  Accuracy: 48.138 %\n",
      "[epoch 64]  Loss: 0.1433  Accuracy: 48.218 %\n",
      "[epoch 65]  Loss: 0.1432  Accuracy: 48.278 %\n",
      "[epoch 66]  Loss: 0.1424  Accuracy: 48.494 %\n",
      "[epoch 67]  Loss: 0.1424  Accuracy: 48.482 %\n",
      "[epoch 68]  Loss: 0.1421  Accuracy: 48.604 %\n",
      "[epoch 69]  Loss: 0.1412  Accuracy: 48.916 %\n",
      "[epoch 70]  Loss: 0.1409  Accuracy: 49.140 %\n",
      "[epoch 71]  Loss: 0.1406  Accuracy: 49.242 %\n",
      "[epoch 72]  Loss: 0.1402  Accuracy: 49.348 %\n",
      "[epoch 73]  Loss: 0.1414  Accuracy: 49.142 %\n",
      "[epoch 74]  Loss: 0.1396  Accuracy: 49.608 %\n",
      "[epoch 75]  Loss: 0.1393  Accuracy: 49.744 %\n",
      "[epoch 76]  Loss: 0.1393  Accuracy: 49.778 %\n",
      "[epoch 77]  Loss: 0.1393  Accuracy: 49.838 %\n",
      "[epoch 78]  Loss: 0.1387  Accuracy: 49.920 %\n",
      "[epoch 79]  Loss: 0.1379  Accuracy: 50.314 %\n",
      "[epoch 80]  Loss: 0.1379  Accuracy: 50.374 %\n",
      "[epoch 81]  Loss: 0.1383  Accuracy: 50.130 %\n",
      "[epoch 82]  Loss: 0.1387  Accuracy: 50.278 %\n",
      "[epoch 83]  Loss: 0.1382  Accuracy: 50.258 %\n",
      "[epoch 84]  Loss: 0.1373  Accuracy: 50.672 %\n",
      "[epoch 85]  Loss: 0.1368  Accuracy: 50.998 %\n",
      "[epoch 86]  Loss: 0.1363  Accuracy: 50.992 %\n",
      "[epoch 87]  Loss: 0.1365  Accuracy: 51.004 %\n",
      "[epoch 88]  Loss: 0.1360  Accuracy: 51.246 %\n",
      "[epoch 89]  Loss: 0.1358  Accuracy: 51.202 %\n",
      "[epoch 90]  Loss: 0.1353  Accuracy: 51.300 %\n",
      "[epoch 91]  Loss: 0.1354  Accuracy: 51.368 %\n",
      "[epoch 92]  Loss: 0.1350  Accuracy: 51.572 %\n",
      "[epoch 93]  Loss: 0.1365  Accuracy: 51.158 %\n",
      "[epoch 94]  Loss: 0.1349  Accuracy: 51.708 %\n",
      "[epoch 95]  Loss: 0.1344  Accuracy: 51.846 %\n",
      "[epoch 96]  Loss: 0.1347  Accuracy: 51.864 %\n",
      "[epoch 97]  Loss: 0.1338  Accuracy: 51.916 %\n",
      "[epoch 98]  Loss: 0.1336  Accuracy: 52.064 %\n",
      "[epoch 99]  Loss: 0.1330  Accuracy: 52.226 %\n",
      "[epoch 100]  Loss: 0.1327  Accuracy: 52.378 %\n",
      "[epoch 101]  Loss: 0.1327  Accuracy: 52.534 %\n",
      "[epoch 102]  Loss: 0.1327  Accuracy: 52.318 %\n",
      "[epoch 103]  Loss: 0.1322  Accuracy: 52.584 %\n",
      "[epoch 104]  Loss: 0.1318  Accuracy: 52.886 %\n",
      "[epoch 105]  Loss: 0.1316  Accuracy: 52.796 %\n",
      "[epoch 106]  Loss: 0.1315  Accuracy: 52.812 %\n",
      "[epoch 107]  Loss: 0.1308  Accuracy: 53.164 %\n",
      "[epoch 108]  Loss: 0.1305  Accuracy: 53.254 %\n",
      "[epoch 109]  Loss: 0.1305  Accuracy: 53.328 %\n",
      "[epoch 110]  Loss: 0.1303  Accuracy: 53.266 %\n",
      "[epoch 111]  Loss: 0.1303  Accuracy: 53.362 %\n",
      "[epoch 112]  Loss: 0.1298  Accuracy: 53.660 %\n",
      "[epoch 113]  Loss: 0.1303  Accuracy: 53.438 %\n",
      "[epoch 114]  Loss: 0.1301  Accuracy: 53.488 %\n",
      "[epoch 115]  Loss: 0.1292  Accuracy: 53.800 %\n",
      "[epoch 116]  Loss: 0.1293  Accuracy: 53.742 %\n",
      "[epoch 117]  Loss: 0.1296  Accuracy: 53.640 %\n",
      "[epoch 118]  Loss: 0.1305  Accuracy: 53.442 %\n",
      "[epoch 119]  Loss: 0.1297  Accuracy: 53.726 %\n",
      "[epoch 120]  Loss: 0.1292  Accuracy: 53.744 %\n",
      "[epoch 121]  Loss: 0.1300  Accuracy: 53.602 %\n",
      "[epoch 122]  Loss: 0.1286  Accuracy: 54.058 %\n",
      "[epoch 123]  Loss: 0.1282  Accuracy: 54.208 %\n",
      "[epoch 124]  Loss: 0.1276  Accuracy: 54.394 %\n",
      "[epoch 125]  Loss: 0.1275  Accuracy: 54.644 %\n",
      "[epoch 126]  Loss: 0.1277  Accuracy: 54.328 %\n",
      "[epoch 127]  Loss: 0.1278  Accuracy: 54.282 %\n",
      "[epoch 128]  Loss: 0.1277  Accuracy: 54.524 %\n",
      "[epoch 129]  Loss: 0.1267  Accuracy: 54.744 %\n",
      "[epoch 130]  Loss: 0.1266  Accuracy: 54.882 %\n",
      "[epoch 131]  Loss: 0.1264  Accuracy: 55.076 %\n",
      "[epoch 132]  Loss: 0.1260  Accuracy: 55.184 %\n",
      "[epoch 133]  Loss: 0.1264  Accuracy: 54.988 %\n",
      "[epoch 134]  Loss: 0.1266  Accuracy: 54.896 %\n",
      "[epoch 135]  Loss: 0.1261  Accuracy: 55.080 %\n",
      "[epoch 136]  Loss: 0.1257  Accuracy: 55.294 %\n",
      "[epoch 137]  Loss: 0.1254  Accuracy: 55.386 %\n",
      "[epoch 138]  Loss: 0.1253  Accuracy: 55.464 %\n",
      "[epoch 139]  Loss: 0.1261  Accuracy: 55.202 %\n",
      "[epoch 140]  Loss: 0.1272  Accuracy: 54.774 %\n",
      "[epoch 141]  Loss: 0.1265  Accuracy: 54.878 %\n",
      "[epoch 142]  Loss: 0.1258  Accuracy: 55.366 %\n",
      "[epoch 143]  Loss: 0.1253  Accuracy: 55.518 %\n",
      "[epoch 144]  Loss: 0.1247  Accuracy: 55.632 %\n",
      "[epoch 145]  Loss: 0.1252  Accuracy: 55.514 %\n",
      "[epoch 146]  Loss: 0.1245  Accuracy: 55.768 %\n",
      "[epoch 147]  Loss: 0.1240  Accuracy: 55.918 %\n",
      "[epoch 148]  Loss: 0.1237  Accuracy: 56.066 %\n",
      "[epoch 149]  Loss: 0.1235  Accuracy: 56.164 %\n",
      "[epoch 150]  Loss: 0.1236  Accuracy: 56.046 %\n",
      "[epoch 151]  Loss: 0.1243  Accuracy: 55.694 %\n",
      "[epoch 152]  Loss: 0.1235  Accuracy: 56.194 %\n",
      "[epoch 153]  Loss: 0.1232  Accuracy: 56.106 %\n",
      "[epoch 154]  Loss: 0.1232  Accuracy: 56.226 %\n",
      "[epoch 155]  Loss: 0.1230  Accuracy: 56.236 %\n",
      "[epoch 156]  Loss: 0.1229  Accuracy: 56.372 %\n",
      "[epoch 157]  Loss: 0.1233  Accuracy: 56.216 %\n",
      "[epoch 158]  Loss: 0.1225  Accuracy: 56.530 %\n",
      "[epoch 159]  Loss: 0.1221  Accuracy: 56.646 %\n",
      "[epoch 160]  Loss: 0.1222  Accuracy: 56.726 %\n",
      "[epoch 161]  Loss: 0.1223  Accuracy: 56.544 %\n",
      "[epoch 162]  Loss: 0.1220  Accuracy: 56.594 %\n",
      "[epoch 163]  Loss: 0.1216  Accuracy: 56.856 %\n",
      "[epoch 164]  Loss: 0.1214  Accuracy: 57.004 %\n",
      "[epoch 165]  Loss: 0.1215  Accuracy: 56.898 %\n",
      "[epoch 166]  Loss: 0.1215  Accuracy: 56.804 %\n",
      "[epoch 167]  Loss: 0.1212  Accuracy: 56.804 %\n",
      "[epoch 168]  Loss: 0.1209  Accuracy: 57.144 %\n",
      "[epoch 169]  Loss: 0.1207  Accuracy: 57.280 %\n",
      "[epoch 170]  Loss: 0.1205  Accuracy: 57.306 %\n",
      "[epoch 171]  Loss: 0.1208  Accuracy: 57.214 %\n",
      "[epoch 172]  Loss: 0.1215  Accuracy: 56.880 %\n",
      "[epoch 173]  Loss: 0.1209  Accuracy: 57.084 %\n",
      "[epoch 174]  Loss: 0.1208  Accuracy: 57.142 %\n",
      "[epoch 175]  Loss: 0.1200  Accuracy: 57.480 %\n",
      "[epoch 176]  Loss: 0.1198  Accuracy: 57.654 %\n",
      "[epoch 177]  Loss: 0.1194  Accuracy: 57.686 %\n",
      "[epoch 178]  Loss: 0.1195  Accuracy: 57.664 %\n",
      "[epoch 179]  Loss: 0.1196  Accuracy: 57.680 %\n",
      "[epoch 180]  Loss: 0.1199  Accuracy: 57.366 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 181]  Loss: 0.1201  Accuracy: 57.508 %\n",
      "[epoch 182]  Loss: 0.1204  Accuracy: 57.326 %\n",
      "[epoch 183]  Loss: 0.1194  Accuracy: 57.706 %\n",
      "[epoch 184]  Loss: 0.1192  Accuracy: 57.760 %\n",
      "[epoch 185]  Loss: 0.1193  Accuracy: 57.662 %\n",
      "[epoch 186]  Loss: 0.1190  Accuracy: 57.784 %\n",
      "[epoch 187]  Loss: 0.1196  Accuracy: 57.560 %\n",
      "[epoch 188]  Loss: 0.1197  Accuracy: 57.668 %\n",
      "[epoch 189]  Loss: 0.1194  Accuracy: 57.684 %\n",
      "[epoch 190]  Loss: 0.1186  Accuracy: 58.206 %\n",
      "[epoch 191]  Loss: 0.1185  Accuracy: 58.040 %\n",
      "[epoch 192]  Loss: 0.1179  Accuracy: 58.274 %\n",
      "[epoch 193]  Loss: 0.1178  Accuracy: 58.488 %\n",
      "[epoch 194]  Loss: 0.1181  Accuracy: 58.220 %\n",
      "[epoch 195]  Loss: 0.1173  Accuracy: 58.520 %\n",
      "[epoch 196]  Loss: 0.1171  Accuracy: 58.712 %\n",
      "[epoch 197]  Loss: 0.1170  Accuracy: 58.672 %\n",
      "[epoch 198]  Loss: 0.1172  Accuracy: 58.624 %\n",
      "[epoch 199]  Loss: 0.1181  Accuracy: 58.298 %\n",
      "[epoch 200]  Loss: 0.1184  Accuracy: 58.078 %\n",
      "[epoch 201]  Loss: 0.1172  Accuracy: 58.530 %\n",
      "[epoch 202]  Loss: 0.1166  Accuracy: 58.778 %\n",
      "[epoch 203]  Loss: 0.1165  Accuracy: 58.816 %\n",
      "[epoch 204]  Loss: 0.1167  Accuracy: 58.840 %\n",
      "[epoch 205]  Loss: 0.1164  Accuracy: 58.976 %\n",
      "[epoch 206]  Loss: 0.1166  Accuracy: 58.832 %\n",
      "[epoch 207]  Loss: 0.1167  Accuracy: 58.748 %\n",
      "[epoch 208]  Loss: 0.1169  Accuracy: 58.762 %\n",
      "[epoch 209]  Loss: 0.1162  Accuracy: 59.064 %\n",
      "[epoch 210]  Loss: 0.1164  Accuracy: 58.918 %\n",
      "[epoch 211]  Loss: 0.1166  Accuracy: 58.624 %\n",
      "[epoch 212]  Loss: 0.1171  Accuracy: 58.556 %\n",
      "[epoch 213]  Loss: 0.1167  Accuracy: 58.818 %\n",
      "[epoch 214]  Loss: 0.1163  Accuracy: 58.848 %\n",
      "[epoch 215]  Loss: 0.1158  Accuracy: 59.358 %\n",
      "[epoch 216]  Loss: 0.1155  Accuracy: 59.198 %\n",
      "[epoch 217]  Loss: 0.1152  Accuracy: 59.290 %\n",
      "[epoch 218]  Loss: 0.1152  Accuracy: 59.476 %\n",
      "[epoch 219]  Loss: 0.1148  Accuracy: 59.520 %\n",
      "[epoch 220]  Loss: 0.1148  Accuracy: 59.562 %\n",
      "[epoch 221]  Loss: 0.1146  Accuracy: 59.700 %\n",
      "[epoch 222]  Loss: 0.1146  Accuracy: 59.688 %\n",
      "[epoch 223]  Loss: 0.1144  Accuracy: 59.712 %\n",
      "[epoch 224]  Loss: 0.1146  Accuracy: 59.586 %\n",
      "[epoch 225]  Loss: 0.1150  Accuracy: 59.526 %\n",
      "[epoch 226]  Loss: 0.1148  Accuracy: 59.422 %\n",
      "[epoch 227]  Loss: 0.1144  Accuracy: 59.672 %\n",
      "[epoch 228]  Loss: 0.1146  Accuracy: 59.640 %\n",
      "[epoch 229]  Loss: 0.1143  Accuracy: 59.836 %\n",
      "[epoch 230]  Loss: 0.1150  Accuracy: 59.254 %\n",
      "[epoch 231]  Loss: 0.1152  Accuracy: 59.404 %\n",
      "[epoch 232]  Loss: 0.1143  Accuracy: 59.622 %\n",
      "[epoch 233]  Loss: 0.1142  Accuracy: 59.914 %\n",
      "[epoch 234]  Loss: 0.1146  Accuracy: 59.808 %\n",
      "[epoch 235]  Loss: 0.1155  Accuracy: 59.164 %\n",
      "[epoch 236]  Loss: 0.1150  Accuracy: 59.502 %\n",
      "[epoch 237]  Loss: 0.1145  Accuracy: 59.624 %\n",
      "[epoch 238]  Loss: 0.1138  Accuracy: 59.924 %\n",
      "[epoch 239]  Loss: 0.1137  Accuracy: 59.934 %\n",
      "[epoch 240]  Loss: 0.1142  Accuracy: 59.708 %\n",
      "[epoch 241]  Loss: 0.1134  Accuracy: 60.082 %\n",
      "[epoch 242]  Loss: 0.1131  Accuracy: 60.262 %\n",
      "[epoch 243]  Loss: 0.1130  Accuracy: 60.168 %\n",
      "[epoch 244]  Loss: 0.1131  Accuracy: 60.356 %\n",
      "[epoch 245]  Loss: 0.1126  Accuracy: 60.460 %\n",
      "[epoch 246]  Loss: 0.1124  Accuracy: 60.440 %\n",
      "[epoch 247]  Loss: 0.1122  Accuracy: 60.630 %\n",
      "[epoch 248]  Loss: 0.1128  Accuracy: 60.398 %\n",
      "[epoch 249]  Loss: 0.1123  Accuracy: 60.536 %\n",
      "[epoch 250]  Loss: 0.1120  Accuracy: 60.622 %\n",
      "[epoch 251]  Loss: 0.1122  Accuracy: 60.560 %\n",
      "[epoch 252]  Loss: 0.1121  Accuracy: 60.612 %\n",
      "[epoch 253]  Loss: 0.1119  Accuracy: 60.688 %\n",
      "[epoch 254]  Loss: 0.1119  Accuracy: 60.662 %\n",
      "[epoch 255]  Loss: 0.1116  Accuracy: 60.866 %\n",
      "[epoch 256]  Loss: 0.1123  Accuracy: 60.476 %\n",
      "[epoch 257]  Loss: 0.1115  Accuracy: 60.736 %\n",
      "[epoch 258]  Loss: 0.1117  Accuracy: 60.758 %\n",
      "[epoch 259]  Loss: 0.1118  Accuracy: 60.636 %\n",
      "[epoch 260]  Loss: 0.1121  Accuracy: 60.550 %\n",
      "[epoch 261]  Loss: 0.1117  Accuracy: 60.812 %\n",
      "[epoch 262]  Loss: 0.1113  Accuracy: 60.966 %\n",
      "[epoch 263]  Loss: 0.1109  Accuracy: 61.042 %\n",
      "[epoch 264]  Loss: 0.1112  Accuracy: 60.916 %\n",
      "[epoch 265]  Loss: 0.1111  Accuracy: 60.834 %\n",
      "[epoch 266]  Loss: 0.1114  Accuracy: 61.012 %\n",
      "[epoch 267]  Loss: 0.1111  Accuracy: 60.864 %\n",
      "[epoch 268]  Loss: 0.1108  Accuracy: 60.992 %\n",
      "[epoch 269]  Loss: 0.1112  Accuracy: 60.934 %\n",
      "[epoch 270]  Loss: 0.1115  Accuracy: 60.782 %\n",
      "[epoch 271]  Loss: 0.1110  Accuracy: 60.790 %\n",
      "[epoch 272]  Loss: 0.1109  Accuracy: 61.020 %\n",
      "[epoch 273]  Loss: 0.1109  Accuracy: 60.914 %\n",
      "[epoch 274]  Loss: 0.1111  Accuracy: 61.086 %\n",
      "[epoch 275]  Loss: 0.1114  Accuracy: 61.146 %\n",
      "[epoch 276]  Loss: 0.1129  Accuracy: 60.360 %\n",
      "[epoch 277]  Loss: 0.1128  Accuracy: 60.350 %\n",
      "[epoch 278]  Loss: 0.1120  Accuracy: 60.674 %\n",
      "[epoch 279]  Loss: 0.1108  Accuracy: 60.964 %\n",
      "[epoch 280]  Loss: 0.1101  Accuracy: 61.290 %\n",
      "[epoch 281]  Loss: 0.1101  Accuracy: 61.322 %\n",
      "[epoch 282]  Loss: 0.1096  Accuracy: 61.628 %\n",
      "[epoch 283]  Loss: 0.1095  Accuracy: 61.554 %\n",
      "[epoch 284]  Loss: 0.1092  Accuracy: 61.706 %\n",
      "[epoch 285]  Loss: 0.1092  Accuracy: 61.702 %\n",
      "[epoch 286]  Loss: 0.1093  Accuracy: 61.580 %\n",
      "[epoch 287]  Loss: 0.1089  Accuracy: 61.862 %\n",
      "[epoch 288]  Loss: 0.1092  Accuracy: 61.640 %\n",
      "[epoch 289]  Loss: 0.1098  Accuracy: 61.430 %\n",
      "[epoch 290]  Loss: 0.1096  Accuracy: 61.522 %\n",
      "[epoch 291]  Loss: 0.1089  Accuracy: 61.870 %\n",
      "[epoch 292]  Loss: 0.1095  Accuracy: 61.466 %\n",
      "[epoch 293]  Loss: 0.1091  Accuracy: 61.762 %\n",
      "[epoch 294]  Loss: 0.1091  Accuracy: 61.680 %\n",
      "[epoch 295]  Loss: 0.1089  Accuracy: 61.686 %\n",
      "[epoch 296]  Loss: 0.1090  Accuracy: 61.854 %\n",
      "[epoch 297]  Loss: 0.1087  Accuracy: 61.954 %\n",
      "[epoch 298]  Loss: 0.1084  Accuracy: 62.046 %\n",
      "[epoch 299]  Loss: 0.1091  Accuracy: 61.806 %\n",
      "[epoch 300]  Loss: 0.1101  Accuracy: 61.478 %\n",
      "[epoch 301]  Loss: 0.1097  Accuracy: 61.414 %\n",
      "[epoch 302]  Loss: 0.1088  Accuracy: 61.714 %\n",
      "[epoch 303]  Loss: 0.1082  Accuracy: 61.928 %\n",
      "[epoch 304]  Loss: 0.1082  Accuracy: 62.120 %\n",
      "[epoch 305]  Loss: 0.1083  Accuracy: 62.084 %\n",
      "[epoch 306]  Loss: 0.1078  Accuracy: 62.244 %\n",
      "[epoch 307]  Loss: 0.1079  Accuracy: 62.186 %\n",
      "[epoch 308]  Loss: 0.1077  Accuracy: 62.340 %\n",
      "[epoch 309]  Loss: 0.1076  Accuracy: 62.376 %\n",
      "[epoch 310]  Loss: 0.1073  Accuracy: 62.364 %\n",
      "[epoch 311]  Loss: 0.1072  Accuracy: 62.446 %\n",
      "[epoch 312]  Loss: 0.1072  Accuracy: 62.472 %\n",
      "[epoch 313]  Loss: 0.1072  Accuracy: 62.520 %\n",
      "[epoch 314]  Loss: 0.1069  Accuracy: 62.566 %\n",
      "[epoch 315]  Loss: 0.1073  Accuracy: 62.448 %\n",
      "[epoch 316]  Loss: 0.1076  Accuracy: 62.166 %\n",
      "[epoch 317]  Loss: 0.1087  Accuracy: 61.894 %\n",
      "[epoch 318]  Loss: 0.1085  Accuracy: 61.860 %\n",
      "[epoch 319]  Loss: 0.1073  Accuracy: 62.416 %\n",
      "[epoch 320]  Loss: 0.1074  Accuracy: 62.418 %\n",
      "[epoch 321]  Loss: 0.1072  Accuracy: 62.476 %\n",
      "[epoch 322]  Loss: 0.1070  Accuracy: 62.436 %\n",
      "[epoch 323]  Loss: 0.1069  Accuracy: 62.584 %\n",
      "[epoch 324]  Loss: 0.1067  Accuracy: 62.586 %\n",
      "[epoch 325]  Loss: 0.1065  Accuracy: 62.774 %\n",
      "[epoch 326]  Loss: 0.1062  Accuracy: 62.952 %\n",
      "[epoch 327]  Loss: 0.1062  Accuracy: 62.906 %\n",
      "[epoch 328]  Loss: 0.1064  Accuracy: 62.906 %\n",
      "[epoch 329]  Loss: 0.1068  Accuracy: 62.602 %\n",
      "[epoch 330]  Loss: 0.1072  Accuracy: 62.390 %\n",
      "[epoch 331]  Loss: 0.1071  Accuracy: 62.490 %\n",
      "[epoch 332]  Loss: 0.1084  Accuracy: 62.048 %\n",
      "[epoch 333]  Loss: 0.1068  Accuracy: 62.662 %\n",
      "[epoch 334]  Loss: 0.1077  Accuracy: 62.358 %\n",
      "[epoch 335]  Loss: 0.1072  Accuracy: 62.412 %\n",
      "[epoch 336]  Loss: 0.1069  Accuracy: 62.636 %\n",
      "[epoch 337]  Loss: 0.1064  Accuracy: 62.788 %\n",
      "[epoch 338]  Loss: 0.1060  Accuracy: 62.876 %\n",
      "[epoch 339]  Loss: 0.1056  Accuracy: 63.176 %\n",
      "[epoch 340]  Loss: 0.1057  Accuracy: 63.096 %\n",
      "[epoch 341]  Loss: 0.1057  Accuracy: 63.042 %\n",
      "[epoch 342]  Loss: 0.1054  Accuracy: 63.156 %\n",
      "[epoch 343]  Loss: 0.1053  Accuracy: 63.236 %\n",
      "[epoch 344]  Loss: 0.1056  Accuracy: 63.192 %\n",
      "[epoch 345]  Loss: 0.1063  Accuracy: 62.824 %\n",
      "[epoch 346]  Loss: 0.1062  Accuracy: 62.784 %\n",
      "[epoch 347]  Loss: 0.1062  Accuracy: 62.778 %\n",
      "[epoch 348]  Loss: 0.1054  Accuracy: 63.078 %\n",
      "[epoch 349]  Loss: 0.1054  Accuracy: 63.106 %\n",
      "[epoch 350]  Loss: 0.1050  Accuracy: 63.350 %\n",
      "[epoch 351]  Loss: 0.1046  Accuracy: 63.522 %\n",
      "[epoch 352]  Loss: 0.1054  Accuracy: 63.120 %\n",
      "[epoch 353]  Loss: 0.1048  Accuracy: 63.342 %\n",
      "[epoch 354]  Loss: 0.1050  Accuracy: 63.308 %\n",
      "[epoch 355]  Loss: 0.1049  Accuracy: 63.372 %\n",
      "[epoch 356]  Loss: 0.1050  Accuracy: 63.186 %\n",
      "[epoch 357]  Loss: 0.1048  Accuracy: 63.262 %\n",
      "[epoch 358]  Loss: 0.1048  Accuracy: 63.270 %\n",
      "[epoch 359]  Loss: 0.1043  Accuracy: 63.560 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 360]  Loss: 0.1045  Accuracy: 63.546 %\n",
      "[epoch 361]  Loss: 0.1044  Accuracy: 63.550 %\n",
      "[epoch 362]  Loss: 0.1043  Accuracy: 63.668 %\n",
      "[epoch 363]  Loss: 0.1040  Accuracy: 63.706 %\n",
      "[epoch 364]  Loss: 0.1043  Accuracy: 63.672 %\n",
      "[epoch 365]  Loss: 0.1037  Accuracy: 63.788 %\n",
      "[epoch 366]  Loss: 0.1039  Accuracy: 63.854 %\n",
      "[epoch 367]  Loss: 0.1051  Accuracy: 63.330 %\n",
      "[epoch 368]  Loss: 0.1047  Accuracy: 63.532 %\n",
      "[epoch 369]  Loss: 0.1052  Accuracy: 63.156 %\n",
      "[epoch 370]  Loss: 0.1053  Accuracy: 63.418 %\n",
      "[epoch 371]  Loss: 0.1051  Accuracy: 63.130 %\n",
      "[epoch 372]  Loss: 0.1046  Accuracy: 63.406 %\n",
      "[epoch 373]  Loss: 0.1039  Accuracy: 63.678 %\n",
      "[epoch 374]  Loss: 0.1036  Accuracy: 63.872 %\n",
      "[epoch 375]  Loss: 0.1035  Accuracy: 63.968 %\n",
      "[epoch 376]  Loss: 0.1036  Accuracy: 63.848 %\n",
      "[epoch 377]  Loss: 0.1041  Accuracy: 63.706 %\n",
      "[epoch 378]  Loss: 0.1048  Accuracy: 63.320 %\n",
      "[epoch 379]  Loss: 0.1053  Accuracy: 63.132 %\n",
      "[epoch 380]  Loss: 0.1047  Accuracy: 63.380 %\n",
      "[epoch 381]  Loss: 0.1038  Accuracy: 63.828 %\n",
      "[epoch 382]  Loss: 0.1032  Accuracy: 64.120 %\n",
      "[epoch 383]  Loss: 0.1034  Accuracy: 63.788 %\n",
      "[epoch 384]  Loss: 0.1033  Accuracy: 64.140 %\n",
      "[epoch 385]  Loss: 0.1028  Accuracy: 64.260 %\n",
      "[epoch 386]  Loss: 0.1027  Accuracy: 64.188 %\n",
      "[epoch 387]  Loss: 0.1027  Accuracy: 64.162 %\n",
      "[epoch 388]  Loss: 0.1036  Accuracy: 63.714 %\n",
      "[epoch 389]  Loss: 0.1035  Accuracy: 63.946 %\n",
      "[epoch 390]  Loss: 0.1027  Accuracy: 64.198 %\n",
      "[epoch 391]  Loss: 0.1026  Accuracy: 64.170 %\n",
      "[epoch 392]  Loss: 0.1028  Accuracy: 64.102 %\n",
      "[epoch 393]  Loss: 0.1030  Accuracy: 64.122 %\n",
      "[epoch 394]  Loss: 0.1027  Accuracy: 64.172 %\n",
      "[epoch 395]  Loss: 0.1025  Accuracy: 64.240 %\n",
      "[epoch 396]  Loss: 0.1023  Accuracy: 64.280 %\n",
      "[epoch 397]  Loss: 0.1029  Accuracy: 64.120 %\n",
      "[epoch 398]  Loss: 0.1022  Accuracy: 64.408 %\n",
      "[epoch 399]  Loss: 0.1018  Accuracy: 64.542 %\n",
      "[epoch 400]  Loss: 0.1019  Accuracy: 64.364 %\n",
      "[epoch 401]  Loss: 0.1016  Accuracy: 64.580 %\n",
      "[epoch 402]  Loss: 0.1021  Accuracy: 64.444 %\n",
      "[epoch 403]  Loss: 0.1019  Accuracy: 64.410 %\n",
      "[epoch 404]  Loss: 0.1018  Accuracy: 64.468 %\n",
      "[epoch 405]  Loss: 0.1020  Accuracy: 64.292 %\n",
      "[epoch 406]  Loss: 0.1020  Accuracy: 64.548 %\n",
      "[epoch 407]  Loss: 0.1021  Accuracy: 64.372 %\n",
      "[epoch 408]  Loss: 0.1021  Accuracy: 64.468 %\n",
      "[epoch 409]  Loss: 0.1016  Accuracy: 64.490 %\n",
      "[epoch 410]  Loss: 0.1025  Accuracy: 64.310 %\n",
      "[epoch 411]  Loss: 0.1026  Accuracy: 64.026 %\n",
      "[epoch 412]  Loss: 0.1015  Accuracy: 64.536 %\n",
      "[epoch 413]  Loss: 0.1017  Accuracy: 64.410 %\n",
      "[epoch 414]  Loss: 0.1013  Accuracy: 64.626 %\n",
      "[epoch 415]  Loss: 0.1011  Accuracy: 64.798 %\n",
      "[epoch 416]  Loss: 0.1013  Accuracy: 64.636 %\n",
      "[epoch 417]  Loss: 0.1012  Accuracy: 64.776 %\n",
      "[epoch 418]  Loss: 0.1010  Accuracy: 64.852 %\n",
      "[epoch 419]  Loss: 0.1016  Accuracy: 64.598 %\n",
      "[epoch 420]  Loss: 0.1015  Accuracy: 64.734 %\n",
      "[epoch 421]  Loss: 0.1010  Accuracy: 64.798 %\n",
      "[epoch 422]  Loss: 0.1009  Accuracy: 64.862 %\n",
      "[epoch 423]  Loss: 0.1010  Accuracy: 64.832 %\n",
      "[epoch 424]  Loss: 0.1011  Accuracy: 64.758 %\n",
      "[epoch 425]  Loss: 0.1010  Accuracy: 64.876 %\n",
      "[epoch 426]  Loss: 0.1007  Accuracy: 64.904 %\n",
      "[epoch 427]  Loss: 0.1007  Accuracy: 64.890 %\n",
      "[epoch 428]  Loss: 0.1005  Accuracy: 64.968 %\n",
      "[epoch 429]  Loss: 0.1012  Accuracy: 64.792 %\n",
      "[epoch 430]  Loss: 0.1030  Accuracy: 64.028 %\n",
      "[epoch 431]  Loss: 0.1032  Accuracy: 63.976 %\n",
      "[epoch 432]  Loss: 0.1027  Accuracy: 64.328 %\n",
      "[epoch 433]  Loss: 0.1017  Accuracy: 64.544 %\n",
      "[epoch 434]  Loss: 0.1023  Accuracy: 64.320 %\n",
      "[epoch 435]  Loss: 0.1009  Accuracy: 64.830 %\n",
      "[epoch 436]  Loss: 0.1012  Accuracy: 64.752 %\n",
      "[epoch 437]  Loss: 0.1011  Accuracy: 64.762 %\n",
      "[epoch 438]  Loss: 0.1006  Accuracy: 65.042 %\n",
      "[epoch 439]  Loss: 0.1005  Accuracy: 64.934 %\n",
      "[epoch 440]  Loss: 0.0999  Accuracy: 65.238 %\n",
      "[epoch 441]  Loss: 0.1003  Accuracy: 65.074 %\n",
      "[epoch 442]  Loss: 0.1001  Accuracy: 65.048 %\n",
      "[epoch 443]  Loss: 0.0998  Accuracy: 65.296 %\n",
      "[epoch 444]  Loss: 0.0993  Accuracy: 65.438 %\n",
      "[epoch 445]  Loss: 0.0997  Accuracy: 65.348 %\n",
      "[epoch 446]  Loss: 0.0997  Accuracy: 65.340 %\n",
      "[epoch 447]  Loss: 0.0996  Accuracy: 65.340 %\n",
      "[epoch 448]  Loss: 0.0996  Accuracy: 65.370 %\n",
      "[epoch 449]  Loss: 0.0997  Accuracy: 65.304 %\n",
      "[epoch 450]  Loss: 0.1000  Accuracy: 65.148 %\n",
      "[epoch 451]  Loss: 0.0997  Accuracy: 65.198 %\n",
      "[epoch 452]  Loss: 0.0997  Accuracy: 65.338 %\n",
      "[epoch 453]  Loss: 0.0994  Accuracy: 65.346 %\n",
      "[epoch 454]  Loss: 0.0991  Accuracy: 65.604 %\n",
      "[epoch 455]  Loss: 0.0989  Accuracy: 65.558 %\n",
      "[epoch 456]  Loss: 0.0987  Accuracy: 65.672 %\n",
      "[epoch 457]  Loss: 0.0989  Accuracy: 65.640 %\n",
      "[epoch 458]  Loss: 0.0992  Accuracy: 65.532 %\n",
      "[epoch 459]  Loss: 0.0991  Accuracy: 65.456 %\n",
      "[epoch 460]  Loss: 0.0989  Accuracy: 65.630 %\n",
      "[epoch 461]  Loss: 0.0984  Accuracy: 65.706 %\n",
      "[epoch 462]  Loss: 0.0987  Accuracy: 65.680 %\n",
      "[epoch 463]  Loss: 0.0992  Accuracy: 65.470 %\n",
      "[epoch 464]  Loss: 0.0986  Accuracy: 65.712 %\n",
      "[epoch 465]  Loss: 0.0992  Accuracy: 65.370 %\n",
      "[epoch 466]  Loss: 0.0993  Accuracy: 65.248 %\n",
      "[epoch 467]  Loss: 0.1001  Accuracy: 65.240 %\n",
      "[epoch 468]  Loss: 0.0994  Accuracy: 65.480 %\n",
      "[epoch 469]  Loss: 0.0988  Accuracy: 65.552 %\n",
      "[epoch 470]  Loss: 0.0982  Accuracy: 65.856 %\n",
      "[epoch 471]  Loss: 0.0981  Accuracy: 65.858 %\n",
      "[epoch 472]  Loss: 0.0988  Accuracy: 65.412 %\n",
      "[epoch 473]  Loss: 0.0981  Accuracy: 65.810 %\n",
      "[epoch 474]  Loss: 0.0981  Accuracy: 65.850 %\n",
      "[epoch 475]  Loss: 0.0985  Accuracy: 65.690 %\n",
      "[epoch 476]  Loss: 0.0977  Accuracy: 65.974 %\n",
      "[epoch 477]  Loss: 0.0982  Accuracy: 65.860 %\n",
      "[epoch 478]  Loss: 0.0986  Accuracy: 65.662 %\n",
      "[epoch 479]  Loss: 0.0990  Accuracy: 65.430 %\n",
      "[epoch 480]  Loss: 0.1010  Accuracy: 64.844 %\n",
      "[epoch 481]  Loss: 0.1016  Accuracy: 64.418 %\n",
      "[epoch 482]  Loss: 0.0996  Accuracy: 65.206 %\n",
      "[epoch 483]  Loss: 0.0993  Accuracy: 65.318 %\n",
      "[epoch 484]  Loss: 0.0986  Accuracy: 65.502 %\n",
      "[epoch 485]  Loss: 0.0987  Accuracy: 65.626 %\n",
      "[epoch 486]  Loss: 0.0981  Accuracy: 65.822 %\n",
      "[epoch 487]  Loss: 0.0972  Accuracy: 66.172 %\n",
      "[epoch 488]  Loss: 0.0973  Accuracy: 66.064 %\n",
      "[epoch 489]  Loss: 0.0976  Accuracy: 66.060 %\n",
      "[epoch 490]  Loss: 0.0979  Accuracy: 65.814 %\n",
      "[epoch 491]  Loss: 0.0971  Accuracy: 66.404 %\n",
      "[epoch 492]  Loss: 0.0968  Accuracy: 66.364 %\n",
      "[epoch 493]  Loss: 0.0968  Accuracy: 66.434 %\n",
      "[epoch 494]  Loss: 0.0969  Accuracy: 66.400 %\n",
      "[epoch 495]  Loss: 0.0970  Accuracy: 66.368 %\n",
      "[epoch 496]  Loss: 0.0966  Accuracy: 66.472 %\n",
      "[epoch 497]  Loss: 0.0965  Accuracy: 66.486 %\n",
      "[epoch 498]  Loss: 0.0968  Accuracy: 66.378 %\n",
      "[epoch 499]  Loss: 0.0979  Accuracy: 66.056 %\n",
      "[epoch 500]  Loss: 0.0985  Accuracy: 65.760 %\n",
      "[epoch 501]  Loss: 0.0992  Accuracy: 65.490 %\n",
      "[epoch 502]  Loss: 0.0981  Accuracy: 65.932 %\n",
      "[epoch 503]  Loss: 0.0970  Accuracy: 66.310 %\n",
      "[epoch 504]  Loss: 0.0967  Accuracy: 66.360 %\n",
      "[epoch 505]  Loss: 0.0967  Accuracy: 66.292 %\n",
      "[epoch 506]  Loss: 0.0962  Accuracy: 66.630 %\n",
      "[epoch 507]  Loss: 0.0961  Accuracy: 66.706 %\n",
      "[epoch 508]  Loss: 0.0962  Accuracy: 66.564 %\n",
      "[epoch 509]  Loss: 0.0967  Accuracy: 66.454 %\n",
      "[epoch 510]  Loss: 0.0978  Accuracy: 65.938 %\n",
      "[epoch 511]  Loss: 0.0973  Accuracy: 66.372 %\n",
      "[epoch 512]  Loss: 0.0971  Accuracy: 66.182 %\n",
      "[epoch 513]  Loss: 0.0984  Accuracy: 65.864 %\n",
      "[epoch 514]  Loss: 0.0974  Accuracy: 66.104 %\n",
      "[epoch 515]  Loss: 0.0967  Accuracy: 66.246 %\n",
      "[epoch 516]  Loss: 0.0964  Accuracy: 66.446 %\n",
      "[epoch 517]  Loss: 0.0966  Accuracy: 66.592 %\n",
      "[epoch 518]  Loss: 0.0964  Accuracy: 66.734 %\n",
      "[epoch 519]  Loss: 0.0969  Accuracy: 66.326 %\n",
      "[epoch 520]  Loss: 0.0965  Accuracy: 66.442 %\n",
      "[epoch 521]  Loss: 0.0960  Accuracy: 66.594 %\n",
      "[epoch 522]  Loss: 0.0959  Accuracy: 66.704 %\n",
      "[epoch 523]  Loss: 0.0964  Accuracy: 66.464 %\n",
      "[epoch 524]  Loss: 0.0958  Accuracy: 66.750 %\n",
      "[epoch 525]  Loss: 0.0954  Accuracy: 66.796 %\n",
      "[epoch 526]  Loss: 0.0952  Accuracy: 67.074 %\n",
      "[epoch 527]  Loss: 0.0953  Accuracy: 66.998 %\n",
      "[epoch 528]  Loss: 0.0953  Accuracy: 66.794 %\n",
      "[epoch 529]  Loss: 0.0959  Accuracy: 66.700 %\n",
      "[epoch 530]  Loss: 0.0960  Accuracy: 66.542 %\n",
      "[epoch 531]  Loss: 0.0962  Accuracy: 66.756 %\n",
      "[epoch 532]  Loss: 0.0982  Accuracy: 65.858 %\n",
      "[epoch 533]  Loss: 0.0992  Accuracy: 65.418 %\n",
      "[epoch 534]  Loss: 0.0987  Accuracy: 65.366 %\n",
      "[epoch 535]  Loss: 0.0977  Accuracy: 65.848 %\n",
      "[epoch 536]  Loss: 0.0966  Accuracy: 66.148 %\n",
      "[epoch 537]  Loss: 0.0964  Accuracy: 66.418 %\n",
      "[epoch 538]  Loss: 0.0968  Accuracy: 66.124 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 539]  Loss: 0.0959  Accuracy: 66.686 %\n",
      "[epoch 540]  Loss: 0.0957  Accuracy: 66.586 %\n",
      "[epoch 541]  Loss: 0.0952  Accuracy: 66.898 %\n",
      "[epoch 542]  Loss: 0.0947  Accuracy: 67.164 %\n",
      "[epoch 543]  Loss: 0.0949  Accuracy: 67.088 %\n",
      "[epoch 544]  Loss: 0.0950  Accuracy: 67.044 %\n",
      "[epoch 545]  Loss: 0.0946  Accuracy: 67.196 %\n",
      "[epoch 546]  Loss: 0.0951  Accuracy: 67.098 %\n",
      "[epoch 547]  Loss: 0.0946  Accuracy: 67.300 %\n",
      "[epoch 548]  Loss: 0.0943  Accuracy: 67.254 %\n",
      "[epoch 549]  Loss: 0.0944  Accuracy: 67.332 %\n",
      "[epoch 550]  Loss: 0.0946  Accuracy: 67.142 %\n",
      "[epoch 551]  Loss: 0.0947  Accuracy: 67.120 %\n",
      "[epoch 552]  Loss: 0.0943  Accuracy: 67.214 %\n",
      "[epoch 553]  Loss: 0.0942  Accuracy: 67.250 %\n",
      "[epoch 554]  Loss: 0.0942  Accuracy: 67.324 %\n",
      "[epoch 555]  Loss: 0.0948  Accuracy: 67.162 %\n",
      "[epoch 556]  Loss: 0.0954  Accuracy: 66.894 %\n",
      "[epoch 557]  Loss: 0.0949  Accuracy: 67.038 %\n",
      "[epoch 558]  Loss: 0.0953  Accuracy: 66.762 %\n",
      "[epoch 559]  Loss: 0.0953  Accuracy: 66.832 %\n",
      "[epoch 560]  Loss: 0.0953  Accuracy: 66.990 %\n",
      "[epoch 561]  Loss: 0.0950  Accuracy: 66.928 %\n",
      "[epoch 562]  Loss: 0.0949  Accuracy: 66.922 %\n",
      "[epoch 563]  Loss: 0.0946  Accuracy: 66.994 %\n",
      "[epoch 564]  Loss: 0.0943  Accuracy: 67.240 %\n",
      "[epoch 565]  Loss: 0.0939  Accuracy: 67.224 %\n",
      "[epoch 566]  Loss: 0.0939  Accuracy: 67.418 %\n",
      "[epoch 567]  Loss: 0.0936  Accuracy: 67.608 %\n",
      "[epoch 568]  Loss: 0.0937  Accuracy: 67.506 %\n",
      "[epoch 569]  Loss: 0.0939  Accuracy: 67.400 %\n",
      "[epoch 570]  Loss: 0.0935  Accuracy: 67.470 %\n",
      "[epoch 571]  Loss: 0.0939  Accuracy: 67.366 %\n",
      "[epoch 572]  Loss: 0.0937  Accuracy: 67.360 %\n",
      "[epoch 573]  Loss: 0.0944  Accuracy: 67.324 %\n",
      "[epoch 574]  Loss: 0.0942  Accuracy: 67.224 %\n",
      "[epoch 575]  Loss: 0.0943  Accuracy: 67.372 %\n",
      "[epoch 576]  Loss: 0.0949  Accuracy: 67.122 %\n",
      "[epoch 577]  Loss: 0.0963  Accuracy: 66.440 %\n",
      "[epoch 578]  Loss: 0.0987  Accuracy: 65.766 %\n",
      "[epoch 579]  Loss: 0.0978  Accuracy: 65.952 %\n",
      "[epoch 580]  Loss: 0.0955  Accuracy: 66.794 %\n",
      "[epoch 581]  Loss: 0.0944  Accuracy: 67.204 %\n",
      "[epoch 582]  Loss: 0.0943  Accuracy: 67.182 %\n",
      "[epoch 583]  Loss: 0.0940  Accuracy: 67.248 %\n",
      "[epoch 584]  Loss: 0.0931  Accuracy: 67.728 %\n",
      "[epoch 585]  Loss: 0.0928  Accuracy: 67.832 %\n",
      "[epoch 586]  Loss: 0.0928  Accuracy: 67.986 %\n",
      "[epoch 587]  Loss: 0.0929  Accuracy: 67.730 %\n",
      "[epoch 588]  Loss: 0.0931  Accuracy: 67.782 %\n",
      "[epoch 589]  Loss: 0.0928  Accuracy: 67.754 %\n",
      "[epoch 590]  Loss: 0.0927  Accuracy: 67.878 %\n",
      "[epoch 591]  Loss: 0.0927  Accuracy: 67.830 %\n",
      "[epoch 592]  Loss: 0.0933  Accuracy: 67.546 %\n",
      "[epoch 593]  Loss: 0.0942  Accuracy: 67.246 %\n",
      "[epoch 594]  Loss: 0.0937  Accuracy: 67.454 %\n",
      "[epoch 595]  Loss: 0.0932  Accuracy: 67.492 %\n",
      "[epoch 596]  Loss: 0.0925  Accuracy: 67.912 %\n",
      "[epoch 597]  Loss: 0.0924  Accuracy: 68.136 %\n",
      "[epoch 598]  Loss: 0.0925  Accuracy: 67.812 %\n",
      "[epoch 599]  Loss: 0.0927  Accuracy: 67.946 %\n",
      "[epoch 600]  Loss: 0.0923  Accuracy: 67.998 %\n",
      "[epoch 601]  Loss: 0.0923  Accuracy: 67.906 %\n",
      "[epoch 602]  Loss: 0.0927  Accuracy: 67.858 %\n",
      "[epoch 603]  Loss: 0.0935  Accuracy: 67.318 %\n",
      "[epoch 604]  Loss: 0.0932  Accuracy: 67.626 %\n",
      "[epoch 605]  Loss: 0.0928  Accuracy: 67.774 %\n",
      "[epoch 606]  Loss: 0.0928  Accuracy: 67.674 %\n",
      "[epoch 607]  Loss: 0.0925  Accuracy: 67.808 %\n",
      "[epoch 608]  Loss: 0.0923  Accuracy: 68.002 %\n",
      "[epoch 609]  Loss: 0.0926  Accuracy: 67.778 %\n",
      "[epoch 610]  Loss: 0.0926  Accuracy: 67.936 %\n",
      "[epoch 611]  Loss: 0.0932  Accuracy: 67.706 %\n",
      "[epoch 612]  Loss: 0.0931  Accuracy: 67.588 %\n",
      "[epoch 613]  Loss: 0.0935  Accuracy: 67.634 %\n",
      "[epoch 614]  Loss: 0.0933  Accuracy: 67.512 %\n",
      "[epoch 615]  Loss: 0.0933  Accuracy: 67.606 %\n",
      "[epoch 616]  Loss: 0.0940  Accuracy: 67.254 %\n",
      "[epoch 617]  Loss: 0.0918  Accuracy: 68.070 %\n",
      "[epoch 618]  Loss: 0.0913  Accuracy: 68.312 %\n",
      "[epoch 619]  Loss: 0.0916  Accuracy: 68.198 %\n",
      "[epoch 620]  Loss: 0.0921  Accuracy: 67.990 %\n",
      "[epoch 621]  Loss: 0.0923  Accuracy: 67.966 %\n",
      "[epoch 622]  Loss: 0.0926  Accuracy: 67.732 %\n",
      "[epoch 623]  Loss: 0.0924  Accuracy: 67.776 %\n",
      "[epoch 624]  Loss: 0.0917  Accuracy: 68.138 %\n",
      "[epoch 625]  Loss: 0.0916  Accuracy: 68.104 %\n",
      "[epoch 626]  Loss: 0.0916  Accuracy: 68.072 %\n",
      "[epoch 627]  Loss: 0.0914  Accuracy: 68.362 %\n",
      "[epoch 628]  Loss: 0.0912  Accuracy: 68.346 %\n",
      "[epoch 629]  Loss: 0.0911  Accuracy: 68.262 %\n",
      "[epoch 630]  Loss: 0.0915  Accuracy: 68.268 %\n",
      "[epoch 631]  Loss: 0.0912  Accuracy: 68.382 %\n",
      "[epoch 632]  Loss: 0.0911  Accuracy: 68.370 %\n",
      "[epoch 633]  Loss: 0.0920  Accuracy: 68.014 %\n",
      "[epoch 634]  Loss: 0.0917  Accuracy: 67.900 %\n",
      "[epoch 635]  Loss: 0.0911  Accuracy: 68.280 %\n",
      "[epoch 636]  Loss: 0.0910  Accuracy: 68.348 %\n",
      "[epoch 637]  Loss: 0.0910  Accuracy: 68.342 %\n",
      "[epoch 638]  Loss: 0.0912  Accuracy: 68.342 %\n",
      "[epoch 639]  Loss: 0.0915  Accuracy: 68.168 %\n",
      "[epoch 640]  Loss: 0.0909  Accuracy: 68.296 %\n",
      "[epoch 641]  Loss: 0.0915  Accuracy: 68.200 %\n",
      "[epoch 642]  Loss: 0.0918  Accuracy: 68.076 %\n",
      "[epoch 643]  Loss: 0.0922  Accuracy: 67.806 %\n",
      "[epoch 644]  Loss: 0.0913  Accuracy: 68.168 %\n",
      "[epoch 645]  Loss: 0.0910  Accuracy: 68.456 %\n",
      "[epoch 646]  Loss: 0.0903  Accuracy: 68.676 %\n",
      "[epoch 647]  Loss: 0.0905  Accuracy: 68.608 %\n",
      "[epoch 648]  Loss: 0.0909  Accuracy: 68.374 %\n",
      "[epoch 649]  Loss: 0.0907  Accuracy: 68.344 %\n",
      "[epoch 650]  Loss: 0.0906  Accuracy: 68.538 %\n",
      "[epoch 651]  Loss: 0.0909  Accuracy: 68.398 %\n",
      "[epoch 652]  Loss: 0.0910  Accuracy: 68.254 %\n",
      "[epoch 653]  Loss: 0.0912  Accuracy: 68.232 %\n",
      "[epoch 654]  Loss: 0.0908  Accuracy: 68.424 %\n",
      "[epoch 655]  Loss: 0.0911  Accuracy: 68.560 %\n",
      "[epoch 656]  Loss: 0.0911  Accuracy: 68.316 %\n",
      "[epoch 657]  Loss: 0.0905  Accuracy: 68.542 %\n",
      "[epoch 658]  Loss: 0.0906  Accuracy: 68.522 %\n",
      "[epoch 659]  Loss: 0.0904  Accuracy: 68.568 %\n",
      "[epoch 660]  Loss: 0.0911  Accuracy: 68.160 %\n",
      "[epoch 661]  Loss: 0.0910  Accuracy: 68.312 %\n",
      "[epoch 662]  Loss: 0.0906  Accuracy: 68.320 %\n",
      "[epoch 663]  Loss: 0.0908  Accuracy: 68.280 %\n",
      "[epoch 664]  Loss: 0.0906  Accuracy: 68.478 %\n",
      "[epoch 665]  Loss: 0.0903  Accuracy: 68.626 %\n",
      "[epoch 666]  Loss: 0.0897  Accuracy: 68.770 %\n",
      "[epoch 667]  Loss: 0.0899  Accuracy: 68.856 %\n",
      "[epoch 668]  Loss: 0.0902  Accuracy: 68.692 %\n",
      "[epoch 669]  Loss: 0.0906  Accuracy: 68.426 %\n",
      "[epoch 670]  Loss: 0.0911  Accuracy: 68.310 %\n",
      "[epoch 671]  Loss: 0.0905  Accuracy: 68.572 %\n",
      "[epoch 672]  Loss: 0.0906  Accuracy: 68.476 %\n",
      "[epoch 673]  Loss: 0.0904  Accuracy: 68.496 %\n",
      "[epoch 674]  Loss: 0.0897  Accuracy: 68.836 %\n",
      "[epoch 675]  Loss: 0.0896  Accuracy: 68.836 %\n",
      "[epoch 676]  Loss: 0.0894  Accuracy: 68.890 %\n",
      "[epoch 677]  Loss: 0.0894  Accuracy: 68.892 %\n",
      "[epoch 678]  Loss: 0.0894  Accuracy: 68.862 %\n",
      "[epoch 679]  Loss: 0.0896  Accuracy: 68.882 %\n",
      "[epoch 680]  Loss: 0.0893  Accuracy: 69.042 %\n",
      "[epoch 681]  Loss: 0.0890  Accuracy: 69.040 %\n",
      "[epoch 682]  Loss: 0.0893  Accuracy: 69.034 %\n",
      "[epoch 683]  Loss: 0.0889  Accuracy: 69.192 %\n",
      "[epoch 684]  Loss: 0.0891  Accuracy: 69.072 %\n",
      "[epoch 685]  Loss: 0.0895  Accuracy: 68.940 %\n",
      "[epoch 686]  Loss: 0.0896  Accuracy: 68.908 %\n",
      "[epoch 687]  Loss: 0.0919  Accuracy: 68.054 %\n",
      "[epoch 688]  Loss: 0.0930  Accuracy: 67.450 %\n",
      "[epoch 689]  Loss: 0.0915  Accuracy: 68.258 %\n",
      "[epoch 690]  Loss: 0.0903  Accuracy: 68.798 %\n",
      "[epoch 691]  Loss: 0.0895  Accuracy: 68.930 %\n",
      "[epoch 692]  Loss: 0.0890  Accuracy: 69.136 %\n",
      "[epoch 693]  Loss: 0.0892  Accuracy: 68.902 %\n",
      "[epoch 694]  Loss: 0.0897  Accuracy: 68.802 %\n",
      "[epoch 695]  Loss: 0.0893  Accuracy: 68.940 %\n",
      "[epoch 696]  Loss: 0.0893  Accuracy: 68.866 %\n",
      "[epoch 697]  Loss: 0.0895  Accuracy: 68.816 %\n",
      "[epoch 698]  Loss: 0.0894  Accuracy: 69.088 %\n",
      "[epoch 699]  Loss: 0.0893  Accuracy: 69.006 %\n",
      "[epoch 700]  Loss: 0.0885  Accuracy: 69.316 %\n",
      "[epoch 701]  Loss: 0.0885  Accuracy: 69.346 %\n",
      "[epoch 702]  Loss: 0.0884  Accuracy: 69.270 %\n",
      "[epoch 703]  Loss: 0.0887  Accuracy: 69.140 %\n",
      "[epoch 704]  Loss: 0.0899  Accuracy: 68.752 %\n",
      "[epoch 705]  Loss: 0.0890  Accuracy: 69.264 %\n",
      "[epoch 706]  Loss: 0.0892  Accuracy: 69.086 %\n",
      "[epoch 707]  Loss: 0.0883  Accuracy: 69.306 %\n",
      "[epoch 708]  Loss: 0.0880  Accuracy: 69.508 %\n",
      "[epoch 709]  Loss: 0.0883  Accuracy: 69.298 %\n",
      "[epoch 710]  Loss: 0.0883  Accuracy: 69.416 %\n",
      "[epoch 711]  Loss: 0.0878  Accuracy: 69.622 %\n",
      "[epoch 712]  Loss: 0.0879  Accuracy: 69.536 %\n",
      "[epoch 713]  Loss: 0.0879  Accuracy: 69.464 %\n",
      "[epoch 714]  Loss: 0.0875  Accuracy: 69.528 %\n",
      "[epoch 715]  Loss: 0.0876  Accuracy: 69.586 %\n",
      "[epoch 716]  Loss: 0.0879  Accuracy: 69.570 %\n",
      "[epoch 717]  Loss: 0.0879  Accuracy: 69.454 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 718]  Loss: 0.0882  Accuracy: 69.254 %\n",
      "[epoch 719]  Loss: 0.0883  Accuracy: 69.232 %\n",
      "[epoch 720]  Loss: 0.0880  Accuracy: 69.498 %\n",
      "[epoch 721]  Loss: 0.0877  Accuracy: 69.608 %\n",
      "[epoch 722]  Loss: 0.0877  Accuracy: 69.594 %\n",
      "[epoch 723]  Loss: 0.0874  Accuracy: 69.718 %\n",
      "[epoch 724]  Loss: 0.0879  Accuracy: 69.424 %\n",
      "[epoch 725]  Loss: 0.0875  Accuracy: 69.708 %\n",
      "[epoch 726]  Loss: 0.0876  Accuracy: 69.614 %\n",
      "[epoch 727]  Loss: 0.0880  Accuracy: 69.558 %\n",
      "[epoch 728]  Loss: 0.0878  Accuracy: 69.598 %\n",
      "[epoch 729]  Loss: 0.0879  Accuracy: 69.486 %\n",
      "[epoch 730]  Loss: 0.0879  Accuracy: 69.428 %\n",
      "[epoch 731]  Loss: 0.0874  Accuracy: 69.732 %\n",
      "[epoch 732]  Loss: 0.0884  Accuracy: 69.150 %\n",
      "[epoch 733]  Loss: 0.0890  Accuracy: 69.070 %\n",
      "[epoch 734]  Loss: 0.0894  Accuracy: 68.778 %\n",
      "[epoch 735]  Loss: 0.0883  Accuracy: 69.360 %\n",
      "[epoch 736]  Loss: 0.0875  Accuracy: 69.652 %\n",
      "[epoch 737]  Loss: 0.0869  Accuracy: 69.836 %\n",
      "[epoch 738]  Loss: 0.0872  Accuracy: 69.644 %\n",
      "[epoch 739]  Loss: 0.0871  Accuracy: 69.868 %\n",
      "[epoch 740]  Loss: 0.0879  Accuracy: 69.466 %\n",
      "[epoch 741]  Loss: 0.0885  Accuracy: 69.236 %\n",
      "[epoch 742]  Loss: 0.0880  Accuracy: 69.346 %\n",
      "[epoch 743]  Loss: 0.0873  Accuracy: 69.610 %\n",
      "[epoch 744]  Loss: 0.0869  Accuracy: 69.924 %\n",
      "[epoch 745]  Loss: 0.0868  Accuracy: 69.858 %\n",
      "[epoch 746]  Loss: 0.0868  Accuracy: 69.782 %\n",
      "[epoch 747]  Loss: 0.0870  Accuracy: 69.758 %\n",
      "[epoch 748]  Loss: 0.0870  Accuracy: 69.694 %\n",
      "[epoch 749]  Loss: 0.0867  Accuracy: 69.786 %\n",
      "[epoch 750]  Loss: 0.0868  Accuracy: 69.906 %\n",
      "[epoch 751]  Loss: 0.0871  Accuracy: 69.670 %\n",
      "[epoch 752]  Loss: 0.0874  Accuracy: 69.582 %\n",
      "[epoch 753]  Loss: 0.0872  Accuracy: 69.630 %\n",
      "[epoch 754]  Loss: 0.0867  Accuracy: 69.792 %\n",
      "[epoch 755]  Loss: 0.0868  Accuracy: 70.002 %\n",
      "[epoch 756]  Loss: 0.0873  Accuracy: 69.544 %\n",
      "[epoch 757]  Loss: 0.0878  Accuracy: 69.266 %\n",
      "[epoch 758]  Loss: 0.0887  Accuracy: 69.098 %\n",
      "[epoch 759]  Loss: 0.0893  Accuracy: 68.890 %\n",
      "[epoch 760]  Loss: 0.0897  Accuracy: 68.828 %\n",
      "[epoch 761]  Loss: 0.0882  Accuracy: 69.294 %\n",
      "[epoch 762]  Loss: 0.0873  Accuracy: 69.632 %\n",
      "[epoch 763]  Loss: 0.0872  Accuracy: 69.632 %\n",
      "[epoch 764]  Loss: 0.0865  Accuracy: 69.882 %\n",
      "[epoch 765]  Loss: 0.0864  Accuracy: 69.936 %\n",
      "[epoch 766]  Loss: 0.0861  Accuracy: 70.134 %\n",
      "[epoch 767]  Loss: 0.0863  Accuracy: 70.022 %\n",
      "[epoch 768]  Loss: 0.0862  Accuracy: 70.162 %\n",
      "[epoch 769]  Loss: 0.0867  Accuracy: 69.916 %\n",
      "[epoch 770]  Loss: 0.0872  Accuracy: 69.574 %\n",
      "[epoch 771]  Loss: 0.0862  Accuracy: 70.116 %\n",
      "[epoch 772]  Loss: 0.0857  Accuracy: 70.256 %\n",
      "[epoch 773]  Loss: 0.0856  Accuracy: 70.278 %\n",
      "[epoch 774]  Loss: 0.0856  Accuracy: 70.276 %\n",
      "[epoch 775]  Loss: 0.0855  Accuracy: 70.338 %\n",
      "[epoch 776]  Loss: 0.0860  Accuracy: 70.118 %\n",
      "[epoch 777]  Loss: 0.0856  Accuracy: 70.184 %\n",
      "[epoch 778]  Loss: 0.0857  Accuracy: 70.164 %\n",
      "[epoch 779]  Loss: 0.0859  Accuracy: 70.120 %\n",
      "[epoch 780]  Loss: 0.0858  Accuracy: 70.202 %\n",
      "[epoch 781]  Loss: 0.0855  Accuracy: 70.324 %\n",
      "[epoch 782]  Loss: 0.0855  Accuracy: 70.382 %\n",
      "[epoch 783]  Loss: 0.0856  Accuracy: 70.198 %\n",
      "[epoch 784]  Loss: 0.0854  Accuracy: 70.394 %\n",
      "[epoch 785]  Loss: 0.0852  Accuracy: 70.362 %\n",
      "[epoch 786]  Loss: 0.0858  Accuracy: 70.108 %\n",
      "[epoch 787]  Loss: 0.0856  Accuracy: 70.148 %\n",
      "[epoch 788]  Loss: 0.0858  Accuracy: 70.288 %\n",
      "[epoch 789]  Loss: 0.0853  Accuracy: 70.446 %\n",
      "[epoch 790]  Loss: 0.0853  Accuracy: 70.370 %\n",
      "[epoch 791]  Loss: 0.0854  Accuracy: 70.318 %\n",
      "[epoch 792]  Loss: 0.0863  Accuracy: 69.854 %\n",
      "[epoch 793]  Loss: 0.0864  Accuracy: 69.836 %\n",
      "[epoch 794]  Loss: 0.0874  Accuracy: 69.640 %\n",
      "[epoch 795]  Loss: 0.0871  Accuracy: 69.622 %\n",
      "[epoch 796]  Loss: 0.0878  Accuracy: 69.454 %\n",
      "[epoch 797]  Loss: 0.0913  Accuracy: 68.064 %\n",
      "[epoch 798]  Loss: 0.0889  Accuracy: 69.068 %\n",
      "[epoch 799]  Loss: 0.0873  Accuracy: 69.690 %\n",
      "Finished Training! Training process cost 5515.815331 sec\n"
     ]
    }
   ],
   "source": [
    "#ALL THE CODE IN THIS CELL ARE WRITE BY MY SELF#\n",
    "# Start training : set net to train model\n",
    "net.train()\n",
    "\n",
    "# make two arrays for saving matplotlib data\n",
    "train_loss = []\n",
    "train_accu = []\n",
    "accuracy = 0\n",
    "\n",
    "# get TersorBoard writer object\n",
    "writer = SummaryWriter(log_dir='Training')\n",
    "\n",
    "# Training process\n",
    "timestart = time.time()\n",
    "for epoch in range(0,epoch):\n",
    "    \n",
    "    # initialize loss,total,correct\n",
    "    loss_value = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    # do iteration (total number of training images / batch size) times\n",
    "    for i, (inputs, labels) in enumerate(trainingloader, 0):\n",
    "        \n",
    "        # get the input and its label\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # make gradients to 0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward step\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        # compute the loss\n",
    "        l = loss(outputs, labels)\n",
    "        \n",
    "        # backward step\n",
    "        l.backward()\n",
    "        \n",
    "        # optimize step\n",
    "        optimizer.step()\n",
    "\n",
    "        # compute loss\n",
    "        loss_value += l.item()\n",
    "        \n",
    "        # save to array in oder to output loss image at the end\n",
    "        train_loss.append(l.item())\n",
    "        \n",
    "        # write to tensorboard file\n",
    "        writer.add_scalars('/GroupB/Loss', {'B3': l.item()}, epoch)\n",
    "\n",
    "        \n",
    "        # compute accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total = total + labels.size(0)\n",
    "        correct = correct + (predicted == labels).sum().item()\n",
    "        accuracy = correct / total * 100.0\n",
    "        \n",
    "        # save to array in oder to output accuracy image at the end\n",
    "        train_accu.append(accuracy)\n",
    "        \n",
    "        # write to tensorboard file\n",
    "        writer.add_scalars('/GroupB/Accuracy', {'B3': accuracy}, epoch)\n",
    "        \n",
    "\n",
    "    loss_epoch = loss_value / (500000/batch_size)\n",
    "    # output the result of this epoch \n",
    "    print('[epoch %d]  Loss: %.4f  Accuracy: %.3f %%' %(epoch, loss_epoch , accuracy))\n",
    "\n",
    "    \n",
    "# Finish Training\n",
    "result_training_accuracy = accuracy\n",
    "result_training_time = (time.time()-timestart)\n",
    "print('Finished Training! Training process cost %3f sec' %result_training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0b2132a8d0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the loss\n",
    "plt.plot(np.arange(len(train_loss)), train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0b201215c0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl8VNXdx/HPL/tCAgFCCARkB0EWMQKKigoqUEVbt1ptseUpbbXWbra41LovXa3PYmvVQutSt1rcC+IOCgYEFAHZt7BvgUD28/wxN0OWSTIJk0xm8n2/XnnN3Dt35v5yE77cnHvuOeacQ0REIl9MuAsQEZHQUKCLiEQJBbqISJRQoIuIRAkFuohIlFCgi4hECQW6iEiUUKCLiEQJBbqISJSIa8mdde7c2fXq1asldykiEvEWL168xzmX2dB2LRrovXr1Ii8vryV3KSIS8cxsUzDbqclFRCRKKNBFRKKEAl1EJEoo0EVEooQCXUQkSijQRUSihAJdRCRKKNBFRI7D2l2H+Gjd3nCXAQQR6GY20MyWVvkqMLMfm1lHM5trZmu8x4yWKFhEpLms332YXjNe48M1e+rcZtehIgCKSsvZVVDEhD+8z1V//ZhbXvqMXjNe446XV/D2qp1UztfckvM2N3inqHNuNTACwMxigW3AS8AMYJ5z7gEzm+Et/7IZaxURadCqHQUMzErDzGq9tnbXYbqkJ5KeFB/wvZ9uPgDAX95fxwmdUujRMaXa668uz+eHT38KwPhBXZi3apf/tacXbgZg5oKNzFywsdr7fjyhPz+eMKDJ31OwGtvkMh5Y55zbBFwMzPLWzwIuCWVhIiINWbWjgMseWUBhcRkAizftY+JDH/B/767jly8sZ/Gm/f4z5ENFpUz4w3sMu2MO97z6Bdc8thDwnUFXbvOz55cB8MGaPZz5m3f4/ZzVjL7vLZZv9QV9ZZgD1cK8IX99f/3xf7NBaOxYLl8HnvGeZznntgM457abWZdAbzCz6cB0gJ49eza1ThGJEhMfep+0pDie//7px/1Zv3lzNXmb9jN/7R7OH9KVrfuPAvDb/6wG4Nm8LWSmJbL7UHG19z324QYAes14rd7P/++31wIw5X/mM/v6sU2us7CknINHS2mfHPgvg1AJ+gzdzBKAKcDzjdmBc+5R51yucy43M7PBwcJEJMqt2nGITzbur3ebL/IL/GfdNVU9o+7gBeTDb68BYFaNpg6gVpg31cX/O7/WusHZ6QCM7t2Rv3zzFL49thfXnt6LZbefX2vbPYdDU0d9GnOGPglY4pzb6S3vNLNs7+w8Gwj+7w8RiQjOOXYfKqZLelLIP7usvILCknL/Wevh4jIKi8tITYxj8sMf0DU9iY9vGQ/AroIiPlizh6z0JK553NdU8ug3T2G3F5Kfbyto8Gw7VN75+dmc87t3Abg8N4cJJ2bRJT2RxLhYLhjStc73de+Q3Oy1NSbQr+JYcwvAy8BU4AHvcXYI6xKRVuC5vC388sXPeOWHZzA0p32tEA7k4JFS1u05zMieGazffZh9hSXk9upYa7s7XlnBkx9v5olrc8lISeCr/7cAgAuGZAGwo6Co3pCe/o/Fjf5+Lj8lh7W7D/svflY6a0Am73+527+88q6JnHj7mwA8cW0u35l5bNjv3p1T+el5A/jD3C+ZcGJWrQundUmKj210vY0VVKCbWQpwHvC9KqsfAJ4zs2nAZuDy0JcnIuFU2TSycnsBQ3Pac+/rK/nb/I18ec8kEuJ8LbYr8g8yZ8VOfnLeAO5/YyV/ec93AfCui4dw++wV/s+676tDWbPrkH/5yY99vUKqhiXAf1bsJBTSkuJ4ctpoyioclz6ygLH9OvHby4fjnGPr/qN0TE3gh08v4Z3Vu6uF+WWn5JCcEMsHvziHFfkHOXdQVq3P/tH4/vxofP9693/HRYO545UvQvK9BCuoQHfOHQE61Vi3F1+vFxGJEK9/tp2/frCel65r+AJfaXkFLyzeCsAvXlzOsq0HeMrrmjfgtjd4/6ZzuPXfn/GB12f7++P6+sMcqBbmALe89FlIvoclvzqPkXfP9S93TU9iR4Gvb/jz3z+Ny//8EQAvXXc6/bqkAbDxga/4tzcz/1l1fGzty4i/u3w4AD061u622JiLmqN6d2p4oxBr0RmLRCS8rn96Cc5BSVmF/wz75LvmcOWpPclKT+SMfp3p0TGFpPhY+t/6RrX3VoZ5pbN++0615Tlf7Gi2ut+76Ww+WreXCYOzSK7RdHHHlCG8sHgL939tGJlpif713Ts03BRSecvP+EFduHnyIErKAt8EdMGQLP6zYieDuqYFXfPgbumkJMRypKScjJTm7d1SSYEu0gaUVzj63vK6f/m+11dyx5QhPPnxJvYfKeXP763zv5YYF8PqeyY1eh83/nPpcdWYlhRHj4wUvtheAMC6+ybzXN4WpgzvRmpiHCd0SvVvO6hrGqt2+Jpv+nVJ5bGpp9b6vOSEhtusi0rLAbjmtBP8Z/OBPHL1KfxtwUYuOyWnUd/Tqzecwbm/f485PxnXqPc1lQJdJAqs2lHAkZJy8g8c5cJh3SgqLWdvYQljH3g74PYzF2zkitwe3Pbvz2u9VlxWEbIeI+vum0xpeQV/m7+RB99cxVWjevDMoi0Bt71oeDfu++pQrn96CcnxscTGGFeNCnzvyvmDs/yB3rldYrXXnp0+htTE4KLtxOx0Plizhx4Z9fdAiYkxpp3RO6jPrKpPZrtqzT3NTYEuEoHW7jrENY8tYkdBEdee3qvareafbT3IX4K4M3Hywx8Eta97LjmJnh1T+NYTiwBYdvv5vLBkK3e/euyC35W5PXg2zxfUU4Z34+Vl+VwzpiexMUZsTCzfH9eHC4dl06NjCndOOYkBt71B++R4pp3Rm2VbDjBv1S4uGtYNgP/9xsgGayopP9Y0UvM2/tF9gm+7/vn5A7loWLd6z84jiQJdJMx8gzwVc7S0nPyDR1m25QDvrN7NuP6d+en5A3HO0ftmX3PJiz84jYNHS6v1DKk5bkgwYV6Xq0f3rNZWfueUIVwz5oRqN+e0T4mnd2df+/SPxvdn4pCuDO6WTnFZOf9ems+g7DQevqr6WWnVC5EJcTHcfuFgzh6YSZ/Mdk2q8/vj+vDUwk385ZunEBNTe8yWYCXExTA0p32T39/aWEuOBJabm+vy8vIa3lCkDZn6xCLeq9JtrqqcjGT/7eyh8PR/jeapRZt5bfn2gK9X7UFiBhvu9wXzvsISRt49l9gYY919kwFYs/MQ/bOOndkePFLK7+as5ubJg0hJ0LliKJnZYudcbkPb6aiLhNCWfUdISYiltNyxYU8hA7LacfvsFdx/6VBmf7qNX81ewYnZ6Xz91B48/uEGfnf58DrDHDjuME9NiKWwpJyvntyd9XsKOblnBqf368yN4w+xYU8h552Yxb+XbmPmgo08//3TSIw7diExrUo7dKw3cmHVHiZVwxx8Z+53X3LScdUrx0eBLtJERaXlmEFiXCzFZeW8sHgrt770OTEGFTX+8H3ts2NnxCu3F/Drl319tK/4y0dB7y+7fRLbDxY1qsabLhjIHa98waUjczijf2f/+gFZaQzwAvlrI3P42sjavTcKio6NpVLh/SUfexzNG9L8NGORSBCOlpRTWFxGUWm5v6vboF+9ycDbfLeHD7ztTW59yddjpGaYN9WVuT2qLT/z3TH+52cNqD7Q3Rd3XcCs74zyL5/aK4M1907iW6f1Yvb1Y6uFeUMeudp3UXLJr87zr0tPjmdwdjp/uGJ4o74HaVk6Q5c2Y+X2AlbvOMQlJ3ev9dr8tXtYsmk/s5flM/cnZ+Gc76aT0fe9xZ7DJQDExxqlXu+KDfdP9r+3uQaFGpR9rEnje+P60KtzKiN7dmDJ5gM8+s1T+HDNHvYVljCwaxopCXGMqxLy08/q678LcniPDo3a76Sh2bW62sXGGK/feOZxfDfSEhToErU27z2CGf7eFZP+5OumVxnozjl+Nftznlq4map9Ayp7lNRUWqWr3MvL8oOu49cXDWZgVhrf8CZU6N05lZyMZHYWFPHlzsO1tr8iN4fs9slcMKQrd77yBV3SErl50okAPD71VFbuKCApPpYJg2uPMVLpzEackUv0UKBL1Kq8Nb3m2eaj76/jrZW7WLRhX5M/O9Bdkfd+9STG9OnE+N+/B8D7N53DK8vzufb0XphZrTom/OG9asuVXQYvHZnD6D6dKCmroHO7RO6YMsS/TUZqAqf3bTis49TW3Sap26JEjRue+ZRh3dvz3bP6sHnvEX+gb7h/MtsPFnF6HXdNhsKArHb+27s37ilkZ0FRgze4fL7tIBf+94cAzPvZOPpmtsM5F3AuzGDlHzhK3qb9TBnercmfIa1PsN0WFegSUfYVlhAbY7RPjue15dvZsOcw3xvXl2F3zOGod7EylNbdN5mlW/Zz6SOBe6N8cusE4mKMpPjYoMYOqWn7waMs2rCPi0fUbtcXqRRsoKuXi0SUkXfPZfidc/jXkq1c//QSfjfnS/rf+kaTw3zmt08l94QMEmJjePfnZwNww7n9ALhl8iBiY8zfvj44O50rco9170uIjSEzLZGM1IQmhTlAdvtkhbmEjNrQpUXNX7uHxLiYajPYbNl3hG0HjjKmTyemzfyE9snxXD3mBDJS4slKTyI1Mc7XhHHfPP97fvrcsibtv3uHZLYd8N2s8+ClQzl7YBfOHnhsfvPKdu4bx/cnzuslclL39pzZvzM3TzqRwd18c0g+l7eV2y8a3KQaRJqLAl1a1NVeT4/K4MzbuI/LvAkJPv3Vecxb5Zua9l+fbvO/5/2bzuHB/6wK6vNfuu50/1RmNbVLjGP+jHOD+py4KhMfJMXH8o9po2tvowuP0sqoyUXC5rXl2/1hDnD+Q+8H3O6s375T59gjVb34g9M5uWcGPzynX52vh8K3TutFcnws5wzq0vDGIi1IgS4hVVpewZqdx+aNLCotp7zCsb+whA17Cv3rv/n4Qq5/ekm191Yd0S9YndslMiDLN2Jf5TgjVTuJrLp7Ivd/bSgAfTJTa72/KU7q3p6Vd08kKz0pJJ8nEipqcpGQenjeGv777bUA/ODsvjzy7rqA21XOQ9kUPzi7LzeO7098bAzOOQ4VlfHG5zs40buz8nvj+rLjYBFfGZZNUnwsV43qWedECSLRRN0WpUlKyyvYf6SELmm+s9TisnIS42IZc988/4S9xyPvtgnk3vNWtXU/PKcfl56SQ69OKcfVV1sk0mj4XAmp/6zYwfYDR7l2rG8arpueX8a/l+bz9HdH842/+i50/u7y4Y0K8/kzzq01RdqquyeS5DWd5N02gV+/vILMdolcPbon/bq0U5CL1EOBLvV6eVk+Q7ql871/LAZgaE4Hikp9M9MA/jAH+PnzwXclrGuexaQq4213bpcY1HRkIuIT1EVRM+tgZi+Y2SozW2lmp5lZRzOba2ZrvMeM5i5WQuPj9Xu55aXPuP/1lQRqcrt99uf0mvEa2w8e5UfPfOofmwTg0kcW+Lse1ucbo2u3WX/vrD4A1SZBeOun43ji2lw6piY05VsRkSqCakM3s1nAB865x8wsAUgBbgH2OeceMLMZQIZz7pf1fY7a0FuHqsO9fnLrBJ5auIkOyfFcO7a3f6qx4/GbS4dxxak9qu3ry3smER9rdTaZHCkpo6zC1ZrwV0RC2IZuZunAWcC1AM65EqDEzC4GzvY2mwW8C9Qb6NL6FJWW89BbawDfJAZNvQOzqsowB99QsRv2FJIQV/8fg5qDUuT4BfOvqA+wG/ibmQ0HFgM3AlnOue0AzrntZqa7LCLA659Vv0Gn6pyV9YX5lbk9eDZvi3/5r9/KpVenFHYWFPPSp9t4cclWAL57Zu9q7/v3dWPZf6QkFKWLSAMabHIxs1zgY2Csc26hmf0JKABucM51qLLdfudcrXZ0M5sOTAfo2bPnKZs2bQpl/dKA4rJy7nl1JaeckMEHa/b4g7cxnrg2l/wDRdz2b98Ua2cNyOTvVaY7A1i8aT+vLMvn9gsHE6Nb4kVCKmTD55pZV+Bj51wvb/lMYAbQDzjbOzvPBt51zg2s77PUht78yit8s83369KO+Wv38J8VO/j7R43/T/ShK0fwlWHZOAcJcTFUVDgWrNvL7KXb+PF5A+jeIbkZqheRQELWhu6c22FmW8xsoHNuNTAe+ML7mgo84D3OPs6a5TgUlZazYN0ebnp+OXsLS3hy2miuebzu3ih//84ovvXEooCv5d02gc7tEquti4kxzujfuVGTDYtIywr2StQNwFNeD5f1wLfxdXl8zsymAZuBy5unRKnPwSOlJCXEMPzOORSXVfjX1xfmy359Pu2T4/nG6J48vXAzf/r6CLqmJ3Hlox8D1ApzEYkMQQW6c24pEOh0f3xoy5HGGn7XHMb06VgtzBuS6k3GcPOkQXRrn8SFw7oRq3ZvkYin0RajwMfr65/suFOVm3Z+fdFg/1jfaUnx/PDc/gpzkSihzr+t3Jqdh1iyeT9XntqTZxZtZkX+QZ78eDMAndvVf3flv647nb6d25EQF8OK/IMM7JpGmm7cEYlaCvRW7GhJOef90Tfpw+yl+SxYt7fa63sO19+/e1j39v6z8apTvolIdFKgtyLlFQ4Dfz/uqrfg1wzzYFSdRi0Yt04+NmemiEQeBXor0veW1xnduyPPfHcM972+ssGZ7M3AOTizf2c+WLOHR64eydCc9sTHxjRp9p/veoNniUhkUqC3ErfP9t2FuXDDPvrc8nq9257RrzOPTc0lKT6W/YUlpCfHs/3gUXIyUvzbaHo0kbZHgd4KLN96IKi7OdfcO4nXP9vOlOHd/KMWZng9WKqGuYi0Teq2GCYHjpRwuLiMtbsOM+V/5te53as3nMGgrmm8esMZxMfGcPGI7pq1R0QC0hl6C3ruky38+uUVfH7nBYy4q+Exx1fceQGpiXG8+eOzWqA6EYl0CvQWsnD9Xn7x4nLAd/GzpienjaaotJzuGcnExRhrdx0mNVE/HhEJnhKjBbz1xU7+6+/1jzJZc9Cr/llpzVmSiEQhtaE3s8+3HWwwzP98zSktVI2IRDOdoTcD5xxHS8tJSYjjq/9X9wVPgH9MG8WZ/TNbqDIRiWYK9BA6VFTK0Dvm+JdP6JRCaXn1CUT+9PURPP7hBmZfP5Y9h0vITNNQtSISGgr0EFq941C15U17j/ifXzWqBzMmnkj7lHguHtEdQGEuIiGlQD9OB4+UMvyuOYwbkMl7X+4OuM2VuT24/2vDWrgyEWlrdFH0OH25y3dWXleYA9x58ZCWKkdE2jAFeiP9Yc5qfv78MgDW7jrEO6t2NfiepPjY5i5LRERNLo318NtrATh3UBeue2pJrdc/vnk88bHGz55fxp7Dxdw6eXBLlygibZQCvRGOlhwbzjZQmC+6dTxd0nyjHM789qgWq0tEBBToQdt24ChPfVz3iIhr753U6AklRERCSYEepLEPvB1wfU5GMvd+dajCXETCToEehOc+2RJw/W8uG8ZlI3P8U8aJiISTAj0IlaMk1nRFbo8WrkREpG5BBbqZbQQOAeVAmXMu18w6As8CvYCNwBXOuf3NU2Z4PPjmKh55d121dX++ZiSzl+bzwKW6UUhEWpfGNPye45wb4ZzL9ZZnAPOcc/2Bed5y1Hhn1a5aYf7Xb+Uy8aRsHrnmFNonx4epMhGRwI7nSt7FwCzv+SzgkuMvJ3wqKhzPLNpMSVkF+QeO8u2Zn9Ta5rzBWWGoTEQkOMG2oTtgjpk54C/OuUeBLOfcdgDn3HYz6xLojWY2HZgO0LNnzxCU3DxeWZ7Pzf/6jI/W7eXlZfm1Xp84pGsYqhIRCV6wgT7WOZfvhfZcM1sV7A688H8UIDc31zWwedgUFvtuGgoU5gAPXDq0JcsREWm0oJpcnHP53uMu4CVgFLDTzLIBvMeGBzVpxRLjah+KM/odmxYuLUlt5iLSujV4hm5mqUCMc+6Q9/x84C7gZWAq8ID3OLs5C21u6QEucj75X6PZsu8In2zcR6z6motIKxdMk0sW8JKZVW7/tHPuTTP7BHjOzKYBm4HLm6/M5lNe4Rh171vsLSzxr4uPNX5y3gAAenRMoUfHlHCVJyIStAYD3Tm3HhgeYP1eYHxzFNWSDhwpqRbmAMt/fQHJCRryVkQiS5u+U7S0vIJT7nmr2rpVd0/U+OUiEpHa9IhS/W99o9ryvJ+NU5iLSMRqs4G+42BRteW3fjqOvpntwlSNiMjxa7OBPub+edWW2yW26dYnEYkCbTLQn8+rPRxuSqKaWkQksrXJQL/phWPD4VaOz5KaoDN0EYlsbS7F7nrlC//zp787mpE9M9hZUKQbh0Qk4rWpM/TFm/bzxPwN/uXhOR1Iio/lhE6pYaxKRCQ02kygv7Isn0sfWeBf/uf0MaTqQqiIRJE2EejbDx7lhmc+rbZuTJ9OYapGRKR5tIlAP+3+t6stP3TliDBVIiLSfKK+zaGotNz//LeXDeNyTewsIlEqqgO9sLiM56r0OT97YMBJlUREokJUB/ol/zufNbsOAzD3J2eRmZYY5opERJpPVAb68q0HmLdylz/MAfponBYRiXJRGehT/md+rXW6cUhEol1UBbpzjvKKVjsPtYhIs4qqbouPvr+efjXGOBcRaSui6gz9xSVbqy3Pvn4ssTFGRmpCmCoSEWk5URXoKTVGTBzeo0OYKhERaXlR0+RSUFTK0i0H/Ms/O29AGKsREWl5URPo763eXW05PTk+TJWIiIRH1AR6siZ3FpE2LuhAN7NYM/vUzF71lnub2UIzW2Nmz5pZWK88PvjmKgAGZqWRk5HMV4Zlh7McEZEW15gz9BuBlVWWHwT+6JzrD+wHpoWysMaYOX+D/67Qf04fw4e/PJfO7XSbv4i0LUEFupnlAF8BHvOWDTgXeMHbZBZwSXMUGIw7qkwrpy6KItJWBXuG/hDwC6DCW+4EHHDOlXnLW4HuIa6t0U7uqW6KItJ2NRjoZnYhsMs5t7jq6gCbBrzn3symm1memeXt3r070CbHxblju12xrSDkny8iEimCOUMfC0wxs43AP/E1tTwEdDCzyjt5coD8QG92zj3qnMt1zuVmZmaGoOTqdh8q9j9/+CrNRCQibVeDge6cu9k5l+Oc6wV8HXjbOXc18A5wmbfZVGB2s1VZj+KyCv/zC4Z0DUcJIiKtwvH0Q/8l8FMzW4uvTf3x0JTUOKXlvkD/0bn98F2rFRFpmxo1lotz7l3gXe/5emBU6EtqnMoz9IFd08NciYhIeEX8naKfbNwHQPeM5DBXIiISXhEf6Hu8i6KDuqaFuRIRkfCK+EA/cLSU9KQ4kjSWi4i0cRE/HvrfP9oU7hJERFqFiD9DFxERn4gO9Mqbik7olBLmSkREwi+iA33cb98B4Pvj+oa5EhGR8IvoQD9SUg7AlzsPhbkSEZHwi+hA797B1/f8W6f1Cm8hIiKtQEQH+rYDR0mMi6F359RwlyIiEnYRHegA7RIjvueliEhIRHSgpyXFcdHwbuEuQ0SkVYjYQC8sLuNQURnpSTpDFxGBCA70v83fAMDKHerhIiICERzo+4+UAvCDs9UHXUQEIjjQH//Qd4Y+pJvGQRcRgQgO9EqJcRplUUQEIni0xRM6pdC5XWK4yxARaTUi9gx9094jZLdPCncZIiKtRkQG+pZ9RwCIi9Gk0CIilSIy0J9auBmAM/tnhrkSEZHWIyIDffEm38TQOZoYWkTELyIDfWj3DgCM7tMpzJWIiLQeDQa6mSWZ2SIzW2ZmK8zsTm99bzNbaGZrzOxZM0to/nJ9CopK6aYLoiIi1QRzhl4MnOucGw6MACaa2RjgQeCPzrn+wH5gWvOVWd3Bo6WkJ8e31O5ERCJCg4HufA57i/HelwPOBV7w1s8CLmmWCgPYV1hCewW6iEg1QbWhm1msmS0FdgFzgXXAAedcmbfJVqB785RYXVl5BV/kF3Bitm75FxGpKqhAd86VO+dGADnAKODEQJsFeq+ZTTezPDPL2717d9Mr9azdfZijpeWc3LPDcX+WiEg0aVQvF+fcAeBdYAzQwcwqhw7IAfLreM+jzrlc51xuZubx9xvfV1gCQJc0XRQVEakqmF4umWbWwXueDEwAVgLvAJd5m00FZjdXkVVd99QSwDdbkYiIHBNMKmYDs8wsFt9/AM855141sy+Af5rZPcCnwOPNWKffAW8c9OQEjbIoIlJVg4HunFsOnBxg/Xp87ektqmfHFDbvO8IJHVNaetciIq1axLVb9M1MpX1yPHGxEXmTq4hIs4m4VDxUVEa7xIj7f0hEpNlFXKDvPFREVromthARqSmiAt05x66CYrqkq8uiiEhNERXo+4+UUlxWQZYCXUSklogK9C/yCwDo16VdmCsREWl9IirQtx3wTT3Xp3NqmCsREWl9IirQ8w8UAWjoXBGRACIq0Gcu2AigbosiIgFEVKCP6OEbYTE2xsJciYhI6xNRgV5SVsGpvTLCXYaISKsUUYG+r7CEjJQWm7pURCSiRFagHymhY6oCXUQkkIgJdOccuw8Vk6FAFxEJKGIC/aP1ewF4dXnAiZFERNq8iAn0WPP1bJl0UnaYKxERaZ0iJtCT4n0zFI3u3THMlYiItE4RE+gVzgEQoz7oIiIBRV6gmwJdRCSQCAp032OsAl1EJKCICfTyisoz9DAXIiLSSkVMoFc2uZjO0EVEAoqcQK/wPWpgLhGRwCIm0AtLygBISYgNcyUiIq1Tg4FuZj3M7B0zW2lmK8zsRm99RzOba2ZrvMdmHQaxsNgX6KkaC11EJKBgztDLgJ85504ExgDXm9lgYAYwzznXH5jnLTebY4GuM3QRkUAaDHTn3Hbn3BLv+SFgJdAduBiY5W02C7ikuYoEOFxcDkBaoqafExEJpFFt6GbWCzgZWAhkOee2gy/0gS51vGe6meWZWd7u3bubXGhhcRkxBknxEdPsLyLSooJORzNrB7wI/Ng5VxDs+5xzjzrncp1zuZmZmU2pEYDDxWWkJsap26KISB2CCnQzi8cX5k855/7lrd5pZtne69nAruYp0aewuEyTQ4uI1COYXi4GPA6sdM79ocpLLwNTvedTgdmhL++YnYeK6dwusTl3ISIS0YIqG+1RAAAHrUlEQVQ55R0LfBP4zMyWeutuAR4AnjOzacBm4PLmKdFn58EiTuiU0py7EBGJaA0GunPuQ6CuhuvxoS2nboeLy0hLUg8XEZG6REyXkbKKCuJjdUFURKQuERPo5RVO47iIiNQjYgK9rMIRp0AXEalTxAR6ebkjNiZiyhURaXERk5BlFY44taGLiNQpYgJdbegiIvWLmEAvq6hQG7qISD0iItArKhwVTrMViYjUJyICvdybTzRWA3OJiNQpMgK9whfocbERUa6ISFhEREKWlvtmiFYbuohI3SIi0I+doSvQRUTqEhGBXlYZ6DpDFxGpU2QEerl3UVR3ioqI1CkiErKswmtDV5OLiEidIiPQy9XkIiLSkMgIdHVbFBFpUEQkZLkuioqINCgiAl390EVEGhYRga5+6CIiDYuIQK/s5aJuiyIidYuIhKzs5RKvJhcRkTpFRKBXNrlo+FwRkbo1GOhm9oSZ7TKzz6us62hmc81sjfeY0ZxFlqrboohIg4JJyJnAxBrrZgDznHP9gXnecrMpr1AvFxGRhjQY6M6594F9NVZfDMzyns8CLglxXdV8Z2YeoF4uIiL1aWobRpZzbjuA99gldCXVzVCgi4jUpdkbpc1supnlmVne7t27m/QZc39yFleN6snArmkhrk5EJHo0NdB3mlk2gPe4q64NnXOPOudynXO5mZmZTdpZ/6w07v/aUPVyERGpR1MD/WVgqvd8KjA7NOWIiEhTBdNt8RngI2CgmW01s2nAA8B5ZrYGOM9bFhGRMIpraAPn3FV1vDQ+xLWIiMhx0J06IiJRQoEuIhIlFOgiIlFCgS4iEiUU6CIiUcKccy23M7PdwKYmvr0zsCeE5YSK6moc1dU4qqtxorWuE5xzDd6Z2aKBfjzMLM85lxvuOmpSXY2juhpHdTVOW69LTS4iIlFCgS4iEiUiKdAfDXcBdVBdjaO6Gkd1NU6briti2tBFRKR+kXSGLiIi9YiIQDeziWa22szWmlmzzl8aYN8bzewzM1tqZnneuoCTZJvPw16dy81sZIhrCXrC7vpqMbOp3vZrzGxqoH2FoK47zGybd9yWmtnkKq/d7NW12swuqLI+ZD9nM+thZu+Y2UozW2FmN3rrw3q86qkrrMfL+7wkM1tkZsu82u701vc2s4Xe9/+smSV46xO95bXe670aqjnEdc00sw1VjtkIb31L/u7HmtmnZvaqtxzWY4VzrlV/AbHAOqAPkAAsAwa34P43Ap1rrPsNMMN7PgN40Hs+GXgDMGAMsDDEtZwFjAQ+b2otQEdgvfeY4T3PaIa67gB+HmDbwd7PMBHo7f1sY0P9cwaygZHe8zTgS2/fYT1e9dQV1uPl7cuAdt7zeGChdyyeA77urf8z8APv+XXAn73nXweera/mZqhrJnBZgO1b8nf/p8DTwKvecliPVSScoY8C1jrn1jvnSoB/4pukOpzqmiT7YuDvzudjoIN5MzuFgmvchN111XIBMNc5t885tx+YC0xshrrqcjHwT+dcsXNuA7AW3884pD9n59x259wS7/khYCXQnTAfr3rqqkuLHC+vHuecO+wtxntfDjgXeMFbX/OYVR7LF4DxZmb11BzquurSIj9LM8sBvgI85i0bYT5WkRDo3YEtVZa3Uv8/gFBzwBwzW2xm0711dU2SHY5aG1tLS9b4Q+9P3icqmzbCUZf35+3J+M7sWs3xqlEXtILj5TUhLMU3reRcfGeMB5xzZQH246/Be/0g0Kk5aqtZl3Ou8pjd6x2zP5pZYs26auw/1HU9BPwCqPCWOxHmYxUJgR5oItGW7Joz1jk3EpgEXG9mZ9WzbbhrraquWlqqxkeAvsAIYDvw+3DUZWbtgBeBHzvnCurbNMx1tYrj5Zwrd86NAHLwnSmeWM9+Wqy2mnWZ2UnAzcAg4FR8zSi/bKm6zOxCYJdzbnHV1fV8foscq0gI9K1AjyrLOUB+S+3cOZfvPe4CXsL3S17XJNnhqLWxtbRIjc65nd4/wgrgrxz7M7LF6jKzeHyh+ZRz7l/e6rAfr0B1tYbjVZVz7gDwLr426A5mVjm7WdX9+GvwXm+Pr+mt2WqrUtdEr/nKOeeKgb/RssdsLDDFzDbia+46F98Ze3iPVVMb31vqC980eevxXTCovPgzpIX2nQqkVXm+AF+b22+pfmHtN97zr1D9YsyiZqipF9UvPjaqFnxnMhvwXRTK8J53bIa6sqs8/wm+dkKAIVS/CLQe3wW+kP6cve/778BDNdaH9XjVU1dYj5e3r0ygg/c8GfgAuBB4nuoX+q7znl9P9Qt9z9VXczPUlV3lmD4EPBCm3/2zOXZRNLzH6ni/mZb4wnfV+kt87Xm3tuB++3gHexmwonLf+Nq+5gFrvMeOVX6x/ter8zMgN8T1PIPvz/FSfP+zT2tKLcB38F18WQt8u5nq+oe33+XAy1QPrFu9ulYDk5rj5wycge9P1+XAUu9rcriPVz11hfV4eZ83DPjUq+Fz4PYq/w4Wed//80Citz7JW17rvd6noZpDXNfb3jH7HHiSYz1hWux33/vMszkW6GE9VrpTVEQkSkRCG7qIiARBgS4iEiUU6CIiUUKBLiISJRToIiJRQoEuIhIlFOgiIlFCgS4iEiX+H8X1mhgdJ0vEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the accuracy\n",
    "plt.plot(np.arange(len(train_accu)), train_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the TensorBoard output stream\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the network is 69.942 %\n"
     ]
    }
   ],
   "source": [
    "#ALL THE CODE IN THIS CELL ARE WRITE BY MY SELF#\n",
    "# Start testing : set net to train model\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# deactivate the autograd engine\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # do testing iteration\n",
    "    #for data in testingloader:\n",
    "        \n",
    "        # get the input and its label\n",
    "        #images, labels = data\n",
    "        #images, labels = images.to(device), labels.to(device)\n",
    "    for i, (inputs, labels) in enumerate(trainingloader, 0):\n",
    "        \n",
    "        # get the input and its label\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward step\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        # compute accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total = total + labels.size(0)\n",
    "        correct = correct + (predicted == labels).sum().item()\n",
    "\n",
    "# Finish Testing\n",
    "result_testing_accuracy = correct / total * 100.0\n",
    "print('The accuracy of the network is %.3f %%' % result_testing_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Configuration]\n",
      "learning rate = 0.001000\n",
      "batch size = 10000\n",
      "epoch = 799\n",
      "\n",
      "[Expirement Result]\n",
      "training time = 5515.815331 sec\n",
      "training accuracy = 69.690 %\n",
      "testing accuracy =  69.942 %\n"
     ]
    }
   ],
   "source": [
    "print('[Configuration]')\n",
    "print('learning rate = %3f' % learning_rate )\n",
    "print('batch size = %d' % batch_size )\n",
    "print('epoch = %d' % epoch )\n",
    "print('')\n",
    "print('[Expirement Result]')\n",
    "print('training time = %3f sec' % result_training_time )\n",
    "print('training accuracy = %.3f %%' %result_training_accuracy )\n",
    "print('testing accuracy =  %.3f %%' % (100.0 * correct / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>click <a href='../Main.ipynb'>here</a> to return to Main.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
