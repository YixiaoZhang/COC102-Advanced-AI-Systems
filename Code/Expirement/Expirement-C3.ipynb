{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18COC102 -  Advanced Artificial Intelligence Systems - Coursework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style='color:red'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Experiment C3</p>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n",
      "CPython 3.6.7\n",
      "IPython 7.2.0\n",
      "\n",
      "numpy 1.15.4\n",
      "torch 0.4.1\n",
      "torchvision 0.2.1\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%watermark -v -p numpy,torch,torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import os\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some of line are refer source[1]\n",
    "# network (VGG16) : this network reduce some convolution cores in oder to improve speed\n",
    "class VGG16(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(VGG16,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,64,3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(64,64,3,padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64,128,3,padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 128, 3,padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.conv5 = nn.Conv2d(128,128, 3,padding=1)\n",
    "        self.conv6 = nn.Conv2d(128, 128, 3,padding=1)\n",
    "        self.conv7 = nn.Conv2d(128, 128, 1,padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.conv8 = nn.Conv2d(128, 256, 3,padding=1)\n",
    "        self.conv9 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.conv10 = nn.Conv2d(256, 256, 1, padding=1)\n",
    "        self.pool4 = nn.MaxPool2d(2, 2, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.conv11 = nn.Conv2d(256, 512, 3, padding=1)\n",
    "        self.conv12 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv13 = nn.Conv2d(512, 512, 1, padding=1)\n",
    "        self.pool5 = nn.MaxPool2d(2, 2, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(512)\n",
    "        self.relu5 = nn.ReLU()\n",
    "\n",
    "        self.fc14 = nn.Linear(512*4*4,1024)\n",
    "        self.drop1 = nn.Dropout2d()\n",
    "        self.fc15 = nn.Linear(1024,1024)\n",
    "        self.drop2 = nn.Dropout2d()\n",
    "        self.fc16 = nn.Linear(1024,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "\n",
    "        x = self.conv8(x)\n",
    "        x = self.conv9(x)\n",
    "        x = self.conv10(x)\n",
    "        x = self.pool4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu4(x)\n",
    "\n",
    "        x = self.conv11(x)\n",
    "        x = self.conv12(x)\n",
    "        x = self.conv13(x)\n",
    "        x = self.pool5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu5(x)\n",
    "\n",
    "        x = x.view(-1,512*4*4)\n",
    "        x = F.relu(self.fc14(x))\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.fc15(x))\n",
    "        x = self.drop2(x)\n",
    "        x = self.fc16(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "#end of source [1]\n",
    "#source [1] https://juejin.im/entry/5bf51d35e51d454049668d57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate=0.001\n",
    "batch_size=200\n",
    "epoch=200\n",
    "workers=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set GPU \n",
    "device = torch.device(\"cuda:0\")\n",
    "# set Netwrok\n",
    "net = VGG16()\n",
    "net = net.to(device)\n",
    "# set optimizer\n",
    "optimizer = optim.Adagrad(net.parameters(), lr=learning_rate)\n",
    "# set loss function\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# dataloader refer source [2]\n",
    "\n",
    "# load training dataset\n",
    "trainingset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, \n",
    "                                           transform=transforms.ToTensor())\n",
    "\n",
    "trainingloader = torch.utils.data.DataLoader(trainingset, batch_size=batch_size,shuffle=True, \n",
    "                                             num_workers=workers)\n",
    "# load testing dataset\n",
    "testingset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transforms.ToTensor())\n",
    "\n",
    "testingloader = torch.utils.data.DataLoader(testingset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=workers)\n",
    "\n",
    "#end of source [2]\n",
    "#source [2] https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0]  Loss: 0.1757  Accuracy: 30.368 %\n",
      "[epoch 1]  Loss: 0.1220  Accuracy: 54.506 %\n",
      "[epoch 2]  Loss: 0.0966  Accuracy: 65.334 %\n",
      "[epoch 3]  Loss: 0.0808  Accuracy: 71.628 %\n",
      "[epoch 4]  Loss: 0.0687  Accuracy: 76.040 %\n",
      "[epoch 5]  Loss: 0.0590  Accuracy: 79.596 %\n",
      "[epoch 6]  Loss: 0.0504  Accuracy: 82.572 %\n",
      "[epoch 7]  Loss: 0.0420  Accuracy: 85.512 %\n",
      "[epoch 8]  Loss: 0.0350  Accuracy: 87.898 %\n",
      "[epoch 9]  Loss: 0.0289  Accuracy: 90.162 %\n",
      "[epoch 10]  Loss: 0.0226  Accuracy: 92.244 %\n",
      "[epoch 11]  Loss: 0.0182  Accuracy: 93.870 %\n",
      "[epoch 12]  Loss: 0.0140  Accuracy: 95.458 %\n",
      "[epoch 13]  Loss: 0.0107  Accuracy: 96.524 %\n",
      "[epoch 14]  Loss: 0.0082  Accuracy: 97.432 %\n",
      "[epoch 15]  Loss: 0.0063  Accuracy: 98.058 %\n",
      "[epoch 16]  Loss: 0.0049  Accuracy: 98.562 %\n",
      "[epoch 17]  Loss: 0.0034  Accuracy: 99.082 %\n",
      "[epoch 18]  Loss: 0.0025  Accuracy: 99.330 %\n",
      "[epoch 19]  Loss: 0.0024  Accuracy: 99.302 %\n",
      "[epoch 20]  Loss: 0.0020  Accuracy: 99.466 %\n",
      "[epoch 21]  Loss: 0.0018  Accuracy: 99.540 %\n",
      "[epoch 22]  Loss: 0.0015  Accuracy: 99.592 %\n",
      "[epoch 23]  Loss: 0.0012  Accuracy: 99.708 %\n",
      "[epoch 24]  Loss: 0.0011  Accuracy: 99.716 %\n",
      "[epoch 25]  Loss: 0.0012  Accuracy: 99.712 %\n",
      "[epoch 26]  Loss: 0.0008  Accuracy: 99.812 %\n",
      "[epoch 27]  Loss: 0.0007  Accuracy: 99.862 %\n",
      "[epoch 28]  Loss: 0.0005  Accuracy: 99.934 %\n",
      "[epoch 29]  Loss: 0.0005  Accuracy: 99.870 %\n",
      "[epoch 30]  Loss: 0.0007  Accuracy: 99.810 %\n",
      "[epoch 31]  Loss: 0.0007  Accuracy: 99.836 %\n",
      "[epoch 32]  Loss: 0.0005  Accuracy: 99.902 %\n",
      "[epoch 33]  Loss: 0.0004  Accuracy: 99.934 %\n",
      "[epoch 34]  Loss: 0.0005  Accuracy: 99.888 %\n",
      "[epoch 35]  Loss: 0.0005  Accuracy: 99.870 %\n",
      "[epoch 36]  Loss: 0.0005  Accuracy: 99.884 %\n",
      "[epoch 37]  Loss: 0.0004  Accuracy: 99.892 %\n",
      "[epoch 38]  Loss: 0.0004  Accuracy: 99.912 %\n",
      "[epoch 39]  Loss: 0.0002  Accuracy: 99.982 %\n",
      "[epoch 40]  Loss: 0.0002  Accuracy: 99.966 %\n",
      "[epoch 41]  Loss: 0.0002  Accuracy: 99.958 %\n",
      "[epoch 42]  Loss: 0.0002  Accuracy: 99.964 %\n",
      "[epoch 43]  Loss: 0.0002  Accuracy: 99.976 %\n",
      "[epoch 44]  Loss: 0.0002  Accuracy: 99.956 %\n",
      "[epoch 45]  Loss: 0.0002  Accuracy: 99.980 %\n",
      "[epoch 46]  Loss: 0.0001  Accuracy: 99.988 %\n",
      "[epoch 47]  Loss: 0.0001  Accuracy: 99.994 %\n",
      "[epoch 48]  Loss: 0.0002  Accuracy: 99.946 %\n",
      "[epoch 49]  Loss: 0.0001  Accuracy: 99.986 %\n",
      "[epoch 50]  Loss: 0.0001  Accuracy: 99.984 %\n",
      "[epoch 51]  Loss: 0.0001  Accuracy: 99.982 %\n",
      "[epoch 52]  Loss: 0.0002  Accuracy: 99.960 %\n",
      "[epoch 53]  Loss: 0.0001  Accuracy: 99.990 %\n",
      "[epoch 54]  Loss: 0.0002  Accuracy: 99.956 %\n",
      "[epoch 55]  Loss: 0.0001  Accuracy: 99.994 %\n",
      "[epoch 56]  Loss: 0.0001  Accuracy: 99.998 %\n",
      "[epoch 57]  Loss: 0.0001  Accuracy: 99.980 %\n",
      "[epoch 58]  Loss: 0.0001  Accuracy: 99.978 %\n",
      "[epoch 59]  Loss: 0.0001  Accuracy: 99.978 %\n",
      "[epoch 60]  Loss: 0.0002  Accuracy: 99.938 %\n",
      "[epoch 61]  Loss: 0.0002  Accuracy: 99.968 %\n",
      "[epoch 62]  Loss: 0.0002  Accuracy: 99.960 %\n",
      "[epoch 63]  Loss: 0.0001  Accuracy: 99.972 %\n",
      "[epoch 64]  Loss: 0.0002  Accuracy: 99.942 %\n",
      "[epoch 65]  Loss: 0.0001  Accuracy: 99.980 %\n",
      "[epoch 66]  Loss: 0.0002  Accuracy: 99.922 %\n",
      "[epoch 67]  Loss: 0.0002  Accuracy: 99.956 %\n",
      "[epoch 68]  Loss: 0.0004  Accuracy: 99.880 %\n",
      "[epoch 69]  Loss: 0.0004  Accuracy: 99.900 %\n",
      "[epoch 70]  Loss: 0.0002  Accuracy: 99.950 %\n",
      "[epoch 71]  Loss: 0.0003  Accuracy: 99.948 %\n",
      "[epoch 72]  Loss: 0.0002  Accuracy: 99.956 %\n",
      "[epoch 73]  Loss: 0.0003  Accuracy: 99.932 %\n",
      "[epoch 74]  Loss: 0.0002  Accuracy: 99.950 %\n",
      "[epoch 75]  Loss: 0.0002  Accuracy: 99.960 %\n",
      "[epoch 76]  Loss: 0.0002  Accuracy: 99.954 %\n",
      "[epoch 77]  Loss: 0.0004  Accuracy: 99.890 %\n",
      "[epoch 78]  Loss: 0.0003  Accuracy: 99.932 %\n",
      "[epoch 79]  Loss: 0.0003  Accuracy: 99.940 %\n",
      "[epoch 80]  Loss: 0.0003  Accuracy: 99.928 %\n",
      "[epoch 81]  Loss: 0.0002  Accuracy: 99.958 %\n",
      "[epoch 82]  Loss: 0.0001  Accuracy: 99.984 %\n",
      "[epoch 83]  Loss: 0.0001  Accuracy: 99.988 %\n",
      "[epoch 84]  Loss: 0.0002  Accuracy: 99.932 %\n",
      "[epoch 85]  Loss: 0.0001  Accuracy: 99.970 %\n",
      "[epoch 86]  Loss: 0.0001  Accuracy: 99.968 %\n",
      "[epoch 87]  Loss: 0.0001  Accuracy: 99.980 %\n",
      "[epoch 88]  Loss: 0.0001  Accuracy: 99.988 %\n",
      "[epoch 89]  Loss: 0.0001  Accuracy: 99.984 %\n",
      "[epoch 90]  Loss: 0.0001  Accuracy: 99.974 %\n",
      "[epoch 91]  Loss: 0.0001  Accuracy: 99.982 %\n",
      "[epoch 92]  Loss: 0.0002  Accuracy: 99.946 %\n",
      "[epoch 93]  Loss: 0.0001  Accuracy: 99.974 %\n",
      "[epoch 94]  Loss: 0.0001  Accuracy: 99.978 %\n",
      "[epoch 95]  Loss: 0.0001  Accuracy: 99.970 %\n",
      "[epoch 96]  Loss: 0.0001  Accuracy: 99.980 %\n",
      "[epoch 97]  Loss: 0.0001  Accuracy: 99.980 %\n",
      "[epoch 98]  Loss: 0.0000  Accuracy: 99.998 %\n",
      "[epoch 99]  Loss: 0.0001  Accuracy: 99.986 %\n",
      "[epoch 100]  Loss: 0.0000  Accuracy: 99.996 %\n",
      "[epoch 101]  Loss: 0.0001  Accuracy: 99.978 %\n",
      "[epoch 102]  Loss: 0.0001  Accuracy: 99.968 %\n",
      "[epoch 103]  Loss: 0.0001  Accuracy: 99.982 %\n",
      "[epoch 104]  Loss: 0.0001  Accuracy: 99.976 %\n",
      "[epoch 105]  Loss: 0.0000  Accuracy: 100.000 %\n",
      "[epoch 106]  Loss: 0.0000  Accuracy: 99.994 %\n",
      "[epoch 107]  Loss: 0.0000  Accuracy: 99.994 %\n",
      "[epoch 108]  Loss: 0.0001  Accuracy: 99.986 %\n",
      "[epoch 109]  Loss: 0.0001  Accuracy: 99.984 %\n",
      "[epoch 110]  Loss: 0.0001  Accuracy: 99.972 %\n",
      "[epoch 111]  Loss: 0.0001  Accuracy: 99.986 %\n",
      "[epoch 112]  Loss: 0.0001  Accuracy: 99.976 %\n",
      "[epoch 113]  Loss: 0.0001  Accuracy: 99.986 %\n",
      "[epoch 114]  Loss: 0.0001  Accuracy: 99.974 %\n",
      "[epoch 115]  Loss: 0.0000  Accuracy: 99.998 %\n",
      "[epoch 116]  Loss: 0.0000  Accuracy: 99.996 %\n",
      "[epoch 117]  Loss: 0.0000  Accuracy: 99.992 %\n",
      "[epoch 118]  Loss: 0.0000  Accuracy: 99.996 %\n",
      "[epoch 119]  Loss: 0.0000  Accuracy: 99.998 %\n",
      "[epoch 120]  Loss: 0.0001  Accuracy: 99.986 %\n",
      "[epoch 121]  Loss: 0.0000  Accuracy: 99.990 %\n",
      "[epoch 122]  Loss: 0.0000  Accuracy: 99.992 %\n",
      "[epoch 123]  Loss: 0.0000  Accuracy: 99.994 %\n",
      "[epoch 124]  Loss: 0.0000  Accuracy: 99.994 %\n",
      "[epoch 125]  Loss: 0.0000  Accuracy: 99.998 %\n",
      "[epoch 126]  Loss: 0.0000  Accuracy: 99.994 %\n",
      "[epoch 127]  Loss: 0.0000  Accuracy: 100.000 %\n",
      "[epoch 128]  Loss: 0.0000  Accuracy: 99.992 %\n",
      "[epoch 129]  Loss: 0.0000  Accuracy: 99.994 %\n",
      "[epoch 130]  Loss: 0.0000  Accuracy: 100.000 %\n",
      "[epoch 131]  Loss: 0.0000  Accuracy: 99.998 %\n",
      "[epoch 132]  Loss: 0.0000  Accuracy: 99.994 %\n",
      "[epoch 133]  Loss: 0.0000  Accuracy: 99.998 %\n",
      "[epoch 134]  Loss: 0.0000  Accuracy: 100.000 %\n",
      "[epoch 135]  Loss: 0.0000  Accuracy: 100.000 %\n",
      "[epoch 136]  Loss: 0.0000  Accuracy: 100.000 %\n",
      "[epoch 137]  Loss: 0.0000  Accuracy: 100.000 %\n",
      "[epoch 138]  Loss: 0.0000  Accuracy: 100.000 %\n",
      "[epoch 139]  Loss: 0.0000  Accuracy: 99.998 %\n",
      "[epoch 140]  Loss: 0.0000  Accuracy: 99.994 %\n",
      "[epoch 141]  Loss: 0.0000  Accuracy: 99.988 %\n",
      "[epoch 142]  Loss: 0.0000  Accuracy: 99.990 %\n",
      "[epoch 143]  Loss: 0.0000  Accuracy: 99.996 %\n",
      "[epoch 144]  Loss: 0.0000  Accuracy: 99.996 %\n",
      "[epoch 145]  Loss: 0.0000  Accuracy: 99.996 %\n",
      "[epoch 146]  Loss: 0.0000  Accuracy: 99.998 %\n",
      "[epoch 147]  Loss: 0.0000  Accuracy: 99.998 %\n",
      "[epoch 148]  Loss: 0.0000  Accuracy: 99.996 %\n",
      "[epoch 149]  Loss: 0.0000  Accuracy: 99.994 %\n",
      "[epoch 150]  Loss: 0.0001  Accuracy: 99.992 %\n",
      "[epoch 151]  Loss: 0.0000  Accuracy: 99.990 %\n",
      "[epoch 152]  Loss: 0.0001  Accuracy: 99.988 %\n",
      "[epoch 153]  Loss: 0.0000  Accuracy: 99.988 %\n",
      "[epoch 154]  Loss: 0.0001  Accuracy: 99.984 %\n",
      "[epoch 155]  Loss: 0.0000  Accuracy: 99.992 %\n",
      "[epoch 156]  Loss: 0.0000  Accuracy: 99.988 %\n",
      "[epoch 157]  Loss: 0.0000  Accuracy: 99.998 %\n",
      "[epoch 158]  Loss: 0.0001  Accuracy: 99.986 %\n",
      "[epoch 159]  Loss: 0.0001  Accuracy: 99.982 %\n",
      "[epoch 160]  Loss: 0.0000  Accuracy: 99.998 %\n",
      "[epoch 161]  Loss: 0.0000  Accuracy: 99.994 %\n",
      "[epoch 162]  Loss: 0.0000  Accuracy: 99.994 %\n",
      "[epoch 163]  Loss: 0.0000  Accuracy: 99.998 %\n",
      "[epoch 164]  Loss: 0.0000  Accuracy: 99.998 %\n",
      "[epoch 165]  Loss: 0.0000  Accuracy: 100.000 %\n",
      "[epoch 166]  Loss: 0.0000  Accuracy: 99.994 %\n",
      "[epoch 167]  Loss: 0.0000  Accuracy: 99.998 %\n",
      "[epoch 168]  Loss: 0.0000  Accuracy: 99.998 %\n",
      "[epoch 169]  Loss: 0.0000  Accuracy: 99.998 %\n",
      "[epoch 170]  Loss: 0.0000  Accuracy: 99.996 %\n",
      "[epoch 171]  Loss: 0.0000  Accuracy: 99.994 %\n",
      "[epoch 172]  Loss: 0.0000  Accuracy: 99.988 %\n",
      "[epoch 173]  Loss: 0.0000  Accuracy: 100.000 %\n",
      "[epoch 174]  Loss: 0.0000  Accuracy: 99.998 %\n",
      "[epoch 175]  Loss: 0.0000  Accuracy: 99.998 %\n",
      "[epoch 176]  Loss: 0.0000  Accuracy: 99.998 %\n",
      "[epoch 177]  Loss: 0.0000  Accuracy: 100.000 %\n",
      "[epoch 178]  Loss: 0.0000  Accuracy: 100.000 %\n",
      "[epoch 179]  Loss: 0.0000  Accuracy: 99.998 %\n",
      "[epoch 180]  Loss: 0.0000  Accuracy: 100.000 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 181]  Loss: 0.0000  Accuracy: 100.000 %\n",
      "[epoch 182]  Loss: 0.0000  Accuracy: 100.000 %\n",
      "[epoch 183]  Loss: 0.0000  Accuracy: 100.000 %\n",
      "[epoch 184]  Loss: 0.0000  Accuracy: 99.998 %\n",
      "[epoch 185]  Loss: 0.0000  Accuracy: 100.000 %\n",
      "[epoch 186]  Loss: 0.0000  Accuracy: 100.000 %\n",
      "[epoch 187]  Loss: 0.0000  Accuracy: 100.000 %\n",
      "[epoch 188]  Loss: 0.0000  Accuracy: 99.994 %\n",
      "[epoch 189]  Loss: 0.0000  Accuracy: 99.998 %\n",
      "[epoch 190]  Loss: 0.0000  Accuracy: 100.000 %\n",
      "[epoch 191]  Loss: 0.0000  Accuracy: 100.000 %\n",
      "[epoch 192]  Loss: 0.0000  Accuracy: 100.000 %\n",
      "[epoch 193]  Loss: 0.0000  Accuracy: 99.998 %\n",
      "[epoch 194]  Loss: 0.0000  Accuracy: 99.998 %\n",
      "[epoch 195]  Loss: 0.0000  Accuracy: 100.000 %\n",
      "[epoch 196]  Loss: 0.0000  Accuracy: 99.998 %\n",
      "[epoch 197]  Loss: 0.0000  Accuracy: 100.000 %\n",
      "[epoch 198]  Loss: 0.0000  Accuracy: 99.990 %\n",
      "[epoch 199]  Loss: 0.0000  Accuracy: 99.994 %\n",
      "Finished Training! Training process cost 2851.067831 sec\n"
     ]
    }
   ],
   "source": [
    "#ALL THE CODE IN THIS CELL ARE WRITE BY MY SELF#\n",
    "# Start training : set net to train model\n",
    "net.train()\n",
    "\n",
    "# make two arrays for saving matplotlib data\n",
    "train_loss = []\n",
    "train_accu = []\n",
    "accuracy = 0\n",
    "\n",
    "# get TersorBoard writer object\n",
    "writer = SummaryWriter(log_dir='Training')\n",
    "\n",
    "# Training process\n",
    "timestart = time.time()\n",
    "for epoch in range(0,epoch):\n",
    "    \n",
    "    # initialize loss,total,correct\n",
    "    loss_value = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    # do iteration (total number of training images / batch size) times\n",
    "    for i, (inputs, labels) in enumerate(trainingloader, 0):\n",
    "        \n",
    "        # get the input and its label\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # make gradients to 0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward step\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        # compute the loss\n",
    "        l = loss(outputs, labels)\n",
    "        \n",
    "        # backward step\n",
    "        l.backward()\n",
    "        \n",
    "        # optimize step\n",
    "        optimizer.step()\n",
    "\n",
    "        # compute loss\n",
    "        loss_value += l.item()\n",
    "        \n",
    "        # save to array in oder to output loss image at the end\n",
    "        train_loss.append(l.item())\n",
    "        \n",
    "        # write to tensorboard file\n",
    "        writer.add_scalars('/GroupC/Loss', {'C3': l.item()}, epoch)\n",
    "\n",
    "        \n",
    "        # compute accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total = total + labels.size(0)\n",
    "        correct = correct + (predicted == labels).sum().item()\n",
    "        accuracy = correct / total * 100.0\n",
    "        \n",
    "        # save to array in oder to output accuracy image at the end\n",
    "        train_accu.append(accuracy)\n",
    "        \n",
    "        # write to tensorboard file\n",
    "        writer.add_scalars('/GroupC/Accuracy', {'C3': accuracy}, epoch)\n",
    "        \n",
    "\n",
    "    loss_epoch = loss_value / (500000/batch_size)\n",
    "    # output the result of this epoch \n",
    "    print('[epoch %d]  Loss: %.4f  Accuracy: %.3f %%' %(epoch, loss_epoch , accuracy))\n",
    "\n",
    "    \n",
    "# Finish Training\n",
    "result_training_accuracy = accuracy\n",
    "result_training_time = (time.time()-timestart)\n",
    "print('Finished Training! Training process cost %3f sec' %result_training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8be1f32e80>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the loss\n",
    "plt.plot(np.arange(len(train_loss)), train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8bd84452b0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the accuracy\n",
    "plt.plot(np.arange(len(train_accu)), train_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the TensorBoard output stream\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the network is 99.988 %\n"
     ]
    }
   ],
   "source": [
    "#ALL THE CODE IN THIS CELL ARE WRITE BY MY SELF#\n",
    "# Start testing : set net to train model\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# deactivate the autograd engine\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # do testing iteration\n",
    "    #for data in testingloader:\n",
    "        \n",
    "        # get the input and its label\n",
    "        #images, labels = data\n",
    "        #images, labels = images.to(device), labels.to(device)\n",
    "    for i, (inputs, labels) in enumerate(trainingloader, 0):\n",
    "        \n",
    "        # get the input and its label\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward step\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        # compute accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total = total + labels.size(0)\n",
    "        correct = correct + (predicted == labels).sum().item()\n",
    "\n",
    "# Finish Testing\n",
    "result_testing_accuracy = correct / total * 100.0\n",
    "print('The accuracy of the network is %.3f %%' % result_testing_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Configuration]\n",
      "learning rate = 0.001000\n",
      "batch size = 200\n",
      "epoch = 199\n",
      "\n",
      "[Expirement Result]\n",
      "training time = 2851.067831 sec\n",
      "training accuracy = 99.994 %\n",
      "testing accuracy =  99.988 %\n"
     ]
    }
   ],
   "source": [
    "print('[Configuration]')\n",
    "print('learning rate = %3f' % learning_rate )\n",
    "print('batch size = %d' % batch_size )\n",
    "print('epoch = %d' % epoch )\n",
    "print('')\n",
    "print('[Expirement Result]')\n",
    "print('training time = %3f sec' % result_training_time )\n",
    "print('training accuracy = %.3f %%' %result_training_accuracy )\n",
    "print('testing accuracy =  %.3f %%' % (100.0 * correct / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>click <a href='../Main.ipynb'>here</a> to return to Main.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
